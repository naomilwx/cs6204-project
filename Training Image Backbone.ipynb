{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "# chestmnist, retinamnist\n",
    "def get_image_mean_std(dataname):\n",
    "    info = INFO[dataname]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((224, 224))\n",
    "            ])\n",
    "\n",
    "    train_dataset = DataClass(split='train', transform=transform, download=True)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=8192)\n",
    "    total = info['n_samples']['train']\n",
    "    mean = torch.zeros(info['n_channels'])\n",
    "    std = torch.zeros(info['n_channels'])\n",
    "    for images, _ in train_loader:\n",
    "        num_img = len(images)\n",
    "        m, s = images.mean([0,2,3]), images.std([0,2,3])\n",
    "        mean += num_img * m / total\n",
    "        std += np.sqrt(num_img/total) * s\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/pathmnist.npz\n",
      "pathmnist tensor([0.7405, 0.5330, 0.7058]) tensor([0.3920, 0.5636, 0.3959])\n",
      "Downloading https://zenodo.org/record/6496656/files/chestmnist.npz?download=1 to /Users/naomileow/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a4e26d9d65463885431a1112f1c12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82802576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestmnist tensor([0.4936]) tensor([0.7392])\n",
      "Downloading https://zenodo.org/record/6496656/files/dermamnist.npz?download=1 to /Users/naomileow/.medmnist/dermamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a9f387e2264897bdff7ae73a39c3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19725078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dermamnist tensor([0.7631, 0.5381, 0.5614]) tensor([0.1354, 0.1530, 0.1679])\n",
      "Downloading https://zenodo.org/record/6496656/files/octmnist.npz?download=1 to /Users/naomileow/.medmnist/octmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7097f8dabc6248908b4ff79621ca9174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54938180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "octmnist tensor([0.1889]) tensor([0.6606])\n",
      "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /Users/naomileow/.medmnist/pneumoniamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0ae89427524cf7806d3cbcd5289d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4170669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pneumoniamnist tensor([0.5719]) tensor([0.1651])\n",
      "Downloading https://zenodo.org/record/6496656/files/retinamnist.npz?download=1 to /Users/naomileow/.medmnist/retinamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f60fc6b2d63460bb3a2196718b78112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3291041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retinamnist tensor([0.3984, 0.2447, 0.1558]) tensor([0.2952, 0.1970, 0.1470])\n",
      "Downloading https://zenodo.org/record/6496656/files/breastmnist.npz?download=1 to /Users/naomileow/.medmnist/breastmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e47eaa870494073b514256c59621848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/559580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breastmnist tensor([0.3276]) tensor([0.2027])\n",
      "Downloading https://zenodo.org/record/6496656/files/bloodmnist.npz?download=1 to /Users/naomileow/.medmnist/bloodmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b123ec2919ca4a54ba8645f6c203c062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35461855 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloodmnist tensor([0.7943, 0.6597, 0.6962]) tensor([0.2930, 0.3292, 0.1541])\n",
      "Downloading https://zenodo.org/record/6496656/files/tissuemnist.npz?download=1 to /Users/naomileow/.medmnist/tissuemnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937abd55417400ca0f8ab5a41cc9cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124962739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissuemnist tensor([0.1020]) tensor([0.4443])\n",
      "Downloading https://zenodo.org/record/6496656/files/organamnist.npz?download=1 to /Users/naomileow/.medmnist/organamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd87d128acb4dabae5ec87edc43dc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38247903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organamnist tensor([0.4678]) tensor([0.6105])\n",
      "Downloading https://zenodo.org/record/6496656/files/organcmnist.npz?download=1 to /Users/naomileow/.medmnist/organcmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91efcfa71b4f495a9e83122e8df95ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15527535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organcmnist tensor([0.4932]) tensor([0.3762])\n",
      "Downloading https://zenodo.org/record/6496656/files/organsmnist.npz?download=1 to /Users/naomileow/.medmnist/organsmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a442275b7a495d81bd3d380182f0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16528536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organsmnist tensor([0.4950]) tensor([0.3779])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdecb9172087411d972fa4e036525a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32657407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_stds = {}\n",
    "\n",
    "for k in ['pathmnist', 'chestmnist', 'dermamnist', 'octmnist', 'pneumoniamnist', 'retinamnist', 'breastmnist', 'bloodmnist', 'tissuemnist', 'organamnist', 'organcmnist', 'organsmnist']:\n",
    "    mean, std = get_image_mean_std(k)\n",
    "    print(k, mean, std)\n",
    "    mean_stds[k] = {\n",
    "        'mean': mean,\n",
    "        'std': std\n",
    "    }\n",
    "print(mean_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import get_device\n",
    "from models.backbone.datasets import MEAN_STDS, DataSets\n",
    "from models.backbone.trainer import Trainer\n",
    "\n",
    "device = get_device()\n",
    "MODEL_SAVE_PATH = 'models/backbone/pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/retinamnist.npz\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch import nn\n",
    "\n",
    "retina_ds = DataSets('retinamnist', MEAN_STDS) # 5 classes\n",
    "backbone = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "backbone.fc = nn.Linear(2048, len(retina_ds.info['label']))\n",
    "\n",
    "batch_size = 256\n",
    "rtrainer = Trainer(backbone, retina_ds, batch_size, device, balance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrainer.run_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52, 0.7557038049792416, 1.3845270824432374)\n"
     ]
    }
   ],
   "source": [
    "print(rtrainer.run_eval(rtrainer.best_model, rtrainer.test_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# (0.5125, 0.7247683647010932, 1.464751205444336) for non pretrained, non balanced\n",
    "print(rtrainer.run_eval(rtrainer.best_model, rtrainer.test_loader)) \n",
    "\n",
    "torch.save(rtrainer.best_model.state_dict(), os.path.join(MODEL_SAVE_PATH, 'retina_backbone_pretrained_bal.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "# 'chestmnist', 'pneumoniamnist', 'octmnist',  'retinamnist'\n",
    "chest_ds = DataSets('chestmnist', MEAN_STDS)\n",
    "\n",
    "backbone = torchvision.models.resnet50(num_classes=len(chest_ds.info['label']), pretrained=False)\n",
    "# patch for single channel\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "batch_size = 128\n",
    "ctrainer = Trainer(backbone, chest_ds, batch_size, device)\n",
    "\n",
    "ctrainer.run_train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# [7996,  1950,  9261, 13914,  3988,  4375,   978,  3705,  3263, 1690,  1799,  1158,  2279,   144]\n",
    "chest_ds = DataSets('chestmnist', mean_stds)\n",
    "\n",
    "backbone = torchvision.models.resnet50(num_classes=len(chest_ds.info['label']), weights=None)\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "backbone.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, 'cxr_backbone.pkl')))\n",
    "\n",
    "batch_size = 256\n",
    "ctrainer = Trainer(backbone, chest_ds, batch_size, device, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrainer.run_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9239799784755875, 0.6329840270919405, 0.7261211995067128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrainer.run_eval(ctrainer.model, ctrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save pretrained resnet from medclip\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from medclip import MedCLIPModel, MedCLIPVisionModel\n",
    "\n",
    "# load MedCLIP-ResNet50\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModel)\n",
    "model.from_pretrained()\n",
    "\n",
    "bconv_weight = model.vision_model.model.conv1.weight.mean(dim=1).unsqueeze(1)\n",
    "\n",
    "# The resnet model was trained on CheXpert and MIMIC-CXR\n",
    "backbone = model.vision_model.model\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "backbone.conv1.weight = nn.Parameter(bconv_weight)\n",
    "\n",
    "torch.save(backbone.state_dict(), 'medclip_resnet50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT, VINDR_SPLIT2\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "\n",
    "from utils.data import get_query_and_support_ids, DatasetConfig\n",
    "from utils.device import get_device\n",
    "from models.embedding.dataset import Dataset\n",
    "from utils.sampling import MultilabelBalancedRandomSampler\n",
    "\n",
    "configs = {\n",
    "    'vindr2': DatasetConfig('datasets/vindr-cxr-png', 'data/vindr_cxr_split_labels2.pkl', 'data/vindr_train_query_set2.pkl', VINDR_CXR_LABELS, VINDR_SPLIT2, MEAN_STDS['chestmnist'])\n",
    "}\n",
    "\n",
    "config = configs['vindr2']\n",
    "\n",
    "batch_size = 10*10\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(config.img_info, config.training_split_path)\n",
    "query_dataset = Dataset(config.img_path, config.img_info, query_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(config.img_path, config.img_info, support_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, sampler=MultilabelBalancedRandomSampler(support_dataset.get_class_indicators()))\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "import torch\n",
    "from models.backbone.trainer import DSTrainer\n",
    "from utils.f1_loss import BalAccuracyLoss, MCCLoss, F1Loss\n",
    "\n",
    "backbone = torchvision.models.resnet50(num_classes=len(config.classes_split_map['train']), weights=None)\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "mtrainer = DSTrainer(backbone, query_dataset.class_labels(), criterion=F1Loss(), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_train(5, support_loader, query_loader, lr=8e-5, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.8846505880355835 | F1 0.31754305958747864 | AUC 0.6390231661700312 | Specificity 0.8324683904647827 | Recall 0.3061603009700775 | Bal Acc 0.5693143606185913\n",
      "Loss 0.8571950793266296 | F1 0.30419912934303284 | AUC 0.6471379088770807 | Specificity 0.8628817200660706 | Recall 0.29924583435058594 | Bal Acc 0.5810637474060059\n",
      "Loss 0.8955227136611938 | F1 0.2928975224494934 | AUC 0.6467687791698298 | Specificity 0.8378623723983765 | Recall 0.29491549730300903 | Bal Acc 0.5663889646530151\n",
      "Loss 0.79469233751297 | F1 0.3806449770927429 | AUC 0.6778729220863033 | Specificity 0.8693472146987915 | Recall 0.3819085955619812 | Bal Acc 0.625627875328064\n",
      "Loss 0.8110535740852356 | F1 0.3501167893409729 | AUC 0.7095406714783695 | Specificity 0.8584957718849182 | Recall 0.33841440081596375 | Bal Acc 0.5984550714492798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8486228585243225,\n",
       " 0.32908029556274415,\n",
       " 0.6640686895563228,\n",
       " 0.8522110939025879,\n",
       " 0.3241289258003235)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, query_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.8142952919006348 | F1 0.4863552153110504 | AUC 0.6676657085120417 | Specificity 0.7322176694869995 | Recall 0.5168277621269226 | Bal Acc 0.6245226860046387\n",
      "Loss 0.7670930624008179 | F1 0.5071707963943481 | AUC 0.6955945824336179 | Specificity 0.7418272495269775 | Recall 0.5384732484817505 | Bal Acc 0.640150249004364\n",
      "Loss 0.8211760520935059 | F1 0.4695371985435486 | AUC 0.6653073310357044 | Specificity 0.7258445024490356 | Recall 0.4860992133617401 | Bal Acc 0.6059718728065491\n",
      "Loss 0.8326702117919922 | F1 0.46564146876335144 | AUC 0.6749339870345388 | Specificity 0.7001748085021973 | Recall 0.5016079545021057 | Bal Acc 0.6008913516998291\n",
      "Loss 0.8312413692474365 | F1 0.4304371774196625 | AUC 0.6596898542511708 | Specificity 0.7387593984603882 | Recall 0.4461764693260193 | Bal Acc 0.5924679040908813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8132951974868774,\n",
       " 0.4718283712863922,\n",
       " 0.6726382926534147,\n",
       " 0.7277647256851196,\n",
       " 0.49783692955970765)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, query_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model, 'models/backbone/pretrained/vindr2/trained-backbone-ba1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3af20c5b7ad2810593c71dd4ba5b7d473da7f58b181d32c1c7ac42846aa4b248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
