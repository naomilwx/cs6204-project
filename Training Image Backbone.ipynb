{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "# chestmnist, retinamnist\n",
    "def get_image_mean_std(dataname):\n",
    "    info = INFO[dataname]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((224, 224))\n",
    "            ])\n",
    "\n",
    "    train_dataset = DataClass(split='train', transform=transform, download=True)\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=8192)\n",
    "    total = info['n_samples']['train']\n",
    "    mean = torch.zeros(info['n_channels'])\n",
    "    std = torch.zeros(info['n_channels'])\n",
    "    for images, _ in train_loader:\n",
    "        num_img = len(images)\n",
    "        m, s = images.mean([0,2,3]), images.std([0,2,3])\n",
    "        mean += num_img * m / total\n",
    "        std += np.sqrt(num_img/total) * s\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/pathmnist.npz\n",
      "pathmnist tensor([0.7405, 0.5330, 0.7058]) tensor([0.3920, 0.5636, 0.3959])\n",
      "Downloading https://zenodo.org/record/6496656/files/chestmnist.npz?download=1 to /Users/naomileow/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a4e26d9d65463885431a1112f1c12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82802576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestmnist tensor([0.4936]) tensor([0.7392])\n",
      "Downloading https://zenodo.org/record/6496656/files/dermamnist.npz?download=1 to /Users/naomileow/.medmnist/dermamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a9f387e2264897bdff7ae73a39c3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19725078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dermamnist tensor([0.7631, 0.5381, 0.5614]) tensor([0.1354, 0.1530, 0.1679])\n",
      "Downloading https://zenodo.org/record/6496656/files/octmnist.npz?download=1 to /Users/naomileow/.medmnist/octmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7097f8dabc6248908b4ff79621ca9174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54938180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "octmnist tensor([0.1889]) tensor([0.6606])\n",
      "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /Users/naomileow/.medmnist/pneumoniamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0ae89427524cf7806d3cbcd5289d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4170669 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pneumoniamnist tensor([0.5719]) tensor([0.1651])\n",
      "Downloading https://zenodo.org/record/6496656/files/retinamnist.npz?download=1 to /Users/naomileow/.medmnist/retinamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f60fc6b2d63460bb3a2196718b78112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3291041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retinamnist tensor([0.3984, 0.2447, 0.1558]) tensor([0.2952, 0.1970, 0.1470])\n",
      "Downloading https://zenodo.org/record/6496656/files/breastmnist.npz?download=1 to /Users/naomileow/.medmnist/breastmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e47eaa870494073b514256c59621848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/559580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breastmnist tensor([0.3276]) tensor([0.2027])\n",
      "Downloading https://zenodo.org/record/6496656/files/bloodmnist.npz?download=1 to /Users/naomileow/.medmnist/bloodmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b123ec2919ca4a54ba8645f6c203c062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35461855 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloodmnist tensor([0.7943, 0.6597, 0.6962]) tensor([0.2930, 0.3292, 0.1541])\n",
      "Downloading https://zenodo.org/record/6496656/files/tissuemnist.npz?download=1 to /Users/naomileow/.medmnist/tissuemnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f937abd55417400ca0f8ab5a41cc9cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124962739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissuemnist tensor([0.1020]) tensor([0.4443])\n",
      "Downloading https://zenodo.org/record/6496656/files/organamnist.npz?download=1 to /Users/naomileow/.medmnist/organamnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd87d128acb4dabae5ec87edc43dc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38247903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organamnist tensor([0.4678]) tensor([0.6105])\n",
      "Downloading https://zenodo.org/record/6496656/files/organcmnist.npz?download=1 to /Users/naomileow/.medmnist/organcmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91efcfa71b4f495a9e83122e8df95ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15527535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organcmnist tensor([0.4932]) tensor([0.3762])\n",
      "Downloading https://zenodo.org/record/6496656/files/organsmnist.npz?download=1 to /Users/naomileow/.medmnist/organsmnist.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a442275b7a495d81bd3d380182f0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16528536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organsmnist tensor([0.4950]) tensor([0.3779])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdecb9172087411d972fa4e036525a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32657407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_stds = {}\n",
    "\n",
    "for k in ['pathmnist', 'chestmnist', 'dermamnist', 'octmnist', 'pneumoniamnist', 'retinamnist', 'breastmnist', 'bloodmnist', 'tissuemnist', 'organamnist', 'organcmnist', 'organsmnist']:\n",
    "    mean, std = get_image_mean_std(k)\n",
    "    print(k, mean, std)\n",
    "    mean_stds[k] = {\n",
    "        'mean': mean,\n",
    "        'std': std\n",
    "    }\n",
    "print(mean_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import get_device\n",
    "from models.backbone.datasets import MEAN_STDS, DataSets\n",
    "from models.backbone.trainer import Trainer\n",
    "\n",
    "device = get_device()\n",
    "MODEL_SAVE_PATH = 'models/backbone/pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/retinamnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/retinamnist.npz\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch import nn\n",
    "\n",
    "retina_ds = DataSets('retinamnist', MEAN_STDS) # 5 classes\n",
    "backbone = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "backbone.fc = nn.Linear(2048, len(retina_ds.info['label']))\n",
    "\n",
    "batch_size = 256\n",
    "rtrainer = Trainer(backbone, retina_ds, batch_size, device, balance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrainer.run_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52, 0.7557038049792416, 1.3845270824432374)\n"
     ]
    }
   ],
   "source": [
    "print(rtrainer.run_eval(rtrainer.best_model, rtrainer.test_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# (0.5125, 0.7247683647010932, 1.464751205444336) for non pretrained, non balanced\n",
    "print(rtrainer.run_eval(rtrainer.best_model, rtrainer.test_loader)) \n",
    "\n",
    "torch.save(rtrainer.best_model.state_dict(), os.path.join(MODEL_SAVE_PATH, 'retina_backbone_pretrained_bal.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "# 'chestmnist', 'pneumoniamnist', 'octmnist',  'retinamnist'\n",
    "chest_ds = DataSets('chestmnist', MEAN_STDS)\n",
    "\n",
    "backbone = torchvision.models.resnet50(num_classes=len(chest_ds.info['label']), pretrained=False)\n",
    "# patch for single channel\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "batch_size = 128\n",
    "ctrainer = Trainer(backbone, chest_ds, batch_size, device)\n",
    "\n",
    "ctrainer.run_train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /Users/naomileow/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/cs6240/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# [7996,  1950,  9261, 13914,  3988,  4375,   978,  3705,  3263, 1690,  1799,  1158,  2279,   144]\n",
    "chest_ds = DataSets('chestmnist', mean_stds)\n",
    "\n",
    "backbone = torchvision.models.resnet50(num_classes=len(chest_ds.info['label']), weights=None)\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "backbone.load_state_dict(torch.load(os.path.join(MODEL_SAVE_PATH, 'cxr_backbone.pkl')))\n",
    "\n",
    "batch_size = 256\n",
    "ctrainer = Trainer(backbone, chest_ds, batch_size, device, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrainer.run_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9239799784755875, 0.6329840270919405, 0.7261211995067128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrainer.run_eval(ctrainer.model, ctrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save pretrained resnet from medclip\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from medclip import MedCLIPModel, MedCLIPVisionModel\n",
    "\n",
    "# load MedCLIP-ResNet50\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModel)\n",
    "model.from_pretrained()\n",
    "\n",
    "bconv_weight = model.vision_model.model.conv1.weight.mean(dim=1).unsqueeze(1)\n",
    "\n",
    "# The resnet model was trained on CheXpert and MIMIC-CXR\n",
    "backbone = model.vision_model.model\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "backbone.conv1.weight = nn.Parameter(bconv_weight)\n",
    "\n",
    "torch.save(backbone.state_dict(), 'medclip_resnet50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT, VINDR_SPLIT2\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "\n",
    "from utils.data import get_query_and_support_ids, DatasetConfig\n",
    "from utils.device import get_device\n",
    "from models.embedding.dataset import Dataset\n",
    "from utils.sampling import MultilabelBalancedRandomSampler\n",
    "\n",
    "configs = {\n",
    "    'vindr2': DatasetConfig('datasets/vindr-cxr-png', 'data/vindr_cxr_split_labels2.pkl', 'data/vindr_train_query_set2.pkl', VINDR_CXR_LABELS, VINDR_SPLIT2, MEAN_STDS['chestmnist'])\n",
    "}\n",
    "\n",
    "config = configs['vindr2']\n",
    "\n",
    "batch_size = 10*10\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(config.img_info, config.training_split_path)\n",
    "query_dataset = Dataset(config.img_path, config.img_info, query_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(config.img_path, config.img_info, support_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, sampler=MultilabelBalancedRandomSampler(support_dataset.get_class_indicators()))\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import os\n",
    "import torch\n",
    "from models.backbone.trainer import DSTrainer\n",
    "from utils.f1_loss import BalAccuracyLoss\n",
    "\n",
    "backbone = torchvision.models.resnet50(num_classes=len(config.classes_split_map['train']), weights=None)\n",
    "backbone.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "mtrainer = DSTrainer(backbone, query_dataset.class_labels(), criterion=BalAccuracyLoss(), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.17223548889160156\n",
      "Batch 2: loss 0.19263505935668945\n",
      "Batch 3: loss 0.18468862771987915\n",
      "Batch 4: loss 0.18475915491580963\n",
      "Batch 5: loss 0.18611371517181396\n",
      "Batch 6: loss 0.18989727894465128\n",
      "Batch 7: loss 0.18829831906727382\n",
      "Batch 8: loss 0.18453095853328705\n",
      "Batch 9: loss 0.18218632539113364\n",
      "Batch 10: loss 0.18041107058525085\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(9, support_loader, query_loader, lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.8178021907806396 | F1 0.3351583778858185 | AUC 0.602855014089035 | Specificity 0.7272143363952637 | Recall 0.4031338691711426 | Bal Acc 0.5651741027832031\n",
      "Loss 0.8040915727615356 | F1 0.32222121953964233 | AUC 0.5738897543349903 | Specificity 0.7176041603088379 | Recall 0.3890199661254883 | Bal Acc 0.5533120632171631\n",
      "Loss 0.8150610327720642 | F1 0.32819268107414246 | AUC 0.5927963819758275 | Specificity 0.685369610786438 | Recall 0.41243231296539307 | Bal Acc 0.5489009618759155\n",
      "Loss 0.8141124248504639 | F1 0.31385940313339233 | AUC 0.6090060357042646 | Specificity 0.7192613482475281 | Recall 0.3877924680709839 | Bal Acc 0.5535268783569336\n",
      "Loss 0.8236879706382751 | F1 0.3152325451374054 | AUC 0.5647615005108276 | Specificity 0.7081069946289062 | Recall 0.37620580196380615 | Bal Acc 0.5421563982963562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8149510383605957,\n",
       " tensor(0.3229, device='mps:0'),\n",
       " 0.588661737322989,\n",
       " 0.7115112900733948,\n",
       " 0.3937168836593628)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, query_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.7730595469474792 | F1 0.4065409302711487 | AUC 0.6377244623793866 | Specificity 0.6742991209030151 | Recall 0.5058967471122742 | Bal Acc 0.5900979042053223\n",
      "Loss 0.792277455329895 | F1 0.38331103324890137 | AUC 0.6266736220474719 | Specificity 0.6769896745681763 | Recall 0.5041444301605225 | Bal Acc 0.5905670523643494\n",
      "Loss 0.8309187889099121 | F1 0.3456721305847168 | AUC 0.6039829723119572 | Specificity 0.656503438949585 | Recall 0.47546499967575073 | Bal Acc 0.5659842491149902\n",
      "Loss 0.7993811368942261 | F1 0.3438308537006378 | AUC 0.5979420461276035 | Specificity 0.6408977508544922 | Recall 0.469146728515625 | Bal Acc 0.5550222396850586\n",
      "Loss 0.7731005549430847 | F1 0.3598782420158386 | AUC 0.6240732889015435 | Specificity 0.6538779735565186 | Recall 0.48356109857559204 | Bal Acc 0.5687195062637329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7937474966049194,\n",
       " tensor(0.3678, device='mps:0'),\n",
       " 0.6180792783535926,\n",
       " 0.6605135917663574,\n",
       " 0.48764280080795286)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, query_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model, 'models/backbone/pretrained/vindr2/trained-backbone-ba1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3af20c5b7ad2810593c71dd4ba5b7d473da7f58b181d32c1c7ac42846aa4b248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
