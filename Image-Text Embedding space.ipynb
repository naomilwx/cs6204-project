{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Image-Text embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT, VINDR_SPLIT2\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "\n",
    "from utils.data import get_query_and_support_ids, DatasetConfig\n",
    "from utils.device import get_device\n",
    "from models.embedding.dataset import Dataset\n",
    "from models.embedding.trainer import Trainer\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder, resnet_backbone, load_medclip_retrained_resnet\n",
    "from utils.sampling import MultilabelBalancedRandomSampler\n",
    "\n",
    "configs = {\n",
    "    'vindr1': DatasetConfig('datasets/vindr-cxr-png', 'data/vindr_cxr_split_labels.pkl', 'data/vindr_train_query_set.pkl', VINDR_CXR_LABELS, VINDR_SPLIT, MEAN_STDS['chestmnist']),\n",
    "    'vindr2': DatasetConfig('datasets/vindr-cxr-png', 'data/vindr_cxr_split_labels2.pkl', 'data/vindr_train_query_set2.pkl', VINDR_CXR_LABELS, VINDR_SPLIT2, MEAN_STDS['chestmnist'])\n",
    "}\n",
    "\n",
    "config = configs['vindr2']\n",
    "\n",
    "batch_size = 10*14\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(config.img_info, config.training_split_path)\n",
    "query_dataset = Dataset(config.img_path, config.img_info, query_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(config.img_path, config.img_info, support_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, sampler=MultilabelBalancedRandomSampler(support_dataset.get_class_indicators()))\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "device = get_device()\n",
    "# backbone = resnet_backbone(load_pretrained_resnet(1, 14, 'models/backbone/pretrained/cxr_backbone_bal.pkl'))\n",
    "# backbone = load_medclip_retrained_resnet('models/backbone/pretrained/medclip_resnet50.pkl')\n",
    "# model = ImageTextEmbedding(backbone, PROJ_SIZE, device=device)\n",
    "model = torch.load('models/embedding/model/vindr2/imgtext_model_trained.pth')\n",
    "# model = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.text_model.set_backbone_trainable(False)\n",
    "mtrainer.model.img_model.set_backbone_trainable(False)\n",
    "mtrainer.model.logit_scale.requires_grad = False\n",
    "\n",
    "mtrainer.model.img_model.set_backbone_layer_trainable(True, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 epochs: training projection + image encoder\n",
    "# 2 epochs: training projection\n",
    "# 1 epoch: training projection + image encoder\n",
    "\n",
    "# 2 epoch: projection + last image encoder layer \n",
    "mtrainer.run_train(2, support_loader, query_loader, lr=1e-6, min_lr=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 141.581787109375 | Accuracy 0.6071428571428571 | AUC 0.6692567693823752 | Specificity 0.618476927280426 | Recall 0.5859165787696838\n",
      "Loss 144.48428344726562 | Accuracy 0.6321428571428571 | AUC 0.6833994106105094 | Specificity 0.6308995485305786 | Recall 0.6337515711784363\n",
      "Loss 138.49468994140625 | Accuracy 0.6228571428571429 | AUC 0.6700765917360793 | Specificity 0.6043102741241455 | Recall 0.6448074579238892\n",
      "Loss 81.15347290039062 | Accuracy 0.60625 | AUC 0.6773642007916304 | Specificity 0.5987976789474487 | Recall 0.6153738498687744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6184,\n",
       " 0.6747434482107707,\n",
       " 131.86156860351562,\n",
       " 0.6148399186134338,\n",
       " 0.6205129861831665)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, query_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.model, 'models/embedding/model/vindr2/imgtext_model_trained1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import AverageMeter, calculate_auc, multilabel_logit_accuracy\n",
    "from torchmetrics.classification import MultilabelRecall, MultilabelSpecificity, MultilabelPrecision\n",
    "\n",
    "def run_eval(model, dataloader, device, class_labels):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_meter = AverageMeter()\n",
    "    auc_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "\n",
    "    specificity = MultilabelSpecificity(num_labels=len(class_labels)).to(device)\n",
    "    spec_meter = AverageMeter()\n",
    "    recall = MultilabelRecall(num_labels=len(class_labels)).to(device)\n",
    "    rec_meter = AverageMeter()\n",
    "    precision = MultilabelPrecision(num_labels=len(class_labels)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, class_inds in dataloader:\n",
    "            images, class_inds = images.to(device), class_inds.to(device)\n",
    "            text_embeddings, image_embeddings = model(class_labels, images, pool=True)\n",
    "\n",
    "            logits_per_text, logits_per_image = model.compute_logits(text_embeddings, image_embeddings)\n",
    "            loss = model.contrastive_logit_loss(logits_per_text, logits_per_image, class_inds)\n",
    "            loss_meter.update(loss.item(), len(class_inds))\n",
    "\n",
    "            auc = calculate_auc(logits_per_image, class_inds)\n",
    "            auc_meter.update(auc, len(class_inds))\n",
    "            \n",
    "            acc = multilabel_logit_accuracy(logits_per_image, class_inds)\n",
    "            acc_meter.update(acc, len(class_inds))\n",
    "\n",
    "            spec = specificity(logits_per_image, class_inds)\n",
    "            spec_meter.update(spec.item(), len(class_inds))\n",
    "            rec = recall(logits_per_image, class_inds)\n",
    "            rec_meter.update(rec.item(), len(class_inds))\n",
    "            prec = precision(logits_per_image, class_inds)\n",
    "            print(f\"Loss {loss} | Accuracy {acc} | AUC {auc} | Specificity {spec} | Recall {rec} | Precision {prec}\")\n",
    "            \n",
    "    return acc_meter.average(), auc_meter.average(), loss_meter.average(), spec_meter.average(), rec_meter.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 71.04728698730469 | Accuracy 0.4479591836734694 | AUC 0.5890015108344036 | Specificity 0.42932575941085815 | Recall 0.6371333003044128 | Precision 0.20914509892463684\n",
      "Loss 75.24569702148438 | Accuracy 0.4887755102040816 | AUC 0.6385256910915584 | Specificity 0.45598727464675903 | Recall 0.6956271529197693 | Precision 0.2463836818933487\n",
      "Loss 78.05477905273438 | Accuracy 0.4959183673469388 | AUC 0.5532589315705337 | Specificity 0.4835784435272217 | Recall 0.5971997380256653 | Precision 0.2374926656484604\n",
      "Loss 79.44345092773438 | Accuracy 0.4357142857142857 | AUC 0.5604148251867628 | Specificity 0.3963735103607178 | Recall 0.6791589856147766 | Precision 0.2589060366153717\n",
      "Loss 76.35698699951172 | Accuracy 0.4806122448979592 | AUC 0.5677557253138265 | Specificity 0.46071845293045044 | Recall 0.6279104351997375 | Precision 0.22663699090480804\n",
      "Loss 71.93860626220703 | Accuracy 0.4479591836734694 | AUC 0.5371337493866897 | Specificity 0.44221925735473633 | Recall 0.5372446775436401 | Precision 0.21629224717617035\n",
      "Loss 78.86904907226562 | Accuracy 0.4775510204081633 | AUC 0.59055082660361 | Specificity 0.4614863991737366 | Recall 0.6569918990135193 | Precision 0.2532520294189453\n",
      "Loss 78.97152709960938 | Accuracy 0.4785714285714286 | AUC 0.5626710923940828 | Specificity 0.4479121267795563 | Recall 0.6566358804702759 | Precision 0.23697103559970856\n",
      "Loss 76.49383544921875 | Accuracy 0.46122448979591835 | AUC 0.5294250063701518 | Specificity 0.4439699351787567 | Recall 0.6035584211349487 | Precision 0.22136756777763367\n",
      "Loss 70.54520416259766 | Accuracy 0.48775510204081635 | AUC 0.6072481915333754 | Specificity 0.45660674571990967 | Recall 0.7341479063034058 | Precision 0.2313462197780609\n",
      "Loss 60.71685028076172 | Accuracy 0.43956043956043955 | AUC 0.5567327797381078 | Specificity 0.4010055661201477 | Recall 0.6685415506362915 | Precision 0.22138066589832306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46784066296261423,\n",
       " 0.572297766822187,\n",
       " 74.54131226611908,\n",
       " 0.44420735527200766,\n",
       " 0.6445646255363661)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset(config.img_path, config.img_info, config.img_info[config.img_info['meta_split'] == 'test']['image_id'].to_list(), config.label_names_map, config.classes_split_map['test'], mean_std=config.mean_std)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "run_eval(mtrainer.model, test_loader, device, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 78.56269836425781 | Accuracy 0.49387755102040815 | AUC 0.5851240751768196 | Specificity 0.4700332283973694 | Recall 0.6316505670547485 | Precision 0.2542865574359894\n",
      "Loss 72.25923919677734 | Accuracy 0.49795918367346936 | AUC 0.6096031818152909 | Specificity 0.4781932234764099 | Recall 0.6903427839279175 | Precision 0.23942965269088745\n",
      "Loss 74.80560302734375 | Accuracy 0.49183673469387756 | AUC 0.6209842205929144 | Specificity 0.47085481882095337 | Recall 0.711128294467926 | Precision 0.23181715607643127\n",
      "Loss 72.50208282470703 | Accuracy 0.4387755102040816 | AUC 0.5273632507381782 | Specificity 0.41236233711242676 | Recall 0.5766076445579529 | Precision 0.2051064372062683\n",
      "Loss 73.56822967529297 | Accuracy 0.47551020408163264 | AUC 0.5694476210302147 | Specificity 0.4573631286621094 | Recall 0.6312494277954102 | Precision 0.22090637683868408\n",
      "Loss 74.90245056152344 | Accuracy 0.4785714285714286 | AUC 0.5932214505670862 | Specificity 0.4474429488182068 | Recall 0.6691378355026245 | Precision 0.2506188750267029\n",
      "Loss 77.90596008300781 | Accuracy 0.4928571428571429 | AUC 0.6119376547304782 | Specificity 0.48571765422821045 | Recall 0.6523458957672119 | Precision 0.25601544976234436\n",
      "Loss 77.04229736328125 | Accuracy 0.4530612244897959 | AUC 0.5264637981196669 | Specificity 0.4247087836265564 | Recall 0.5989472270011902 | Precision 0.2285483181476593\n",
      "Loss 74.80877685546875 | Accuracy 0.48775510204081635 | AUC 0.5820807532919193 | Specificity 0.4832354187965393 | Recall 0.5714284181594849 | Precision 0.21926727890968323\n",
      "Loss 77.53977966308594 | Accuracy 0.47551020408163264 | AUC 0.5262630471086392 | Specificity 0.46405914425849915 | Recall 0.5664602518081665 | Precision 0.21730323135852814\n",
      "Loss 62.28874588012695 | Accuracy 0.4053724053724054 | AUC 0.549110972159562 | Specificity 0.3583359122276306 | Recall 0.6932659149169922 | Precision 0.2262977659702301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4729258875600339,\n",
       " 0.573232993531073,\n",
       " 74.3792878932362,\n",
       " 0.45160263533174166,\n",
       " 0.6348146872058383)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval(mtrainer.best_model, test_loader, device, test_dataset.class_labels())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
