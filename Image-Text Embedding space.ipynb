{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from torch import nn\n",
    "# import torchvision\n",
    "\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder, resnet_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "from utils.device import get_device\n",
    "from models.embedding.dataset import Dataset\n",
    "from models.embedding.trainer import Trainer\n",
    "\n",
    "def get_query_and_support_ids(img_info, split_file):\n",
    "    with open(split_file, 'rb') as fp:\n",
    "        cxr_train_query = pickle.load(fp)\n",
    "    query_image_ids = []\n",
    "    for ids in cxr_train_query.values():\n",
    "        query_image_ids.extend(ids)\n",
    "    support_image_ids = img_info[(img_info['meta_split'] == 'train') & ~img_info['image_id'].isin(query_image_ids)]['image_id'].to_list()\n",
    "    return query_image_ids, support_image_ids\n",
    "\n",
    "img_info = pd.read_pickle('data/vindr_cxr_split_labels.pkl')\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(img_info, 'data/vindr_train_query_set.pkl')\n",
    "# support_image_ids = img_info[(img_info['meta_split'] == 'train') & ~img_info['image_id'].isin(query_image_ids)]['image_id'].to_list()\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "batch_size = 10*14\n",
    "query_dataset = Dataset(IMG_PATH, img_info, query_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(IMG_PATH, img_info, support_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "device = get_device()\n",
    "# backbone = resnet_backbone(load_pretrained_resnet(1, 14, 'models/backbone/pretrained/cxr_backbone_bal.pkl'))\n",
    "\n",
    "# backbone = load_medclip_retrained_resnet('models/backbone/pretrained/medclip_resnet50.pkl')\n",
    "# model = ImageTextEmbedding(backbone, PROJ_SIZE, device=device)\n",
    "model = torch.load('imgtext_model_trained.pth')\n",
    "\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.text_model.set_backbone_trainable(False)\n",
    "mtrainer.model.img_model.set_backbone_trainable(False)\n",
    "mtrainer.model.logit_scale.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 26.7219181060791\n",
      "Batch 2: loss 28.940580368041992\n",
      "Batch 3: loss 29.15361785888672\n",
      "Batch 4: loss 29.56848907470703\n",
      "Batch 5: loss 29.39850196838379\n",
      "Batch 6: loss 28.922122637430828\n",
      "Batch 7: loss 29.026561737060547\n",
      "Batch 8: loss 28.973043203353882\n",
      "Batch 9: loss 29.296273761325413\n",
      "Batch 10: loss 29.4564640045166\n",
      "Batch 11: loss 29.32164226878773\n",
      "Batch 12: loss 29.078742186228435\n",
      "Batch 13: loss 29.135898883526142\n",
      "Batch 14: loss 29.11204787663051\n",
      "Batch 15: loss 29.288188934326172\n",
      "Batch 16: loss 29.281124711036682\n",
      "Batch 17: loss 29.217458724975586\n",
      "Batch 18: loss 29.2834259668986\n",
      "Batch 19: loss 29.12468599018298\n",
      "Batch 20: loss 29.078123378753663\n",
      "Batch 21: loss 29.029097420828684\n",
      "Batch 22: loss 29.09607947956432\n",
      "Batch 23: loss 29.01464371059252\n",
      "Batch 24: loss 29.087071816126507\n",
      "Batch 25: loss 29.007728118896484\n",
      "Batch 26: loss 28.967255665705753\n",
      "Batch 27: loss 29.072203247635453\n",
      "Batch 28: loss 29.029563426971436\n",
      "Batch 29: loss 28.959361438093513\n",
      "Batch 30: loss 28.96729475657145\n",
      "Batch 31: loss 28.943711803805442\n",
      "Batch 32: loss 28.873181700706482\n",
      "Batch 33: loss 28.915524396029387\n",
      "Batch 34: loss 28.931419989641974\n",
      "Batch 35: loss 28.932901545933316\n",
      "Batch 36: loss 28.918627103169758\n",
      "Batch 37: loss 28.911905237146325\n",
      "Batch 38: loss 28.915052865680895\n",
      "Batch 39: loss 28.89605928078676\n",
      "Batch 40: loss 28.930750799179076\n",
      "Batch 41: loss 28.963243577538467\n",
      "Batch 42: loss 28.90980897630964\n",
      "Batch 43: loss 28.98522421371105\n",
      "Batch 44: loss 28.97472264549949\n",
      "Batch 45: loss 28.937395095825195\n",
      "Batch 46: loss 28.902300627335258\n",
      "Batch 47: loss 28.91132890417221\n",
      "Batch 48: loss 28.940134922663372\n",
      "Batch 49: loss 28.977303719034\n",
      "Batch 50: loss 29.014843406677247\n",
      "Batch 51: loss 29.03028387181899\n",
      "Batch 52: loss 29.043697393857517\n",
      "Batch 53: loss 29.050210017078328\n",
      "Batch 54: loss 29.047061849523473\n",
      "Batch 55: loss 29.034583594582298\n",
      "Batch 56: loss 29.141252279281616\n",
      "Batch 57: loss 29.223819230732165\n",
      "Batch 58: loss 29.265127247777478\n",
      "Batch 59: loss 29.313409514346365\n",
      "Batch 60: loss 29.28874333699544\n",
      "Batch 61: loss 29.25735523661629\n",
      "Batch 62: loss 29.285415864759877\n",
      "Batch 63: loss 29.283932398235986\n",
      "Batch 64: loss 29.311455130577087\n",
      "Batch 65: loss 29.37930691058819\n",
      "Batch 66: loss 29.383476344021883\n",
      "Batch 67: loss 29.364452589803665\n",
      "Batch 68: loss 29.36090654485366\n",
      "Batch 69: loss 29.344568086707074\n",
      "Batch 70: loss 29.374481664385115\n",
      "Batch 71: loss 29.341679425306722\n",
      "Batch 72: loss 29.314916584226822\n",
      "Batch 73: loss 29.281778361699352\n",
      "Batch 74: loss 29.27588656141951\n",
      "Batch 75: loss 29.26855349222819\n",
      "Batch 76: loss 29.27880176744963\n",
      "Batch 77: loss 29.2824686471518\n",
      "Batch 78: loss 29.272155663906\n",
      "Batch 79: loss 29.266809125489825\n",
      "Batch 80: loss 29.265460896492005\n",
      "Batch 81: loss 29.243199948911315\n",
      "Batch 82: loss 29.23090762626834\n",
      "Batch 83: loss 29.19414823601045\n",
      "Batch 84: loss 29.185901074182418\n",
      "Batch 85: loss 29.158186632044174\n",
      "Batch 86: loss 29.14493223678234\n",
      "Batch 87: loss 29.151740435896247\n",
      "Batch 88: loss 29.146949724717572\n",
      "Batch 89: loss 29.142778525191748\n",
      "Batch 90: loss 29.133544985453288\n",
      "Batch 91: loss 29.11404928270277\n",
      "Batch 92: loss 29.087826459304146\n",
      "Batch 93: loss 29.087732150990476\n",
      "Batch 94: loss 29.109370982393305\n",
      "Batch 95: loss 29.09071607087788\n",
      "Batch 96: loss 29.091794312000275\n",
      "Batch 97: loss 29.08101132972953\n",
      "Batch 98: loss 29.0673050588491\n",
      "Batch 99: loss 29.061897528291954\n",
      "Batch 100: loss 29.057633056640626\n",
      "Batch 101: loss 29.071987510907768\n",
      "Batch 102: loss 29.08310420840394\n",
      "Batch 103: loss 29.100103322742054\n",
      "Batch 104: loss 29.090899008970993\n",
      "Batch 105: loss 29.073274993896483\n",
      "Batch 106: loss 29.08602502211085\n",
      "Batch 107: loss 29.08712570689549\n",
      "Batch 108: loss 29.07537001150626\n",
      "Batch 109: loss 29.0410223019734\n",
      "Epoch 1: Training loss 29.0410223019734\n",
      "Epoch 1: Validation loss 141.12528381347656 | Accuracy 62.122448979591844 | AUC 0.8061291551740245\n",
      "Batch 1: loss 26.87771224975586\n",
      "Batch 2: loss 28.719149589538574\n",
      "Batch 3: loss 28.713687260945637\n",
      "Batch 4: loss 28.224205017089844\n",
      "Batch 5: loss 28.15775146484375\n",
      "Batch 6: loss 28.436545372009277\n",
      "Batch 7: loss 28.257232666015625\n",
      "Batch 8: loss 28.522857189178467\n",
      "Batch 9: loss 28.385325749715168\n",
      "Batch 10: loss 28.369228172302247\n",
      "Batch 11: loss 28.298389434814453\n",
      "Batch 12: loss 28.347332159678142\n",
      "Batch 13: loss 28.446110798762394\n",
      "Batch 14: loss 28.422945158822195\n",
      "Batch 15: loss 28.598125966389976\n",
      "Batch 16: loss 28.46247708797455\n",
      "Batch 17: loss 28.415223402135513\n",
      "Batch 18: loss 28.468358357747395\n",
      "Batch 19: loss 28.455202704981755\n",
      "Batch 20: loss 28.68247079849243\n",
      "Batch 21: loss 28.67082405090332\n",
      "Batch 22: loss 28.78612622347745\n",
      "Batch 23: loss 28.92144427092179\n",
      "Batch 24: loss 28.904805183410645\n",
      "Batch 25: loss 28.889975051879883\n",
      "Batch 26: loss 28.863799535311184\n",
      "Batch 27: loss 28.814989231250905\n",
      "Batch 28: loss 28.88190766743251\n",
      "Batch 29: loss 28.892222963530443\n",
      "Batch 30: loss 28.93440119425456\n",
      "Batch 31: loss 28.901209800474106\n",
      "Batch 32: loss 28.882690727710724\n",
      "Batch 33: loss 28.905187838005297\n",
      "Batch 34: loss 28.87028469758875\n",
      "Batch 35: loss 28.870805304391045\n",
      "Batch 36: loss 28.879535781012642\n",
      "Batch 37: loss 28.880104064941406\n",
      "Batch 38: loss 28.836447464792354\n",
      "Batch 39: loss 28.825459847083458\n",
      "Batch 40: loss 28.812939596176147\n",
      "Batch 41: loss 28.762968016833796\n",
      "Batch 42: loss 28.766203834896995\n",
      "Batch 43: loss 28.740402088608853\n",
      "Batch 44: loss 28.718977624719795\n",
      "Batch 45: loss 28.683438322279187\n",
      "Batch 46: loss 28.695720340894617\n",
      "Batch 47: loss 28.701282541802588\n",
      "Batch 48: loss 28.71358374754588\n",
      "Batch 49: loss 28.74700417810557\n",
      "Batch 50: loss 28.780411415100097\n",
      "Batch 51: loss 28.844987570070753\n",
      "Batch 52: loss 28.830467774317814\n",
      "Batch 53: loss 28.851111933870136\n",
      "Batch 54: loss 28.868630020706743\n",
      "Batch 55: loss 28.85544554970481\n",
      "Batch 56: loss 28.94495231764657\n",
      "Batch 57: loss 28.962481582373904\n",
      "Batch 58: loss 28.985529768055883\n",
      "Batch 59: loss 29.006235025696835\n",
      "Batch 60: loss 29.014911969502766\n",
      "Batch 61: loss 29.01104633143691\n",
      "Batch 62: loss 28.978434316573605\n",
      "Batch 63: loss 28.945952854459247\n",
      "Batch 64: loss 28.958203554153442\n",
      "Batch 65: loss 28.988819709190956\n",
      "Batch 66: loss 28.966309258432098\n",
      "Batch 67: loss 28.932635890903757\n",
      "Batch 68: loss 28.915724978727454\n",
      "Batch 69: loss 28.915497240812883\n",
      "Batch 70: loss 28.925279344831193\n",
      "Batch 71: loss 28.932497534953374\n",
      "Batch 72: loss 28.929222848680283\n",
      "Batch 73: loss 28.92718477118505\n",
      "Batch 74: loss 28.956250371159733\n",
      "Batch 75: loss 28.942314910888673\n",
      "Batch 76: loss 28.924788098586234\n",
      "Batch 77: loss 28.926609807200247\n",
      "Batch 78: loss 28.910184860229492\n",
      "Batch 79: loss 28.948009152955645\n",
      "Batch 80: loss 28.93668692111969\n",
      "Batch 81: loss 28.91114343242881\n",
      "Batch 82: loss 28.936780487618794\n",
      "Batch 83: loss 28.931880606226173\n",
      "Batch 84: loss 28.91234357016427\n",
      "Batch 85: loss 28.91950813742245\n",
      "Batch 86: loss 28.91609415897103\n",
      "Batch 87: loss 28.91921280170309\n",
      "Batch 88: loss 28.909505865790628\n",
      "Batch 89: loss 28.912743043363765\n",
      "Batch 90: loss 28.91040742662218\n",
      "Batch 91: loss 28.90872028895787\n",
      "Batch 92: loss 28.904965068982996\n",
      "Batch 93: loss 28.921401382774434\n",
      "Batch 94: loss 28.939198960649207\n",
      "Batch 95: loss 28.936871137117084\n",
      "Batch 96: loss 28.94404939810435\n",
      "Batch 97: loss 28.92442058287945\n",
      "Batch 98: loss 28.937461171831405\n",
      "Batch 99: loss 28.925746243409435\n",
      "Batch 100: loss 28.930483779907227\n",
      "Batch 101: loss 28.939683706453533\n",
      "Batch 102: loss 28.95052266588398\n",
      "Batch 103: loss 28.952558091543253\n",
      "Batch 104: loss 28.966403594383827\n",
      "Batch 105: loss 28.99337752205985\n",
      "Batch 106: loss 28.997414534946657\n",
      "Batch 107: loss 28.99279020434228\n",
      "Batch 108: loss 28.988713882587575\n",
      "Batch 109: loss 28.927479547207366\n",
      "Epoch 2: Training loss 28.927479547207366\n",
      "Epoch 2: Validation loss 140.79029846191406 | Accuracy 61.38775510204082 | AUC 0.8089979522189032\n",
      "Best epoch:  1\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(2, support_loader, query_loader, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.38775510204083, 0.8102664557552944, 140.3484375)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, query_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.31632653061224, 0.8074608790767269, 140.04942321777344)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, query_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model, 'imgtext_model_trained1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
