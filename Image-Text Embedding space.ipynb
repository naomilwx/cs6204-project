{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder, resnet_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "from utils.device import get_device\n",
    "from models.embedding.dataset import Dataset\n",
    "from models.embedding.trainer import Trainer\n",
    "\n",
    "def get_query_and_support_ids(img_info, split_file):\n",
    "    with open(split_file, 'rb') as fp:\n",
    "        cxr_train_query = pickle.load(fp)\n",
    "    query_image_ids = []\n",
    "    for ids in cxr_train_query.values():\n",
    "        query_image_ids.extend(ids)\n",
    "    support_image_ids = img_info[(img_info['meta_split'] == 'train') & ~img_info['image_id'].isin(query_image_ids)]['image_id'].to_list()\n",
    "    return query_image_ids, support_image_ids\n",
    "\n",
    "img_info = pd.read_pickle('data/vindr_cxr_split_labels.pkl')\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(img_info, 'data/vindr_train_query_set.pkl')\n",
    "# support_image_ids = img_info[(img_info['meta_split'] == 'train') & ~img_info['image_id'].isin(query_image_ids)]['image_id'].to_list()\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "batch_size = 10*14\n",
    "query_dataset = Dataset(IMG_PATH, img_info, query_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(IMG_PATH, img_info, support_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "device = get_device()\n",
    "# backbone = resnet_backbone(load_pretrained_resnet(1, 14, 'models/backbone/pretrained/cxr_backbone_bal.pkl'))\n",
    "\n",
    "# backbone = load_medclip_retrained_resnet('models/backbone/pretrained/medclip_resnet50.pkl')\n",
    "# model = ImageTextEmbedding(backbone, PROJ_SIZE, device=device)\n",
    "model = torch.load('imgtext_model_trained1-newlib.pth')\n",
    "\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.text_model.set_backbone_trainable(False)\n",
    "mtrainer.model.img_model.set_backbone_trainable(False)\n",
    "mtrainer.model.logit_scale.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 28.469074249267578\n",
      "Batch 2: loss 29.466032028198242\n",
      "Batch 3: loss 29.55094846089681\n",
      "Batch 4: loss 29.260549068450928\n",
      "Batch 5: loss 29.87935600280762\n",
      "Batch 6: loss 29.490957578023274\n",
      "Batch 7: loss 29.538506371634348\n",
      "Batch 8: loss 29.57067632675171\n",
      "Batch 9: loss 29.427893108791775\n",
      "Batch 10: loss 29.408737564086913\n",
      "Batch 11: loss 29.4022967598655\n",
      "Batch 12: loss 29.30565357208252\n",
      "Batch 13: loss 29.34943727346567\n",
      "Batch 14: loss 29.5397915158953\n",
      "Batch 15: loss 29.41028429667155\n",
      "Batch 16: loss 29.50651216506958\n",
      "Batch 17: loss 29.42297699872185\n",
      "Batch 18: loss 29.336332427130806\n",
      "Batch 19: loss 29.348928150377777\n",
      "Batch 20: loss 29.349716663360596\n",
      "Batch 21: loss 29.540258589245024\n",
      "Batch 22: loss 29.593233108520508\n",
      "Batch 23: loss 29.482493773750637\n",
      "Batch 24: loss 29.557597796122234\n",
      "Batch 25: loss 29.48684310913086\n",
      "Batch 26: loss 29.467873353224533\n",
      "Batch 27: loss 29.41236729092068\n",
      "Batch 28: loss 29.47128200531006\n",
      "Batch 29: loss 29.590852671656116\n",
      "Batch 30: loss 29.52819569905599\n",
      "Batch 31: loss 29.53061085362588\n",
      "Batch 32: loss 29.513982951641083\n",
      "Batch 33: loss 29.58920900749438\n",
      "Batch 34: loss 29.55735128066119\n",
      "Batch 35: loss 29.512568446568082\n",
      "Batch 36: loss 29.455695999993218\n",
      "Batch 37: loss 29.47962812475256\n",
      "Batch 38: loss 29.450803505746944\n",
      "Batch 39: loss 29.418253189478165\n",
      "Batch 40: loss 29.388663625717165\n",
      "Batch 41: loss 29.40337855641435\n",
      "Batch 42: loss 29.378703798566544\n",
      "Batch 43: loss 29.418759102045104\n",
      "Batch 44: loss 29.45686184276234\n",
      "Batch 45: loss 29.430644989013672\n",
      "Batch 46: loss 29.44656853053881\n",
      "Batch 47: loss 29.51489907122673\n",
      "Batch 48: loss 29.517258246739704\n",
      "Batch 49: loss 29.52747866572166\n",
      "Batch 50: loss 29.524087829589845\n",
      "Batch 51: loss 29.524080388686237\n",
      "Batch 52: loss 29.529293353740986\n",
      "Batch 53: loss 29.558007726129496\n",
      "Batch 54: loss 29.515082818490487\n",
      "Batch 55: loss 29.507449132745915\n",
      "Batch 56: loss 29.459832225527084\n",
      "Batch 57: loss 29.45190958391156\n",
      "Batch 58: loss 29.428477977884228\n",
      "Batch 59: loss 29.428721573393222\n",
      "Batch 60: loss 29.41401300430298\n",
      "Batch 61: loss 29.432693669053375\n",
      "Batch 62: loss 29.444555651757025\n",
      "Batch 63: loss 29.423358069525825\n",
      "Batch 64: loss 29.43837571144104\n",
      "Batch 65: loss 29.41337500352126\n",
      "Batch 66: loss 29.424124457619406\n",
      "Batch 67: loss 29.441924365598766\n",
      "Batch 68: loss 29.50865307976218\n",
      "Batch 69: loss 29.521787367005278\n",
      "Batch 70: loss 29.57649745941162\n",
      "Batch 71: loss 29.540884582089706\n",
      "Batch 72: loss 29.56260323524475\n",
      "Batch 73: loss 29.53711026335416\n",
      "Batch 74: loss 29.49510396493448\n",
      "Batch 75: loss 29.516604385375977\n",
      "Batch 76: loss 29.49239494926051\n",
      "Batch 77: loss 29.46139144897461\n",
      "Batch 78: loss 29.446987812335674\n",
      "Batch 79: loss 29.44004433064521\n",
      "Batch 80: loss 29.468228888511657\n",
      "Batch 81: loss 29.45549319702902\n",
      "Batch 82: loss 29.469973238503062\n",
      "Batch 83: loss 29.48500587279538\n",
      "Batch 84: loss 29.505258764539445\n",
      "Batch 85: loss 29.496224526798024\n",
      "Batch 86: loss 29.47424988413966\n",
      "Batch 87: loss 29.456257962632453\n",
      "Batch 88: loss 29.45157183300365\n",
      "Batch 89: loss 29.46996551685119\n",
      "Batch 90: loss 29.488493135240343\n",
      "Batch 91: loss 29.47673443385533\n",
      "Batch 92: loss 29.487818738688592\n",
      "Batch 93: loss 29.47987788210633\n",
      "Batch 94: loss 29.451224103887032\n",
      "Batch 95: loss 29.47764111569053\n",
      "Batch 96: loss 29.45849112669627\n",
      "Batch 97: loss 29.455849637690278\n",
      "Batch 98: loss 29.4489573459236\n",
      "Batch 99: loss 29.47546203690346\n",
      "Batch 100: loss 29.487498378753664\n",
      "Batch 101: loss 29.483689260954904\n",
      "Batch 102: loss 29.515566545374252\n",
      "Batch 103: loss 29.539213754598375\n",
      "Batch 104: loss 29.556762823691734\n",
      "Batch 105: loss 29.585136032104494\n",
      "Batch 106: loss 29.579199089194244\n",
      "Batch 107: loss 29.579992401265653\n",
      "Batch 108: loss 29.560314072502983\n",
      "Batch 109: loss 29.487292935124522\n",
      "Epoch 1: Training loss 29.487292935124522\n",
      "Epoch 1: Validation loss 133.71139526367188 | Accuracy 54.37755102040817 | AUC 0.8127198749261957\n",
      "Batch 1: loss 28.002763748168945\n",
      "Batch 2: loss 27.84455108642578\n",
      "Batch 3: loss 28.65243911743164\n",
      "Batch 4: loss 28.78474760055542\n",
      "Batch 5: loss 28.857929992675782\n",
      "Batch 6: loss 29.224167505900066\n",
      "Batch 7: loss 29.038810185023717\n",
      "Batch 8: loss 29.16780424118042\n",
      "Batch 9: loss 29.029143651326496\n",
      "Batch 10: loss 28.96305446624756\n",
      "Batch 11: loss 29.15856205333363\n",
      "Batch 12: loss 29.09791358311971\n",
      "Batch 13: loss 29.00269655080942\n",
      "Batch 14: loss 28.82273074558803\n",
      "Batch 15: loss 28.88460922241211\n",
      "Batch 16: loss 28.87139630317688\n",
      "Batch 17: loss 29.007045970243567\n",
      "Batch 18: loss 28.914722548590767\n",
      "Batch 19: loss 29.002106716758327\n",
      "Batch 20: loss 29.12572832107544\n",
      "Batch 21: loss 29.072829746064684\n",
      "Batch 22: loss 29.029336149042305\n",
      "Batch 23: loss 29.135442402051844\n",
      "Batch 24: loss 29.258474747339886\n",
      "Batch 25: loss 29.43055076599121\n",
      "Batch 26: loss 29.423921438363884\n",
      "Batch 27: loss 29.427879969278973\n",
      "Batch 28: loss 29.45731292452131\n",
      "Batch 29: loss 29.442251731609478\n",
      "Batch 30: loss 29.408577728271485\n",
      "Batch 31: loss 29.329184993620842\n",
      "Batch 32: loss 29.317033648490906\n",
      "Batch 33: loss 29.31295296640107\n",
      "Batch 34: loss 29.398985526140997\n",
      "Batch 35: loss 29.36220763070243\n",
      "Batch 36: loss 29.430252657996284\n",
      "Batch 37: loss 29.361715522972315\n",
      "Batch 38: loss 29.333473506726715\n",
      "Batch 39: loss 29.346214587871845\n",
      "Batch 40: loss 29.367958545684814\n",
      "Batch 41: loss 29.354832719012006\n",
      "Batch 42: loss 29.377440452575684\n",
      "Batch 43: loss 29.36797288406727\n",
      "Batch 44: loss 29.37452034516768\n",
      "Batch 45: loss 29.347844568888345\n",
      "Batch 46: loss 29.317566249681555\n",
      "Batch 47: loss 29.273750467503323\n",
      "Batch 48: loss 29.28532036145528\n",
      "Batch 49: loss 29.296372433097996\n",
      "Batch 50: loss 29.312636909484862\n",
      "Batch 51: loss 29.36404426425111\n",
      "Batch 52: loss 29.32174356167133\n",
      "Batch 53: loss 29.377585465053343\n",
      "Batch 54: loss 29.44824723844175\n",
      "Batch 55: loss 29.40472308072177\n",
      "Batch 56: loss 29.387261867523193\n",
      "Batch 57: loss 29.399133782637747\n",
      "Batch 58: loss 29.401183128356934\n",
      "Batch 59: loss 29.35480874271716\n",
      "Batch 60: loss 29.351185862223307\n",
      "Batch 61: loss 29.334710011716748\n",
      "Batch 62: loss 29.33798805359871\n",
      "Batch 63: loss 29.36954701136029\n",
      "Batch 64: loss 29.355880320072174\n",
      "Batch 65: loss 29.327438295804537\n",
      "Batch 66: loss 29.344974344426934\n",
      "Batch 67: loss 29.343134837364083\n",
      "Batch 68: loss 29.36030455196605\n",
      "Batch 69: loss 29.38341071640236\n",
      "Batch 70: loss 29.37179445539202\n",
      "Batch 71: loss 29.37763893772179\n",
      "Batch 72: loss 29.39811420440674\n",
      "Batch 73: loss 29.386856105229626\n",
      "Batch 74: loss 29.388557176332217\n",
      "Batch 75: loss 29.382100041707357\n",
      "Batch 76: loss 29.34588010687577\n",
      "Batch 77: loss 29.402225643009334\n",
      "Batch 78: loss 29.401783576378456\n",
      "Batch 79: loss 29.42949280557753\n",
      "Batch 80: loss 29.478208160400392\n",
      "Batch 81: loss 29.480168684029284\n",
      "Batch 82: loss 29.504436097493986\n",
      "Batch 83: loss 29.469694045652826\n",
      "Batch 84: loss 29.52574196315947\n",
      "Batch 85: loss 29.563658882589902\n",
      "Batch 86: loss 29.552154740621877\n",
      "Batch 87: loss 29.55785729419226\n",
      "Batch 88: loss 29.5552800135179\n",
      "Batch 89: loss 29.573609512843444\n",
      "Batch 90: loss 29.567397816975912\n",
      "Batch 91: loss 29.5575872358385\n",
      "Batch 92: loss 29.56688688112342\n",
      "Batch 93: loss 29.592483212870935\n",
      "Batch 94: loss 29.602798867732922\n",
      "Batch 95: loss 29.599957837556538\n",
      "Batch 96: loss 29.593784749507904\n",
      "Batch 97: loss 29.607554091620692\n",
      "Batch 98: loss 29.575028497345592\n",
      "Batch 99: loss 29.58377379600448\n",
      "Batch 100: loss 29.56811580657959\n",
      "Batch 101: loss 29.57921347287622\n",
      "Batch 102: loss 29.587320365157783\n",
      "Batch 103: loss 29.565261377871614\n",
      "Batch 104: loss 29.549634566673866\n",
      "Batch 105: loss 29.51612817673456\n",
      "Batch 106: loss 29.5229821475047\n",
      "Batch 107: loss 29.52572917046948\n",
      "Batch 108: loss 29.522993440981264\n",
      "Batch 109: loss 29.454297357727132\n",
      "Epoch 2: Training loss 29.454297357727132\n",
      "Epoch 2: Validation loss 133.39806518554687 | Accuracy 53.08163265306122 | AUC 0.8123094646826654\n",
      "Best epoch:  1\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(2, support_loader, query_loader, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54.377551020408156, 0.8127540973974094, 133.65570678710938)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, query_loader)\n",
    "# (62.38775510204083, 0.8102664557552944, 140.3484375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.31632653061224, 0.8074608790767269, 140.04942321777344)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, query_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model, 'imgtext_model_trained1-newlib.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
