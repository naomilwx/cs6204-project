{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.attention.trainer import Trainer\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.device import get_device\n",
    "from utils.data import get_query_and_support_ids\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "from models.embedding.dataset import Dataset\n",
    "from utils.sampling import MultilabelBalancedRandomSampler\n",
    "\n",
    "img_info = pd.read_pickle('data/vindr_cxr_split_labels.pkl')\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(img_info, 'data/vindr_train_query_set.pkl')\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "batch_size = 10*14\n",
    "\n",
    "query_dataset = Dataset(IMG_PATH, img_info, query_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(IMG_PATH, img_info, support_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, sampler=MultilabelBalancedRandomSampler(support_dataset.get_class_indicators()))\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "# device = 'cpu'\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "model = LabelImagePrototypeModel(encoder, 8, PROJ_SIZE, num_layers=2)\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "mtrainer.run_train(2, support_loader, query_loader, lr=2e-5, full_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, query_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.82653061224491, 0.9992765783681979, 14.54466733932495)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, query_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.model.attention, 'attention-model8h2l.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
