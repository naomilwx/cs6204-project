{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel, LabelImageMHAttention\n",
    "from models.attention.trainer import Trainer\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.data import get_query_and_support_ids, DatasetConfig\n",
    "from utils.device import get_device\n",
    "from utils.data import get_query_and_support_ids\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT, VINDR_SPLIT2\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "from models.embedding.dataset import Dataset\n",
    "from utils.sampling import MultilabelBalancedRandomSampler\n",
    "from utils.f1_loss import BalAccuracyLoss\n",
    "\n",
    "\n",
    "configs = {\n",
    "    'vindr1': DatasetConfig('datasets/vindr-cxr-png', 'data/vindr_cxr_split_labels.pkl', 'data/vindr_train_query_set.pkl', VINDR_CXR_LABELS, VINDR_SPLIT, MEAN_STDS['chestmnist']),\n",
    "    'vindr2': DatasetConfig('datasets/vindr-cxr-png', 'data/vindr_cxr_split_labels2.pkl', 'data/vindr_train_query_set2.pkl', VINDR_CXR_LABELS, VINDR_SPLIT2, MEAN_STDS['chestmnist'])\n",
    "}\n",
    "\n",
    "config = configs['vindr2']\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "batch_size = 10*14\n",
    "\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(config.img_info, config.training_split_path)\n",
    "query_dataset = Dataset(config.img_path, config.img_info, query_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "query_loader = DataLoader(dataset=query_dataset, batch_size=batch_size, shuffle=True)\n",
    "support_dataset = Dataset(config.img_path, config.img_info, support_image_ids, config.label_names_map, config.classes_split_map['train'], mean_std=config.mean_std)\n",
    "support_loader = DataLoader(dataset=support_dataset, batch_size=batch_size, sampler=MultilabelBalancedRandomSampler(support_dataset.get_class_indicators()))\n",
    "\n",
    "\n",
    "PROJ_SIZE = 512\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr2/imgtext_model_trained1.pth')\n",
    "encoder.text_model.device = device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = LabelImageMHAttention(PROJ_SIZE, 8, cls_weight=1, cls_loss=BalAccuracyLoss(), device=device)\n",
    "# attn_model = torch.load('models/attention/model/vindr2/attention-8h.pth')\n",
    "model = LabelImagePrototypeModel(encoder, 8, PROJ_SIZE, attn_model=attn_model)\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LabelImagePrototypeModel(encoder, 8, PROJ_SIZE, num_layers=4, cls_weight=5, cls_loss=BalAccuracyLoss())\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)\n",
    "\n",
    "mtrainer.run_train(10, support_loader, query_loader, lr=2e-5, lr=1e-4, min_lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = torch.load('models/attention/model/vindr2/attention-model8h4l.pth')\n",
    "model = LabelImagePrototypeModel(encoder, 8, PROJ_SIZE, attn_model=attn_model)\n",
    "mtrainer = Trainer(model, support_dataset.class_labels(), device)\n",
    "\n",
    "mtrainer.run_train(10, support_loader, query_loader, lr=2e-5, encoder_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.best_loss = 8.106417350769043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# mtrainer.run_train(6, support_loader, query_loader, lr=2e-5, full_training=True)\n",
    "# mtrainer.run_train(10, support_loader, query_loader, lr=2e-5)\n",
    "mtrainer.run_train(10, support_loader, query_loader, lr=1e-4, min_lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.attention, 'models/attention/model/vindr2/attention-8h.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.attention, 'models/attention/model/vindr2/attention-model8h.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.model.attention, 'models/attention/model/vindr2/full-mh/attention-model8h.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.model.encoder, 'models/attention/model/vindr2/full-mh/imgtxt-encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import AverageMeter, calculate_auc, multilabel_logit_accuracy\n",
    "from torchmetrics.classification import MultilabelRecall, MultilabelSpecificity, MultilabelPrecision, MultilabelF1Score\n",
    "from models.attention.model import image_text_logits\n",
    "\n",
    "def run_eval(model, dataloader, device, class_labels):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    auc_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    spec_meter = AverageMeter()\n",
    "    rec_meter = AverageMeter()\n",
    "    f1_meter = AverageMeter()\n",
    "\n",
    "    num_labels = len(class_labels)\n",
    "    specificity = MultilabelSpecificity(num_labels=num_labels).to(device)\n",
    "    recall = MultilabelRecall(num_labels=num_labels).to(device)\n",
    "    precision = MultilabelPrecision(num_labels=num_labels).to(device)\n",
    "    f1_func = MultilabelF1Score(num_labels=num_labels).to(device)\n",
    "    with torch.no_grad():\n",
    "         for images, class_inds in dataloader:\n",
    "                images, class_inds = images.to(device), class_inds.to(device)\n",
    "\n",
    "                text_embeddings, _, prototypes = model(class_labels, images)\n",
    "\n",
    "                logits_per_image = image_text_logits(text_embeddings, prototypes, model.encoder.get_logit_scale())\n",
    "                \n",
    "                f1 = f1_func(logits_per_image, class_inds)\n",
    "                f1_meter.update(f1.item(), len(class_inds))\n",
    "\n",
    "                auc = calculate_auc(logits_per_image, class_inds)\n",
    "                auc_meter.update(auc, len(class_inds))\n",
    "            \n",
    "                acc = multilabel_logit_accuracy(logits_per_image, class_inds)\n",
    "                acc_meter.update(acc, len(class_inds))\n",
    "\n",
    "                spec = specificity(logits_per_image, class_inds)\n",
    "                spec_meter.update(spec.item(), len(class_inds))\n",
    "                rec = recall(logits_per_image, class_inds)\n",
    "                rec_meter.update(rec.item(), len(class_inds))\n",
    "                prec = precision(logits_per_image, class_inds)\n",
    "                print(f\"F1 {f1} | Accuracy {acc} | AUC {auc} | Specificity {spec} | Recall {rec} | Precision {prec}\")\n",
    "            \n",
    "    return f1_meter.average(), acc_meter.average(), auc_meter.average(), spec_meter.average(), rec_meter.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.28933292627334595 | Accuracy 0.42653061224489797 | AUC 0.5012760106407754 | Specificity 0.34877878427505493 | Recall 0.6482062339782715 | Precision 0.2067118138074875\n",
      "F1 0.28000032901763916 | Accuracy 0.45 | AUC 0.5244511868726545 | Specificity 0.39517742395401 | Recall 0.6888952255249023 | Precision 0.2086719423532486\n",
      "F1 0.28447121381759644 | Accuracy 0.45 | AUC 0.5205382476454347 | Specificity 0.4083195924758911 | Recall 0.5929675698280334 | Precision 0.20806168019771576\n",
      "F1 0.29833951592445374 | Accuracy 0.47653061224489796 | AUC 0.5744529014172269 | Specificity 0.4363011419773102 | Recall 0.6751984357833862 | Precision 0.2179604172706604\n",
      "F1 0.28733593225479126 | Accuracy 0.47244897959183674 | AUC 0.5298072579951354 | Specificity 0.4340851306915283 | Recall 0.5941333174705505 | Precision 0.2122020423412323\n",
      "F1 0.31361648440361023 | Accuracy 0.47551020408163264 | AUC 0.5771737606285515 | Specificity 0.41940829157829285 | Recall 0.7063462734222412 | Precision 0.22470252215862274\n",
      "F1 0.2933703362941742 | Accuracy 0.47959183673469385 | AUC 0.5326843885165832 | Specificity 0.43574878573417664 | Recall 0.5903514623641968 | Precision 0.2145860493183136\n",
      "F1 0.28064924478530884 | Accuracy 0.46530612244897956 | AUC 0.521636340612371 | Specificity 0.4244951009750366 | Recall 0.5778109431266785 | Precision 0.20746544003486633\n",
      "F1 0.27894946932792664 | Accuracy 0.47244897959183674 | AUC 0.554312950322107 | Specificity 0.4400014877319336 | Recall 0.620962381362915 | Precision 0.20798859000205994\n",
      "F1 0.2926637828350067 | Accuracy 0.4683673469387755 | AUC 0.5376461707533592 | Specificity 0.42896217107772827 | Recall 0.6293912529945374 | Precision 0.20753693580627441\n",
      "F1 0.27982789278030396 | Accuracy 0.4822954822954823 | AUC 0.5339745006359913 | Specificity 0.4545108377933502 | Recall 0.6160205006599426 | Precision 0.2095937728881836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28909819139488135,\n",
       " 0.46510970901214793,\n",
       " 0.5371338871001969,\n",
       " 0.4200109924111778,\n",
       " 0.6311609967020522)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset(config.img_path, config.img_info, config.img_info[config.img_info['meta_split'] == 'test']['image_id'].to_list(), config.label_names_map, config.classes_split_map['test'], mean_std=config.mean_std)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "run_eval(mtrainer.model, test_loader, device, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.283608078956604 | Accuracy 0.5510204081632653 | AUC 0.5591138550574418 | Specificity 0.5776880979537964 | Recall 0.5120512247085571 | Precision 0.24715235829353333\n",
      "F1 0.3002997934818268 | Accuracy 0.5489795918367347 | AUC 0.6044194470160384 | Specificity 0.5632289052009583 | Recall 0.59834223985672 | Precision 0.24182595312595367\n",
      "F1 0.2862740457057953 | Accuracy 0.5163265306122449 | AUC 0.5949728348230874 | Specificity 0.5229647159576416 | Recall 0.6066675782203674 | Precision 0.23028656840324402\n",
      "F1 0.3166683316230774 | Accuracy 0.5683673469387756 | AUC 0.580749794828874 | Specificity 0.5908064246177673 | Recall 0.5454789400100708 | Precision 0.26926490664482117\n",
      "F1 0.24924519658088684 | Accuracy 0.5275510204081633 | AUC 0.4699966260166683 | Specificity 0.5696976184844971 | Recall 0.3806300759315491 | Precision 0.21931084990501404\n",
      "F1 0.2658153176307678 | Accuracy 0.5285714285714286 | AUC 0.5439945277405026 | Specificity 0.5573750138282776 | Recall 0.4719454348087311 | Precision 0.23520803451538086\n",
      "F1 0.24619382619857788 | Accuracy 0.5204081632653061 | AUC 0.5168676830295571 | Specificity 0.5529254674911499 | Recall 0.4247581958770752 | Precision 0.20966966450214386\n",
      "F1 0.3062472939491272 | Accuracy 0.5530612244897959 | AUC 0.5794352635030157 | Specificity 0.5586888790130615 | Recall 0.5774807929992676 | Precision 0.24152639508247375\n",
      "F1 0.2939085364341736 | Accuracy 0.560204081632653 | AUC 0.5924554139799719 | Specificity 0.5769210457801819 | Recall 0.5578364133834839 | Precision 0.23814643919467926\n",
      "F1 0.30255451798439026 | Accuracy 0.5102040816326531 | AUC 0.5496925137200426 | Specificity 0.5013461709022522 | Recall 0.5441245436668396 | Precision 0.23692253232002258\n",
      "F1 0.2807418704032898 | Accuracy 0.5372405372405372 | AUC 0.5324785194372665 | Specificity 0.5560652613639832 | Recall 0.5174108743667603 | Precision 0.23803174495697021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28474679646243684,\n",
       " 0.5383746115453434,\n",
       " 0.5571112070759975,\n",
       " 0.557079474668245,\n",
       " 0.5215828832074381)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval(mtrainer.model, test_loader, device, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.5260613560676575 | Accuracy 0.58 | AUC 0.6544703604938192 | Specificity 0.5661594867706299 | Recall 0.6639364957809448 | Precision 0.4823448956012726\n",
      "F1 0.4983893930912018 | Accuracy 0.5385714285714286 | AUC 0.6108061858041806 | Specificity 0.49644139409065247 | Recall 0.6740500330924988 | Precision 0.45193716883659363\n",
      "F1 0.5306516885757446 | Accuracy 0.5778571428571428 | AUC 0.6377309784179848 | Specificity 0.5418899059295654 | Recall 0.6695412993431091 | Precision 0.48143211007118225\n",
      "F1 0.527908205986023 | Accuracy 0.5475 | AUC 0.6262019690082068 | Specificity 0.4911428987979889 | Recall 0.682529091835022 | Precision 0.48489272594451904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5198939955234527,\n",
       " 0.5626,\n",
       " 0.6330344219617888,\n",
       " 0.5278402841091157,\n",
       " 0.6713124465942383)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval(mtrainer.model, query_loader, device, query_dataset.class_labels())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
