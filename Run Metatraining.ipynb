{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from abc import abstractmethod\n",
    "# from models.metaclassifier.base import MetaModelBase\n",
    "\n",
    "class MetaModelBase(nn.Module):\n",
    "    def __init__(self, imgtxt_encoder, class_prototype_aggregator):\n",
    "        super().__init__()\n",
    "        self.encoder = imgtxt_encoder\n",
    "        self.class_prototype_aggregator = class_prototype_aggregator\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def set_class_prototype_details(self, class_labels, support_images, support_label_inds):\n",
    "        image_embeddings = self.encoder.embed_image(support_images, pool=True) # (B, D)\n",
    "        image_embeddings = image_embeddings.unsqueeze(1).expand(-1, support_label_inds.shape[1], -1)\n",
    "\n",
    "        self.class_prototypes = self.class_prototype_aggregator(image_embeddings, support_label_inds)\n",
    "    \n",
    "    def update_support_and_classify(self, class_labels, support_images, support_label_inds, query_images):\n",
    "        self.set_class_prototype_details(class_labels, support_images, support_label_inds)\n",
    "        return self.forward(query_images)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, query_images):\n",
    "        return query_images\n",
    "    \n",
    "    def loss(self, predictions, label_inds):\n",
    "        return self.loss_fn(predictions, label_inds.float())\n",
    "\n",
    "\n",
    "class ProtoNet(MetaModelBase):\n",
    "    def __init__(self, imgtxt_encoder, class_prototype_aggregator, distance_func, scale=1.0, trainable_base=True):\n",
    "        super(ProtoNet, self).__init__(imgtxt_encoder, class_prototype_aggregator)\n",
    "        self.distance_func = distance_func\n",
    "        self.scale = nn.Parameter(torch.tensor(scale))\n",
    "        self.set_trainable(trainable_base, trainable_base, include_text_bb=False, include_logit_scale=False)\n",
    "    \n",
    "    def set_trainable(self, trainable):\n",
    "        self.encoder.set_trainable(trainable, trainable, include_text_bb=False, include_logit_scale=False)\n",
    "\n",
    "    def forward(self, query_images):\n",
    "        query_image_embeddings = self.encoder.embed_image(query_images, pool=True)\n",
    "        query_image_embeddings = query_image_embeddings.unsqueeze(1).expand(-1, self.class_prototypes.shape[0], -1)\n",
    "        return -self.distance_func(self.class_prototypes, query_image_embeddings) * self.scale\n",
    "    \n",
    "class RelationNet(MetaModelBase):\n",
    "    def __init__(self, imgtxt_encoder, embed_dim, class_prototype_aggregator, fc_hidden_size=16, activation=nn.ReLU, dropout=0.3):\n",
    "        super(RelationNet, self).__init__(imgtxt_encoder, class_prototype_aggregator)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(embed_dim*2, fc_hidden_size),\n",
    "            activation(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fc_hidden_size, 1)\n",
    "        )\n",
    "        self.encoder.set_trainable(False, False)\n",
    "\n",
    "    def forward(self, query_images):\n",
    "        query_image_embeddings = self.encoder.embed_image(query_images, pool=True)\n",
    "        query_image_embeddings = query_image_embeddings.unsqueeze(1).expand(-1, self.class_prototypes.shape[0], -1)\n",
    "        class_prototypes = self.class_prototypes.repeat(query_image_embeddings.shape[0], 1, 1)\n",
    "       \n",
    "        out = self.cls(torch.cat((class_prototypes, query_image_embeddings), dim=2))\n",
    "        return out.squeeze(2) # NxLx1 -> NxL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from utils.device import get_device\n",
    "from utils.data import get_query_and_support_ids\n",
    "from utils.sampling import FewShotBatchSampler\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "from models.embedding.dataset import Dataset\n",
    "\n",
    "img_info = pd.read_pickle('data/vindr_cxr_split_labels.pkl')\n",
    "query_image_ids, support_image_ids = get_query_and_support_ids(img_info, 'data/vindr_train_query_set.pkl')\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "\n",
    "def meta_training_loader(dataset, shots, n_ways=None, include_query=False):\n",
    "    return DataLoader(dataset, batch_sampler=FewShotBatchSampler(dataset.get_class_indicators(), shots, n_ways=n_ways, include_query=include_query))\n",
    "\n",
    "def meta_training_dataset(img_info, split):\n",
    "    img_ids = img_info[img_info['meta_split'] == split]['image_id'].to_list()\n",
    "    return Dataset(IMG_PATH, img_info, img_ids, VINDR_CXR_LABELS, VINDR_SPLIT[split], mean_std=MEAN_STDS['chestmnist'])\n",
    "\n",
    "num_shots = 5\n",
    "train_query_dataset = Dataset(IMG_PATH, img_info, query_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "train_query_loader = meta_training_loader(train_query_dataset, num_shots)\n",
    "train_support_dataset = Dataset(IMG_PATH, img_info, support_image_ids, VINDR_CXR_LABELS, VINDR_SPLIT['train'], mean_std=MEAN_STDS['chestmnist'])\n",
    "train_support_loader = meta_training_loader(train_support_dataset, num_shots)\n",
    "\n",
    "val_dataset = meta_training_dataset(img_info, 'val')\n",
    "val_loader = meta_training_loader(val_dataset, num_shots, include_query=True)\n",
    "\n",
    "test_dataset = meta_training_dataset(img_info, 'test')\n",
    "test_loader = meta_training_loader(test_dataset, num_shots, include_query=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with attention\n",
    "### Run experiments on proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import MetaTrainer\n",
    "from models.metaclassifier.model import ClsModel\n",
    "\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/attention-model-16h4l.pth')\n",
    "model = ClsModel(encoder, attention, 512, class_prototype_inf, fc_hidden_size=64)\n",
    "mtrainer = MetaTrainer(model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, test_loader, test_dataset.class_labels())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(model, val_loader, val_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model seems to have a tendency to overfit, improving performance on training seems to quickly lead to a degradation for test and val\n",
    "mtrainer.run_train(4, train_query_loader, train_support_loader, val_loader,  train_query_dataset.class_labels(), val_dataset.class_labels(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.48688046647233, 0.5369015346066683, 0.6640473263604301)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, val_loader, val_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.64310602289699, 0.5174087630955708, 0.6670199937936736)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, test_loader, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.cls.state_dict(), 'models/metaclassifier/model/comb1/cls_weights-64.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import MetaTrainer\n",
    "from models.metaclassifier.model import ProtoNetAttention\n",
    "\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/attention-model-8h4l.pth')\n",
    "# imgtxt_encoder, attn_model, class_prototype_aggregator, distance_func\n",
    "model = ProtoNetAttention(encoder, attention, class_prototype_inf, euclidean_distance)\n",
    "mtrainer = MetaTrainer(model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naomileow/Documents/school/CS6240/project/utils/prototype.py:55: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  classes_count = torch.nonzero(label_inds)[:,1].bincount()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80.39820806371328, 0.5402599822857049, 0.6664394343771586)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(model, test_loader, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.37026239067053, 0.5161583489962621, 0.6703500832830157)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(model, val_loader, val_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.645804762840271 | Acc 59.795918367346935\n",
      "Batch 2: loss 0.64562126994133 | Acc 58.877551020408156\n",
      "Batch 3: loss 0.6446925004323324 | Acc 60.51020408163266\n",
      "Batch 4: loss 0.6453973799943924 | Acc 59.285714285714285\n",
      "Batch 5: loss 0.6450785756111145 | Acc 58.673469387755105\n",
      "Batch 6: loss 0.6450744767983755 | Acc 59.38775510204082\n",
      "Batch 7: loss 0.6451364670481 | Acc 58.57142857142858\n",
      "Batch 8: loss 0.6450803205370903 | Acc 60.71428571428571\n",
      "Batch 9: loss 0.6445973383055793 | Acc 61.530612244897966\n",
      "Batch 10: loss 0.6443249225616455 | Acc 60.71428571428571\n",
      "Batch 11: loss 0.6443740454587069 | Acc 59.591836734693885\n",
      "Batch 12: loss 0.6442251602808634 | Acc 60.10204081632653\n",
      "Batch 13: loss 0.6441494272305415 | Acc 60.0\n",
      "Batch 14: loss 0.6442059363637652 | Acc 57.44897959183673\n",
      "Batch 15: loss 0.6439297715822856 | Acc 62.755102040816325\n",
      "Batch 16: loss 0.6437373459339142 | Acc 59.08163265306122\n",
      "Batch 17: loss 0.6442396991393146 | Acc 56.93877551020409\n",
      "Batch 18: loss 0.644419295920266 | Acc 57.6530612244898\n",
      "Batch 19: loss 0.6443859276018644 | Acc 61.224489795918366\n",
      "Batch 20: loss 0.644442817568779 | Acc 60.204081632653065\n",
      "Batch 21: loss 0.644468279111953 | Acc 58.36734693877551\n",
      "Batch 22: loss 0.6442746682600542 | Acc 60.61224489795919\n",
      "Batch 23: loss 0.6440734267234802 | Acc 59.48979591836735\n",
      "Batch 24: loss 0.6440364544590315 | Acc 58.57142857142858\n",
      "Batch 25: loss 0.6440093660354614 | Acc 59.08163265306122\n",
      "Batch 26: loss 0.6440682090245761 | Acc 59.693877551020414\n",
      "Batch 27: loss 0.6444474480770253 | Acc 58.57142857142858\n",
      "Batch 28: loss 0.6445617356470653 | Acc 58.265306122448976\n",
      "Batch 29: loss 0.6447201946686054 | Acc 59.48979591836735\n",
      "Batch 30: loss 0.6448805093765259 | Acc 59.285714285714285\n",
      "Batch 31: loss 0.6448275543028309 | Acc 60.30612244897959\n",
      "Batch 32: loss 0.6447042729705572 | Acc 59.38775510204082\n",
      "Batch 33: loss 0.6446310606869784 | Acc 61.224489795918366\n",
      "Batch 34: loss 0.6444737595670363 | Acc 61.3265306122449\n",
      "Batch 35: loss 0.6446235792977469 | Acc 59.183673469387756\n",
      "Batch 36: loss 0.644515100452635 | Acc 58.97959183673469\n",
      "Batch 37: loss 0.6445720469629442 | Acc 58.97959183673469\n",
      "Batch 38: loss 0.6446787918868818 | Acc 56.63265306122449\n",
      "Batch 39: loss 0.6446952407176678 | Acc 59.183673469387756\n",
      "Batch 40: loss 0.6447015598416328 | Acc 59.693877551020414\n",
      "Batch 41: loss 0.6445464331929277 | Acc 63.469387755102034\n",
      "Batch 42: loss 0.644495780978884 | Acc 59.08163265306122\n",
      "Batch 43: loss 0.6445212960243225 | Acc 58.57142857142858\n",
      "Batch 44: loss 0.6444095495072278 | Acc 62.55102040816326\n",
      "Batch 45: loss 0.6444143811861675 | Acc 57.44897959183673\n",
      "Batch 46: loss 0.6443672724392103 | Acc 60.61224489795919\n",
      "Batch 47: loss 0.644300141233079 | Acc 59.08163265306122\n",
      "Batch 48: loss 0.6441943148771921 | Acc 58.77551020408164\n",
      "Batch 49: loss 0.644330764303402 | Acc 58.16326530612245\n",
      "Epoch 1: Training loss 0.644330764303402 | Acc: 59.53352769679299\n",
      "Epoch 1: Validation loss 0.6641835195677621 | Accuracy 79.12536443148687 | AUC 0.5295648644525054\n",
      "Batch 1: loss 0.6464527249336243 | Acc 59.897959183673464\n",
      "Batch 2: loss 0.6458544433116913 | Acc 58.97959183673469\n",
      "Batch 3: loss 0.6446337898572286 | Acc 60.0\n",
      "Batch 4: loss 0.6461596041917801 | Acc 58.77551020408164\n",
      "Batch 5: loss 0.6460518360137939 | Acc 58.57142857142858\n",
      "Batch 6: loss 0.6460611820220947 | Acc 59.38775510204082\n",
      "Batch 7: loss 0.6462189384869167 | Acc 58.16326530612245\n",
      "Batch 8: loss 0.6465961188077927 | Acc 60.51020408163266\n",
      "Batch 9: loss 0.6457337074809604 | Acc 61.224489795918366\n",
      "Batch 10: loss 0.6456472396850585 | Acc 60.71428571428571\n",
      "Batch 11: loss 0.6451704556291754 | Acc 60.51020408163266\n",
      "Batch 12: loss 0.6448740611473719 | Acc 59.285714285714285\n",
      "Batch 13: loss 0.645025005707374 | Acc 59.795918367346935\n",
      "Batch 14: loss 0.6451449223927089 | Acc 57.44897959183673\n",
      "Batch 15: loss 0.6449779907862345 | Acc 62.34693877551021\n",
      "Batch 16: loss 0.644949484616518 | Acc 59.48979591836735\n",
      "Batch 17: loss 0.6451979805441463 | Acc 56.53061224489796\n",
      "Batch 18: loss 0.6452026930120256 | Acc 57.85714285714286\n",
      "Batch 19: loss 0.645241097400063 | Acc 61.836734693877546\n",
      "Batch 20: loss 0.6450112730264663 | Acc 60.51020408163266\n",
      "Batch 21: loss 0.6450335355032057 | Acc 57.75510204081633\n",
      "Batch 22: loss 0.6448475230823864 | Acc 61.0204081632653\n",
      "Batch 23: loss 0.6448500571043595 | Acc 59.38775510204082\n",
      "Batch 24: loss 0.6447729443510374 | Acc 59.183673469387756\n",
      "Batch 25: loss 0.6447567558288574 | Acc 58.265306122448976\n",
      "Batch 26: loss 0.6445562747808603 | Acc 61.12244897959184\n",
      "Batch 27: loss 0.6447264772874338 | Acc 58.265306122448976\n",
      "Batch 28: loss 0.6448971884591239 | Acc 56.83673469387755\n",
      "Batch 29: loss 0.6452014322938591 | Acc 57.75510204081633\n",
      "Batch 30: loss 0.6452295184135437 | Acc 58.77551020408164\n",
      "Batch 31: loss 0.6452498012973417 | Acc 59.285714285714285\n",
      "Batch 32: loss 0.6454197894781828 | Acc 58.673469387755105\n",
      "Batch 33: loss 0.6453623265931101 | Acc 59.693877551020414\n",
      "Batch 34: loss 0.6451991393285639 | Acc 61.12244897959184\n",
      "Batch 35: loss 0.6451753411974226 | Acc 56.53061224489796\n",
      "Batch 36: loss 0.6451225678126017 | Acc 59.693877551020414\n",
      "Batch 37: loss 0.6452148524490563 | Acc 58.77551020408164\n",
      "Batch 38: loss 0.6452572518273404 | Acc 59.48979591836735\n",
      "Batch 39: loss 0.6452626158029605 | Acc 58.97959183673469\n",
      "Batch 40: loss 0.6452720627188683 | Acc 60.51020408163266\n",
      "Batch 41: loss 0.6451658359388026 | Acc 62.04081632653061\n",
      "Batch 42: loss 0.6454526327905201 | Acc 57.6530612244898\n",
      "Batch 43: loss 0.6454908057700756 | Acc 59.08163265306122\n",
      "Batch 44: loss 0.645400112325495 | Acc 60.71428571428571\n",
      "Batch 45: loss 0.6453922775056627 | Acc 57.6530612244898\n",
      "Batch 46: loss 0.6452509229597838 | Acc 60.91836734693877\n",
      "Batch 47: loss 0.6452864966493972 | Acc 59.183673469387756\n",
      "Batch 48: loss 0.6451647480328878 | Acc 60.40816326530612\n",
      "Batch 49: loss 0.64504068603321 | Acc 61.0204081632653\n",
      "Epoch 2: Training loss 0.64504068603321 | Acc: 59.421074552269886\n",
      "Epoch 2: Validation loss 0.6642832006726946 | Accuracy 79.5218658892128 | AUC 0.5293396045695373\n",
      "Best epoch:  2\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(2, train_query_loader, train_support_loader, val_loader,  train_query_dataset.class_labels(), val_dataset.class_labels(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.25883524141364, 0.5444164673305804, 0.6577511822305074)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(model, test_loader, test_dataset.class_labels())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments on baseline models without attention\n",
    "### RelationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import MetaTrainer\n",
    "from models.metaclassifier.baselines import RelationNet\n",
    "\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = RelationNet(encoder, 512, class_prototype_inf, fc_hidden_size=64)\n",
    "btrainer = MetaTrainer(base_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76.40816326530613, 0.4814422659229693, 0.6890060526984079)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, val_loader, val_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.85863613738178, 0.46753415772972007, 0.6887184134343776)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, test_loader, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.6922392845153809 | Acc 55.81632653061225\n",
      "Batch 2: loss 0.6922772824764252 | Acc 56.42857142857143\n",
      "Batch 3: loss 0.6921975612640381 | Acc 56.53061224489796\n",
      "Batch 4: loss 0.6921016573905945 | Acc 56.42857142857143\n",
      "Batch 5: loss 0.6920598268508911 | Acc 56.93877551020409\n",
      "Batch 6: loss 0.6919763882954916 | Acc 57.95918367346938\n",
      "Batch 7: loss 0.6918906910078866 | Acc 57.14285714285714\n",
      "Batch 8: loss 0.6917958334088326 | Acc 58.57142857142858\n",
      "Batch 9: loss 0.6916449202431573 | Acc 59.897959183673464\n",
      "Batch 10: loss 0.6915410220623016 | Acc 58.97959183673469\n",
      "Batch 11: loss 0.6914029825817455 | Acc 59.897959183673464\n",
      "Batch 12: loss 0.6912817309300104 | Acc 59.48979591836735\n",
      "Batch 13: loss 0.6911432926471417 | Acc 59.38775510204082\n",
      "Batch 14: loss 0.6910162568092346 | Acc 59.38775510204082\n",
      "Batch 15: loss 0.6908564249674479 | Acc 60.40816326530612\n",
      "Batch 16: loss 0.6907406598329544 | Acc 58.97959183673469\n",
      "Batch 17: loss 0.6905901607345132 | Acc 59.285714285714285\n",
      "Batch 18: loss 0.6904586421118842 | Acc 59.48979591836735\n",
      "Batch 19: loss 0.6903580364428068 | Acc 57.95918367346938\n",
      "Batch 20: loss 0.6902426958084107 | Acc 58.77551020408164\n",
      "Batch 21: loss 0.6900684095564342 | Acc 59.591836734693885\n",
      "Batch 22: loss 0.6899705122817646 | Acc 58.06122448979592\n",
      "Batch 23: loss 0.6898851887039517 | Acc 57.55102040816327\n",
      "Batch 24: loss 0.6897051880757014 | Acc 62.04081632653061\n",
      "Batch 25: loss 0.6895659399032593 | Acc 59.795918367346935\n",
      "Batch 26: loss 0.6894316283556131 | Acc 59.285714285714285\n",
      "Batch 27: loss 0.6893438741012856 | Acc 57.55102040816327\n",
      "Batch 28: loss 0.6892368580613818 | Acc 58.673469387755105\n",
      "Batch 29: loss 0.6891068713418369 | Acc 58.97959183673469\n",
      "Batch 30: loss 0.6889615774154663 | Acc 60.204081632653065\n",
      "Batch 31: loss 0.688858893609816 | Acc 57.95918367346938\n",
      "Batch 32: loss 0.6887626629322767 | Acc 58.673469387755105\n",
      "Batch 33: loss 0.688580516612891 | Acc 61.0204081632653\n",
      "Batch 34: loss 0.6885147988796234 | Acc 56.93877551020409\n",
      "Batch 35: loss 0.6882957662854876 | Acc 63.9795918367347\n",
      "Batch 36: loss 0.6881766865650812 | Acc 58.97959183673469\n",
      "Batch 37: loss 0.6881095235412186 | Acc 57.85714285714286\n",
      "Batch 38: loss 0.6878698421152014 | Acc 62.857142857142854\n",
      "Batch 39: loss 0.6877533717033191 | Acc 58.36734693877551\n",
      "Batch 40: loss 0.6875804081559181 | Acc 59.897959183673464\n",
      "Batch 41: loss 0.6874986363620292 | Acc 57.3469387755102\n",
      "Batch 42: loss 0.6873420945235661 | Acc 61.0204081632653\n",
      "Batch 43: loss 0.6871476686278055 | Acc 61.12244897959184\n",
      "Batch 44: loss 0.6869287084449421 | Acc 63.469387755102034\n",
      "Batch 45: loss 0.6868225296338399 | Acc 58.97959183673469\n",
      "Batch 46: loss 0.6866591883742291 | Acc 60.71428571428571\n",
      "Batch 47: loss 0.6864511180431285 | Acc 62.55102040816326\n",
      "Batch 48: loss 0.6863410274187723 | Acc 59.183673469387756\n",
      "Batch 49: loss 0.6861897439372783 | Acc 60.61224489795919\n",
      "Epoch 1: Training loss 0.6861897439372783 | Acc: 59.2044981257809\n",
      "Epoch 1: Validation loss 0.6591783268111092 | Accuracy 78.68221574344024 | AUC 0.5174450021592617\n",
      "Batch 1: loss 0.6794984936714172 | Acc 60.51020408163266\n",
      "Batch 2: loss 0.679203987121582 | Acc 60.0\n",
      "Batch 3: loss 0.6792896588643392 | Acc 60.0\n",
      "Batch 4: loss 0.6793586313724518 | Acc 59.38775510204082\n",
      "Batch 5: loss 0.6795257568359375 | Acc 57.95918367346938\n",
      "Batch 6: loss 0.6796328822771708 | Acc 58.265306122448976\n",
      "Batch 7: loss 0.6800575852394104 | Acc 57.14285714285714\n",
      "Batch 8: loss 0.6798605695366859 | Acc 58.57142857142858\n",
      "Batch 9: loss 0.67949288421207 | Acc 59.591836734693885\n",
      "Batch 10: loss 0.6793319642543793 | Acc 58.877551020408156\n",
      "Batch 11: loss 0.678920713337985 | Acc 60.0\n",
      "Batch 12: loss 0.67886454363664 | Acc 58.06122448979592\n",
      "Batch 13: loss 0.6787226429352393 | Acc 59.591836734693885\n",
      "Batch 14: loss 0.6785929203033447 | Acc 59.38775510204082\n",
      "Batch 15: loss 0.6783170580863953 | Acc 60.40816326530612\n",
      "Batch 16: loss 0.6781174838542938 | Acc 59.48979591836735\n",
      "Batch 17: loss 0.6780138822162852 | Acc 58.673469387755105\n",
      "Batch 18: loss 0.6778813401858012 | Acc 59.48979591836735\n",
      "Batch 19: loss 0.6779164671897888 | Acc 57.55102040816327\n",
      "Batch 20: loss 0.6778457194566727 | Acc 58.77551020408164\n",
      "Batch 21: loss 0.6777306028774807 | Acc 59.183673469387756\n",
      "Batch 22: loss 0.6777736002748663 | Acc 57.55102040816327\n",
      "Batch 23: loss 0.6777204119640848 | Acc 58.877551020408156\n",
      "Batch 24: loss 0.6774991825222969 | Acc 61.42857142857143\n",
      "Batch 25: loss 0.6772192907333374 | Acc 61.3265306122449\n",
      "Batch 26: loss 0.6770845055580139 | Acc 59.08163265306122\n",
      "Batch 27: loss 0.6770436675460251 | Acc 58.06122448979592\n",
      "Batch 28: loss 0.6769895809037345 | Acc 57.95918367346938\n",
      "Batch 29: loss 0.6767991370168226 | Acc 60.0\n",
      "Batch 30: loss 0.6766861975193024 | Acc 60.10204081632653\n",
      "Batch 31: loss 0.676718202329451 | Acc 57.75510204081633\n",
      "Batch 32: loss 0.6766557916998863 | Acc 58.36734693877551\n",
      "Batch 33: loss 0.6763838222532561 | Acc 60.61224489795919\n",
      "Batch 34: loss 0.6764291437233195 | Acc 57.04081632653061\n",
      "Batch 35: loss 0.6760616336550032 | Acc 64.08163265306122\n",
      "Batch 36: loss 0.6758561962180667 | Acc 61.530612244897966\n",
      "Batch 37: loss 0.6757375307985254 | Acc 60.71428571428571\n",
      "Batch 38: loss 0.675583585312492 | Acc 62.244897959183675\n",
      "Batch 39: loss 0.6754604134804163 | Acc 60.30612244897959\n",
      "Batch 40: loss 0.6753481760621071 | Acc 60.0\n",
      "Batch 41: loss 0.6753720728362479 | Acc 58.265306122448976\n",
      "Batch 42: loss 0.6752108818008786 | Acc 60.30612244897959\n",
      "Batch 43: loss 0.6750412818997406 | Acc 60.61224489795919\n",
      "Batch 44: loss 0.6748815354975787 | Acc 60.30612244897959\n",
      "Batch 45: loss 0.6747330930497911 | Acc 59.897959183673464\n",
      "Batch 46: loss 0.6747071069219838 | Acc 59.897959183673464\n",
      "Batch 47: loss 0.6744581143906776 | Acc 63.775510204081634\n",
      "Batch 48: loss 0.6743760332465172 | Acc 59.38775510204082\n",
      "Batch 49: loss 0.6743285449183717 | Acc 59.183673469387756\n",
      "Epoch 2: Training loss 0.6743285449183717 | Acc: 59.5835068721366\n",
      "Epoch 2: Validation loss 0.6308378747531346 | Accuracy 78.7521865889213 | AUC 0.5215574423686749\n",
      "Batch 1: loss 0.6671068668365479 | Acc 61.530612244897966\n",
      "Batch 2: loss 0.6695881187915802 | Acc 59.693877551020414\n",
      "Batch 3: loss 0.6696506142616272 | Acc 61.224489795918366\n",
      "Batch 4: loss 0.6696416437625885 | Acc 58.877551020408156\n",
      "Batch 5: loss 0.6704630374908447 | Acc 57.75510204081633\n",
      "Batch 6: loss 0.6708731055259705 | Acc 58.77551020408164\n",
      "Batch 7: loss 0.6717420986720494 | Acc 57.244897959183675\n",
      "Batch 8: loss 0.6715336218476295 | Acc 59.591836734693885\n",
      "Batch 9: loss 0.6710280643569099 | Acc 60.204081632653065\n",
      "Batch 10: loss 0.670782345533371 | Acc 60.51020408163266\n",
      "Batch 11: loss 0.6697549494830045 | Acc 61.224489795918366\n",
      "Batch 12: loss 0.6696996539831161 | Acc 59.693877551020414\n",
      "Batch 13: loss 0.6693907150855432 | Acc 60.40816326530612\n",
      "Batch 14: loss 0.6693734441484723 | Acc 61.12244897959184\n",
      "Batch 15: loss 0.6690911293029785 | Acc 61.224489795918366\n",
      "Batch 16: loss 0.6690889820456505 | Acc 60.30612244897959\n",
      "Batch 17: loss 0.6689454106723561 | Acc 59.38775510204082\n",
      "Batch 18: loss 0.6689656575520834 | Acc 60.10204081632653\n",
      "Batch 19: loss 0.6692209933933458 | Acc 57.3469387755102\n",
      "Batch 20: loss 0.6690206527709961 | Acc 60.0\n",
      "Batch 21: loss 0.6688638187590099 | Acc 60.816326530612244\n",
      "Batch 22: loss 0.668828934431076 | Acc 58.77551020408164\n",
      "Batch 23: loss 0.668866929800614 | Acc 59.38775510204082\n",
      "Batch 24: loss 0.6685812075932821 | Acc 61.836734693877546\n",
      "Batch 25: loss 0.6684433007240296 | Acc 60.816326530612244\n",
      "Batch 26: loss 0.6681980926256913 | Acc 61.0204081632653\n",
      "Batch 27: loss 0.6680872197504397 | Acc 60.204081632653065\n",
      "Batch 28: loss 0.6680277990443366 | Acc 59.38775510204082\n",
      "Batch 29: loss 0.667841033688907 | Acc 62.44897959183674\n",
      "Batch 30: loss 0.6678104221820831 | Acc 59.693877551020414\n",
      "Batch 31: loss 0.6681316129622921 | Acc 56.93877551020409\n",
      "Batch 32: loss 0.6682349387556314 | Acc 57.44897959183673\n",
      "Batch 33: loss 0.668085596778176 | Acc 60.40816326530612\n",
      "Batch 34: loss 0.6683073517154244 | Acc 57.244897959183675\n",
      "Batch 35: loss 0.6681495359965733 | Acc 61.0204081632653\n",
      "Batch 36: loss 0.6681797206401825 | Acc 60.30612244897959\n",
      "Batch 37: loss 0.6679497055105261 | Acc 63.469387755102034\n",
      "Batch 38: loss 0.6677134052703255 | Acc 63.87755102040816\n",
      "Batch 39: loss 0.6676883330711951 | Acc 59.795918367346935\n",
      "Batch 40: loss 0.6675750225782394 | Acc 60.30612244897959\n",
      "Batch 41: loss 0.6677043379806891 | Acc 57.44897959183673\n",
      "Batch 42: loss 0.667630136013031 | Acc 61.63265306122449\n",
      "Batch 43: loss 0.6675477679385695 | Acc 60.40816326530612\n",
      "Batch 44: loss 0.6673743331974203 | Acc 63.57142857142857\n",
      "Batch 45: loss 0.6673522737291124 | Acc 59.693877551020414\n",
      "Batch 46: loss 0.6672070894552313 | Acc 61.93877551020408\n",
      "Batch 47: loss 0.6669787510912469 | Acc 64.38775510204081\n",
      "Batch 48: loss 0.666894386212031 | Acc 59.48979591836735\n",
      "Batch 49: loss 0.6668269123349871 | Acc 62.244897959183675\n",
      "Epoch 3: Training loss 0.6668269123349871 | Acc: 60.249895876718035\n",
      "Epoch 3: Validation loss 0.6146493826593672 | Accuracy 77.87755102040818 | AUC 0.5236970305311497\n",
      "Batch 1: loss 0.6645023822784424 | Acc 61.530612244897966\n",
      "Batch 2: loss 0.666167676448822 | Acc 60.816326530612244\n",
      "Batch 3: loss 0.6659182707468668 | Acc 62.34693877551021\n",
      "Batch 4: loss 0.6658838391304016 | Acc 59.897959183673464\n",
      "Batch 5: loss 0.6661906957626342 | Acc 59.897959183673464\n",
      "Batch 6: loss 0.6667752464612325 | Acc 59.795918367346935\n",
      "Batch 7: loss 0.6679234334400722 | Acc 59.285714285714285\n",
      "Batch 8: loss 0.6671867147088051 | Acc 60.30612244897959\n",
      "Batch 9: loss 0.6666208836767409 | Acc 61.73469387755102\n",
      "Batch 10: loss 0.6662196159362793 | Acc 61.73469387755102\n",
      "Batch 11: loss 0.6653882806951349 | Acc 61.0204081632653\n",
      "Batch 12: loss 0.6650811582803726 | Acc 61.73469387755102\n",
      "Batch 13: loss 0.6648334035506616 | Acc 60.40816326530612\n",
      "Batch 14: loss 0.6646990392889295 | Acc 61.224489795918366\n",
      "Batch 15: loss 0.664291787147522 | Acc 63.775510204081634\n",
      "Batch 16: loss 0.6643046028912067 | Acc 60.61224489795919\n",
      "Batch 17: loss 0.664245580925661 | Acc 59.183673469387756\n",
      "Batch 18: loss 0.6643294029765658 | Acc 61.42857142857143\n",
      "Batch 19: loss 0.6647240143073233 | Acc 58.16326530612245\n",
      "Batch 20: loss 0.6646039873361588 | Acc 60.0\n",
      "Batch 21: loss 0.664353316738492 | Acc 63.57142857142857\n",
      "Batch 22: loss 0.6642938174984672 | Acc 60.816326530612244\n",
      "Batch 23: loss 0.6642630540806315 | Acc 61.530612244897966\n",
      "Batch 24: loss 0.6639002313216528 | Acc 63.06122448979592\n",
      "Batch 25: loss 0.6638231682777405 | Acc 59.48979591836735\n",
      "Batch 26: loss 0.6635776528945336 | Acc 62.142857142857146\n",
      "Batch 27: loss 0.6636184829252737 | Acc 60.204081632653065\n",
      "Batch 28: loss 0.6635727712086269 | Acc 60.71428571428571\n",
      "Batch 29: loss 0.6632150637692419 | Acc 64.38775510204081\n",
      "Batch 30: loss 0.663139541943868 | Acc 61.530612244897966\n",
      "Batch 31: loss 0.6634142341152314 | Acc 57.85714285714286\n",
      "Batch 32: loss 0.6636482607573271 | Acc 57.95918367346938\n",
      "Batch 33: loss 0.663311318917708 | Acc 63.6734693877551\n",
      "Batch 34: loss 0.6634208419743706 | Acc 59.48979591836735\n",
      "Batch 35: loss 0.6631177595683506 | Acc 63.163265306122454\n",
      "Batch 36: loss 0.6631718907091353 | Acc 60.61224489795919\n",
      "Batch 37: loss 0.6631984324068636 | Acc 62.142857142857146\n",
      "Batch 38: loss 0.6629828481297744 | Acc 63.06122448979592\n",
      "Batch 39: loss 0.6628193305088923 | Acc 63.06122448979592\n",
      "Batch 40: loss 0.6625381708145142 | Acc 63.775510204081634\n",
      "Batch 41: loss 0.6626030061303115 | Acc 60.10204081632653\n",
      "Batch 42: loss 0.6624367308048975 | Acc 63.469387755102034\n",
      "Batch 43: loss 0.6622579028440077 | Acc 63.36734693877551\n",
      "Batch 44: loss 0.6621849699453874 | Acc 61.42857142857143\n",
      "Batch 45: loss 0.6621556798617045 | Acc 61.63265306122449\n",
      "Batch 46: loss 0.6621394572050675 | Acc 62.142857142857146\n",
      "Batch 47: loss 0.6620904638412151 | Acc 61.93877551020408\n",
      "Batch 48: loss 0.6618497011562189 | Acc 63.57142857142857\n",
      "Batch 49: loss 0.6617987800617607 | Acc 62.65306122448979\n",
      "Epoch 4: Training loss 0.6617987800617607 | Acc: 61.376509787588496\n",
      "Epoch 4: Validation loss 0.6034654668399266 | Accuracy 76.89795918367345 | AUC 0.525221066447877\n",
      "Best epoch:  2\n"
     ]
    }
   ],
   "source": [
    "btrainer.run_train(4, train_query_loader, train_support_loader, val_loader,  train_query_dataset.class_labels(), val_dataset.class_labels(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.69387755102042, 0.5204702109376685, 0.6312191026551383)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.best_model, val_loader, val_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.25335988053757, 0.510349916356135, 0.6320822573289638)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.best_model, test_loader, test_dataset.class_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(btrainer.best_model.cls.state_dict(), 'relnet_weights-64.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
