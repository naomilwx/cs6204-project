{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import get_device\n",
    "from utils.data import DatasetConfig\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "\n",
    "NUM_SHOTS = 5\n",
    "NUM_WAYS = 7\n",
    "TRAIN_NUM_WAYS= 7\n",
    "N_QUERY = 20\n",
    "dataset_config = DatasetConfig(IMG_PATH, 'data/vindr_cxr_split_labels.pkl', 'data/vindr_train_query_set.pkl', VINDR_CXR_LABELS, VINDR_SPLIT, MEAN_STDS['chestmnist'])\n",
    "device =  get_device()\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with attention\n",
    "### Run experiments on proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.model import ClsModel\n",
    "\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/vindr1/attention-model-8h4l.pth')\n",
    "model = ClsModel(encoder, attention, 512, class_prototype_inf, fc_hidden_size=16)\n",
    "mtrainer = ControlledMetaTrainer(model, NUM_SHOTS, NUM_WAYS, dataset_config, train_n_ways=TRAIN_NUM_WAYS, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 times?\n",
    "mtrainer.run_train(2, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.attn_model.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_train(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model trained 3 epochs with lr=5e-6, 3 epochs with lr=1e-6, 3 epochs with lr=1e-5\n",
    "mtrainer.run_eval(mtrainer.model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.cls.state_dict(), 'models/metaclassifier/model/comb3/cls_weights-16.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.attn_model, 'models/metaclassifier/model/comb3/attention-model-8h4l.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.model import ProtoNetAttention\n",
    "\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/vindr1/attention-model-8h4l.pth')\n",
    "# imgtxt_encoder, attn_model, class_prototype_aggregator, distance_func\n",
    "model = ProtoNetAttention(encoder, attention, class_prototype_inf, euclidean_distance)\n",
    "mtrainer = ControlledMetaTrainer(model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.encoder.set_trainable(True, True, include_logit_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.attn_model.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(model, mtrainer.test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(model, mtrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_train(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mtrainer.best_model.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.create_query_eval_dataloader('train'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.val_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result of training backbone for 3 iterations\n",
    "Training Query set: 0.5583506872136611\n",
    "Test set: 0.8007964161274267\n",
    "Validation set: 0.7913702623906704\n",
    "\n",
    "\n",
    "#### Result of attention for 3 iterations\n",
    "Training Query set: 0.558725531028738\n",
    "Test set: 0.7993031358885015\n",
    "Validation set: 0.7881049562682213\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments on baseline models without attention\n",
    "### RelationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import RelationNet\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = RelationNet(encoder, 512, class_prototype_inf, fc_hidden_size=16)\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_train(2, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(btrainer.best_model.cls.state_dict(), 'relnet_weights-16.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import ProtoNet\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = ProtoNet(encoder, class_prototype_inf, euclidean_distance, trainable_base=False)\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.val_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder, ImageOnlyEmbedding, DummyEncoder, resnet_backbone, load_pretrained_resnet, adapt_resnet_input_channels\n",
    "\n",
    "from utils.prototype import class_prototype_inf, class_prototype_mean\n",
    "from models.metaclassifier.base import euclidean_distance, cosine_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import ProtoNet\n",
    "\n",
    "# from torchmetrics.classification import MultilabelAccuracy, MultilabelAUROC\n",
    "\n",
    "# encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "# encoder = torch.load('models/embedding/model/imgtext_model_from_medclip.pth')\n",
    "# torchvision.models.resnet50(num_classes=len(chest_ds.info['label']), pretrained=False)\n",
    "# img_backbone = resnet_backbone(adapt_resnet_input_channels(torchvision.models.resnet50(weights=None), 1))\n",
    "img_backbone = resnet_backbone(adapt_resnet_input_channels(torchvision.models.resnet50(weights='IMAGENET1K_V1'), 1))\n",
    "\n",
    "\n",
    "encoder = ImageOnlyEmbedding(img_backbone, 512)\n",
    "# encoder = DummyEncoder(512)\n",
    "base_model = ProtoNet(encoder, class_prototype_inf, cosine_distance, trainable_base=False)\n",
    "\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device, n_query=N_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.val_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_train(4, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
