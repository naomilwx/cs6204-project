{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import get_device\n",
    "from utils.data import DatasetConfig\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT, VINDR_SPLIT2\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "\n",
    "NUM_SHOTS = 5\n",
    "NUM_WAYS = 7\n",
    "N_QUERY = 10\n",
    "TRAIN_NUM_WAYS= 7\n",
    "# dataset_config = DatasetConfig(IMG_PATH, 'data/vindr_cxr_split_labels.pkl', 'data/vindr_train_query_set.pkl', VINDR_CXR_LABELS, VINDR_SPLIT, MEAN_STDS['chestmnist'])\n",
    "dataset_config = DatasetConfig(IMG_PATH, 'data/vindr_cxr_split_labels2.pkl', 'data/vindr_train_query_set2.pkl', VINDR_CXR_LABELS, VINDR_SPLIT2, MEAN_STDS['chestmnist'])\n",
    "device =  get_device()\n",
    "\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with attention\n",
    "### Run experiments on proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.model import ClsModel\n",
    "\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/vindr1/attention-model-8h4l.pth')\n",
    "model = ClsModel(encoder, attention, 512, class_prototype_inf, fc_hidden_size=16)\n",
    "mtrainer = ControlledMetaTrainer(model, NUM_SHOTS, NUM_WAYS, dataset_config, train_n_ways=TRAIN_NUM_WAYS, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 times?\n",
    "mtrainer.run_train(2, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.attn_model.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_train(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model trained 3 epochs with lr=5e-6, 3 epochs with lr=1e-6, 3 epochs with lr=1e-5\n",
    "mtrainer.run_eval(mtrainer.model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.cls.state_dict(), 'models/metaclassifier/model/comb3/cls_weights-16.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.attn_model, 'models/metaclassifier/model/comb3/attention-model-8h4l.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.model import ProtoNetAttention\n",
    "\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/vindr1/attention-model-8h4l.pth')\n",
    "# imgtxt_encoder, attn_model, class_prototype_aggregator, distance_func\n",
    "model = ProtoNetAttention(encoder, attention, class_prototype_inf, euclidean_distance)\n",
    "mtrainer = ControlledMetaTrainer(model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.encoder.set_trainable(True, True, include_logit_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.attn_model.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(model, mtrainer.test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(model, mtrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_train(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mtrainer.best_model.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.create_query_eval_dataloader('train'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.val_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments on baseline models without attention\n",
    "### RelationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import RelationNet\n",
    "\n",
    "encoder = torch.load('models/embedding/model/vindr1/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = RelationNet(encoder, 512, class_prototype_inf, fc_hidden_size=16)\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_train(2, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(btrainer.best_model.cls.state_dict(), 'relnet_weights-16.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder, ImageOnlyEmbedding, resnet_backbone, load_pretrained_resnet, adapt_resnet_input_channels\n",
    "\n",
    "from utils.prototype import class_prototype_inf, class_prototype_mean, class_prototype_rrp\n",
    "from models.metaclassifier.base import euclidean_distance, cosine_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import ProtoNet\n",
    "\n",
    "# img_backbone = resnet_backbone(adapt_resnet_input_channels(resnet50(weights=None), 1)) # 13.0714\n",
    "img_backbone = resnet_backbone(load_pretrained_resnet(1, 14, 'models/backbone/pretrained/cxr_backbone_bal.pkl')) # 5.5300\n",
    "# img_backbone = resnet_backbone(torch.load('models/backbone/pretrained/vindr2/trained-backbone.pth')) # 3.4861\n",
    "# img_backbone = resnet_backbone(torch.load('models/backbone/pretrained/vindr2/trained-backbone-balacc.pth')) # 3.6244\n",
    "encoder = ImageOnlyEmbedding(img_backbone, 512)\n",
    "\n",
    "# encoder = torch.load('models/embedding/model/vindr2/imgtext_model_trained1.pth') #  0.9843\n",
    "# encoder = torch.load('models/attention/model/vindr2/full/imgtxt-encoder.pth')\n",
    "# encoder.text_model.device = device\n",
    "base_model = ProtoNet(encoder, class_prototype_inf, euclidean_distance, trainable_base=False, scale=5.5300)\n",
    "\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device, n_query=N_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_train(3, lr=0.05, min_lr=1e-4, lr_change_step=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "mtrainer.run_eval(btrainer.best_model, btrainer.create_query_eval_dataloader(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running seed: 42\n",
      "query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naomileow/Documents/school/CS6240/project/utils/prototype.py:55: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  classes_count = torch.nonzero(label_inds)[:,1].bincount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5017755031585693 | F1 0.5352621674537659 | AUC 0.5025913566060083 | Specificity 0.398845911026001 | Recall 0.6332180500030518 | Bal Acc 0.5160319805145264\n",
      "Loss 0.5897843837738037 | F1 0.6261849403381348 | AUC 0.4740823387334818 | Specificity 0.23998019099235535 | Recall 0.7194490432739258 | Bal Acc 0.47971463203430176\n",
      "Loss 0.5285687446594238 | F1 0.49893999099731445 | AUC 0.4637256728778468 | Specificity 0.27443066239356995 | Recall 0.7666667699813843 | Bal Acc 0.5205487012863159\n",
      "Loss 0.49999916553497314 | F1 0.5323529243469238 | AUC 0.5195971267587426 | Specificity 0.39143839478492737 | Recall 0.6073631048202515 | Bal Acc 0.4994007349014282\n",
      "Loss 0.5379074811935425 | F1 0.5855317115783691 | AUC 0.5170592909442527 | Specificity 0.23362255096435547 | Recall 0.8241515755653381 | Bal Acc 0.5288870334625244\n",
      "Loss 0.5325268507003784 | F1 0.6284292936325073 | AUC 0.4969740219522829 | Specificity 0.19544607400894165 | Recall 0.7958242297172546 | Bal Acc 0.49563515186309814\n",
      "Loss 0.510648250579834 | F1 0.5343496799468994 | AUC 0.5273359106912621 | Specificity 0.27883902192115784 | Recall 0.7468885779380798 | Bal Acc 0.51286381483078\n",
      "Loss 0.5173082947731018 | F1 0.5157828330993652 | AUC 0.4856244564305253 | Specificity 0.2905409038066864 | Recall 0.7380121946334839 | Bal Acc 0.5142765641212463\n",
      "Loss 0.5265872478485107 | F1 0.6332305073738098 | AUC 0.48451990158380703 | Specificity 0.18960513174533844 | Recall 0.7526208162307739 | Bal Acc 0.4711129665374756\n",
      "Loss 0.5252383947372437 | F1 0.5195207595825195 | AUC 0.49604088669312 | Specificity 0.22763775289058685 | Recall 0.7763639092445374 | Bal Acc 0.5020008087158203\n",
      "Loss 0.5112596750259399 | F1 0.5077284574508667 | AUC 0.48955029294600366 | Specificity 0.3499630391597748 | Recall 0.6650663614273071 | Bal Acc 0.5075147151947021\n",
      "Loss 0.5877903699874878 | F1 0.635533332824707 | AUC 0.40725977443245004 | Specificity 0.20272201299667358 | Recall 0.6684490442276001 | Bal Acc 0.43558552861213684\n",
      "Loss 0.514545202255249 | F1 0.5266486406326294 | AUC 0.5038249346279028 | Specificity 0.2933206558227539 | Recall 0.7184901237487793 | Bal Acc 0.5059053897857666\n",
      "Loss 0.5300980806350708 | F1 0.5508950352668762 | AUC 0.5017027633183525 | Specificity 0.2376163750886917 | Recall 0.7547203302383423 | Bal Acc 0.4961683452129364\n",
      "Loss 0.5250889658927917 | F1 0.6773735880851746 | AUC 0.5162491475322865 | Specificity 0.2532367706298828 | Recall 0.7912333011627197 | Bal Acc 0.5222350358963013\n",
      "Loss 0.4981198310852051 | F1 0.6315128207206726 | AUC 0.5635453869762308 | Specificity 0.33365797996520996 | Recall 0.8210251331329346 | Bal Acc 0.5773415565490723\n",
      "Loss 0.5231248140335083 | F1 0.4894513189792633 | AUC 0.5058134453292049 | Specificity 0.27849897742271423 | Recall 0.7116632461547852 | Bal Acc 0.4950811266899109\n",
      "Loss 0.5044115781784058 | F1 0.5550796389579773 | AUC 0.55007778521036 | Specificity 0.28088247776031494 | Recall 0.7168283462524414 | Bal Acc 0.4988554120063782\n",
      "Loss 0.5353466272354126 | F1 0.5227112770080566 | AUC 0.5185576914352605 | Specificity 0.2570040822029114 | Recall 0.7447795867919922 | Bal Acc 0.5008918046951294\n",
      "Loss 0.5169463753700256 | F1 0.5519618988037109 | AUC 0.5056767361407769 | Specificity 0.29760420322418213 | Recall 0.6819767951965332 | Bal Acc 0.48979049921035767\n",
      "Loss 0.5316700339317322 | F1 0.6160095930099487 | AUC 0.51195941024834 | Specificity 0.2545740306377411 | Recall 0.7524911165237427 | Bal Acc 0.5035325884819031\n",
      "Loss 0.53777015209198 | F1 0.4961528182029724 | AUC 0.4841499490766971 | Specificity 0.22217556834220886 | Recall 0.763869047164917 | Bal Acc 0.4930223226547241\n",
      "Loss 0.5753645300865173 | F1 0.6250938177108765 | AUC 0.5163280610754813 | Specificity 0.23599615693092346 | Recall 0.6990323662757874 | Bal Acc 0.4675142765045166\n",
      "Loss 0.5843382477760315 | F1 0.6187344193458557 | AUC 0.5017099922373195 | Specificity 0.22234433889389038 | Recall 0.7213355898857117 | Bal Acc 0.471839964389801\n",
      "Loss 0.5358355641365051 | F1 0.5223755836486816 | AUC 0.4912588618576013 | Specificity 0.20315492153167725 | Recall 0.7680442333221436 | Bal Acc 0.4855995774269104\n",
      "Loss 0.48068487644195557 | F1 0.6023185849189758 | AUC 0.5852942078141927 | Specificity 0.4148576259613037 | Recall 0.7376563549041748 | Bal Acc 0.5762569904327393\n",
      "Loss 0.5234413743019104 | F1 0.590850830078125 | AUC 0.5163369188960434 | Specificity 0.27281442284584045 | Recall 0.8209503889083862 | Bal Acc 0.5468823909759521\n",
      "Loss 0.5091147422790527 | F1 0.5352413654327393 | AUC 0.5153034841193906 | Specificity 0.3268994092941284 | Recall 0.7591425776481628 | Bal Acc 0.5430209636688232\n",
      "Loss 0.5838192701339722 | F1 0.6573784947395325 | AUC 0.5249474796196422 | Specificity 0.2451561689376831 | Recall 0.7632075548171997 | Bal Acc 0.5041818618774414\n",
      "Loss 0.5198806524276733 | F1 0.4855136275291443 | AUC 0.46116755763021955 | Specificity 0.3848499655723572 | Recall 0.5970591306686401 | Bal Acc 0.49095454812049866\n",
      "Loss 0.6112688779830933 | F1 0.6529616117477417 | AUC 0.4746331266763417 | Specificity 0.1983543038368225 | Recall 0.7663239240646362 | Bal Acc 0.48233911395072937\n",
      "Loss 0.57159823179245 | F1 0.5146784782409668 | AUC 0.46944085897026155 | Specificity 0.19993355870246887 | Recall 0.7613293528556824 | Bal Acc 0.4806314706802368\n",
      "Loss 0.5152109861373901 | F1 0.5541564226150513 | AUC 0.5385395660428672 | Specificity 0.3016223609447479 | Recall 0.7350590825080872 | Bal Acc 0.5183407068252563\n",
      "Loss 0.5418019890785217 | F1 0.5338757634162903 | AUC 0.49021749116603003 | Specificity 0.2087882161140442 | Recall 0.7326042056083679 | Bal Acc 0.47069621086120605\n",
      "Loss 0.5380914211273193 | F1 0.5801154375076294 | AUC 0.5004918380251938 | Specificity 0.27985048294067383 | Recall 0.7554739713668823 | Bal Acc 0.5176622271537781\n",
      "Loss 0.538993239402771 | F1 0.5877746939659119 | AUC 0.5001255381978018 | Specificity 0.2359316349029541 | Recall 0.748477578163147 | Bal Acc 0.49220460653305054\n",
      "Loss 0.5830987691879272 | F1 0.5758229494094849 | AUC 0.5045614691350392 | Specificity 0.24444644153118134 | Recall 0.7118536829948425 | Bal Acc 0.47815006971359253\n",
      "Loss 0.5153415203094482 | F1 0.5226485133171082 | AUC 0.5136163863182927 | Specificity 0.28677454590797424 | Recall 0.7387761473655701 | Bal Acc 0.5127753615379333\n",
      "Loss 0.4885890483856201 | F1 0.5487334132194519 | AUC 0.5544175163310886 | Specificity 0.39880749583244324 | Recall 0.6558653116226196 | Bal Acc 0.5273364186286926\n",
      "Loss 0.5224672555923462 | F1 0.553899884223938 | AUC 0.4433670064797888 | Specificity 0.32202762365341187 | Recall 0.6376141309738159 | Bal Acc 0.4798208773136139\n",
      "Loss 0.5056341886520386 | F1 0.5028018355369568 | AUC 0.5153403719774236 | Specificity 0.33678025007247925 | Recall 0.6666050553321838 | Bal Acc 0.5016926527023315\n",
      "Loss 0.5409685373306274 | F1 0.5213398337364197 | AUC 0.49446572324706034 | Specificity 0.24351075291633606 | Recall 0.7082113027572632 | Bal Acc 0.4758610129356384\n",
      "Loss 0.6571523547172546 | F1 0.6626241207122803 | AUC 0.5133535534386937 | Specificity 0.19436174631118774 | Recall 0.7345824837684631 | Bal Acc 0.46447211503982544\n",
      "Loss 0.5409518480300903 | F1 0.5402130484580994 | AUC 0.4763470038213569 | Specificity 0.20548617839813232 | Recall 0.7795355319976807 | Bal Acc 0.4925108551979065\n",
      "Loss 0.5930784940719604 | F1 0.6954997181892395 | AUC 0.49168602893353724 | Specificity 0.18926683068275452 | Recall 0.7737131118774414 | Bal Acc 0.48148995637893677\n",
      "Loss 0.5326839685440063 | F1 0.5660735964775085 | AUC 0.5231800732276518 | Specificity 0.21938884258270264 | Recall 0.7949296236038208 | Bal Acc 0.5071592330932617\n",
      "Loss 0.5293055176734924 | F1 0.46570393443107605 | AUC 0.48259219888712146 | Specificity 0.3183205723762512 | Recall 0.6830856204032898 | Bal Acc 0.5007030963897705\n",
      "Loss 0.5892142057418823 | F1 0.6348996758460999 | AUC 0.5334697273149142 | Specificity 0.185643270611763 | Recall 0.7915903329849243 | Bal Acc 0.48861679434776306\n",
      "Loss 0.5219027996063232 | F1 0.5194984674453735 | AUC 0.4944615240992013 | Specificity 0.31511563062667847 | Recall 0.6701722145080566 | Bal Acc 0.49264392256736755\n",
      "Loss 0.5354487895965576 | F1 0.559901773929596 | AUC 0.4825009060889445 | Specificity 0.22341212630271912 | Recall 0.7847767472267151 | Bal Acc 0.5040944218635559\n",
      "Loss 0.5113041400909424 | F1 0.5091143846511841 | AUC 0.5205315058056864 | Specificity 0.27921757102012634 | Recall 0.7608551383018494 | Bal Acc 0.5200363397598267\n",
      "Loss 0.6032266616821289 | F1 0.612261176109314 | AUC 0.4948508621232743 | Specificity 0.21600404381752014 | Recall 0.712895393371582 | Bal Acc 0.4644497036933899\n",
      "Loss 0.5015995502471924 | F1 0.5496013760566711 | AUC 0.548227892844244 | Specificity 0.3076472282409668 | Recall 0.7609288692474365 | Bal Acc 0.5342880487442017\n",
      "Loss 0.503980278968811 | F1 0.5802240371704102 | AUC 0.5689191637063289 | Specificity 0.3012000322341919 | Recall 0.7867106199264526 | Bal Acc 0.5439553260803223\n",
      "Loss 0.594614565372467 | F1 0.6620526909828186 | AUC 0.5424993557755243 | Specificity 0.20741918683052063 | Recall 0.8390674591064453 | Bal Acc 0.5232433080673218\n",
      "Loss 0.5161726474761963 | F1 0.5847200751304626 | AUC 0.4864913563021708 | Specificity 0.25872427225112915 | Recall 0.7442107200622559 | Bal Acc 0.5014674663543701\n",
      "Loss 0.5175014138221741 | F1 0.5373238325119019 | AUC 0.5173545696083316 | Specificity 0.28152960538864136 | Recall 0.7567796111106873 | Bal Acc 0.5191546082496643\n",
      "Loss 0.5248106718063354 | F1 0.5499277114868164 | AUC 0.48325104763489485 | Specificity 0.237093985080719 | Recall 0.696571409702301 | Bal Acc 0.46683269739151\n",
      "(0.5369828836671238, 0.5670103173831413, 0.5051241121719683, 0.26697197530804007, 0.7363134057357393)\n",
      "val\n",
      "Loss 0.5214060544967651 | F1 0.3001876175403595 | AUC 0.5079593596059114 | Specificity 0.29588109254837036 | Recall 0.6610389947891235 | Bal Acc 0.47846004366874695\n",
      "Loss 0.49755436182022095 | F1 0.3495416045188904 | AUC 0.5597347211743914 | Specificity 0.3351125121116638 | Recall 0.7521809339523315 | Bal Acc 0.5436466932296753\n",
      "Loss 0.5108479261398315 | F1 0.34009724855422974 | AUC 0.5032106049197248 | Specificity 0.3570778965950012 | Recall 0.646127462387085 | Bal Acc 0.5016026496887207\n",
      "Loss 0.5384329557418823 | F1 0.31967341899871826 | AUC 0.47888255291932563 | Specificity 0.2360520362854004 | Recall 0.7489034533500671 | Bal Acc 0.49247774481773376\n",
      "Loss 0.5256991386413574 | F1 0.3272168040275574 | AUC 0.5213141569966907 | Specificity 0.2683567702770233 | Recall 0.7872599363327026 | Bal Acc 0.5278083682060242\n",
      "Loss 0.5301413536071777 | F1 0.3217673897743225 | AUC 0.5131238946505017 | Specificity 0.22621551156044006 | Recall 0.7693021893501282 | Bal Acc 0.4977588653564453\n",
      "Loss 0.49617648124694824 | F1 0.3626019060611725 | AUC 0.5382310201354186 | Specificity 0.3299967050552368 | Recall 0.7594487071037292 | Bal Acc 0.5447226762771606\n",
      "Loss 0.5312422513961792 | F1 0.3463917374610901 | AUC 0.4944897063883421 | Specificity 0.27706825733184814 | Recall 0.7631456851959229 | Bal Acc 0.5201069712638855\n",
      "Loss 0.5072827339172363 | F1 0.3535674810409546 | AUC 0.5423101561615559 | Specificity 0.32741475105285645 | Recall 0.7455124855041504 | Bal Acc 0.5364636182785034\n",
      "Loss 0.513399600982666 | F1 0.32187971472740173 | AUC 0.4903825718195415 | Specificity 0.33581915497779846 | Recall 0.6524941921234131 | Bal Acc 0.4941566586494446\n",
      "Loss 0.5097717046737671 | F1 0.34768766164779663 | AUC 0.5354222885505957 | Specificity 0.32661867141723633 | Recall 0.7107352018356323 | Bal Acc 0.5186769366264343\n",
      "Loss 0.5297834873199463 | F1 0.3404342830181122 | AUC 0.49868233949253565 | Specificity 0.2709518373012543 | Recall 0.7559347748756409 | Bal Acc 0.5134432911872864\n",
      "Loss 0.5093300342559814 | F1 0.3054726719856262 | AUC 0.5350890957543301 | Specificity 0.33880361914634705 | Recall 0.6459169387817383 | Bal Acc 0.49236029386520386\n",
      "Loss 0.5029465556144714 | F1 0.3318963646888733 | AUC 0.5269897634557695 | Specificity 0.3478245437145233 | Recall 0.6804622411727905 | Bal Acc 0.5141434073448181\n",
      "Loss 0.5113236904144287 | F1 0.29867982864379883 | AUC 0.501923866427393 | Specificity 0.37391579151153564 | Recall 0.6002141237258911 | Bal Acc 0.4870649576187134\n",
      "Loss 0.4957026243209839 | F1 0.3187713027000427 | AUC 0.5433729231026133 | Specificity 0.3492729067802429 | Recall 0.7295454740524292 | Bal Acc 0.5394091606140137\n",
      "Loss 0.512308657169342 | F1 0.3403007984161377 | AUC 0.5295487893685403 | Specificity 0.28470104932785034 | Recall 0.7646403908729553 | Bal Acc 0.5246707201004028\n",
      "Loss 0.5319773554801941 | F1 0.26975545287132263 | AUC 0.48168983237420954 | Specificity 0.35101133584976196 | Recall 0.5857607126235962 | Bal Acc 0.4683860242366791\n",
      "Loss 0.5238751173019409 | F1 0.3305337727069855 | AUC 0.5192868387927465 | Specificity 0.2881472408771515 | Recall 0.7748561501502991 | Bal Acc 0.5315017104148865\n",
      "Loss 0.5102532505989075 | F1 0.30288198590278625 | AUC 0.5073837336519437 | Specificity 0.35602355003356934 | Recall 0.6685491800308228 | Bal Acc 0.512286365032196\n",
      "Loss 0.5220691561698914 | F1 0.32851162552833557 | AUC 0.4960601210153307 | Specificity 0.24883586168289185 | Recall 0.7800522446632385 | Bal Acc 0.5144440531730652\n",
      "Loss 0.5199506282806396 | F1 0.3110308051109314 | AUC 0.5108502826887265 | Specificity 0.2720285952091217 | Recall 0.7316327095031738 | Bal Acc 0.5018306374549866\n",
      "Loss 0.4963299036026001 | F1 0.3258242905139923 | AUC 0.5253835213062843 | Specificity 0.3947695791721344 | Recall 0.6067991256713867 | Bal Acc 0.5007843375205994\n",
      "Loss 0.5199670195579529 | F1 0.3347054123878479 | AUC 0.4988545774370987 | Specificity 0.3336041271686554 | Recall 0.7109153270721436 | Bal Acc 0.5222597122192383\n",
      "Loss 0.5189650058746338 | F1 0.3480756878852844 | AUC 0.5478215076619842 | Specificity 0.2798820734024048 | Recall 0.8148424029350281 | Bal Acc 0.547362208366394\n",
      "Loss 0.533068060874939 | F1 0.3191157579421997 | AUC 0.5011478528391197 | Specificity 0.20325139164924622 | Recall 0.7709011435508728 | Bal Acc 0.4870762825012207\n",
      "Loss 0.5189966559410095 | F1 0.31631240248680115 | AUC 0.484985613628433 | Specificity 0.3112155497074127 | Recall 0.6913808584213257 | Bal Acc 0.501298189163208\n",
      "Loss 0.5075666308403015 | F1 0.3514637351036072 | AUC 0.528693668322326 | Specificity 0.3071589469909668 | Recall 0.7208991050720215 | Bal Acc 0.5140290260314941\n",
      "Loss 0.5282974243164062 | F1 0.33162012696266174 | AUC 0.5058437011086051 | Specificity 0.24001440405845642 | Recall 0.7755102515220642 | Bal Acc 0.5077623128890991\n",
      "Loss 0.534530758857727 | F1 0.3365286886692047 | AUC 0.5107447519645337 | Specificity 0.18544214963912964 | Recall 0.8231785893440247 | Bal Acc 0.5043103694915771\n",
      "Loss 0.5468577146530151 | F1 0.3251478374004364 | AUC 0.5188509883680836 | Specificity 0.24580717086791992 | Recall 0.7366475462913513 | Bal Acc 0.4912273585796356\n",
      "Loss 0.5217347741127014 | F1 0.3445907235145569 | AUC 0.5133059084614137 | Specificity 0.2717069089412689 | Recall 0.7735018730163574 | Bal Acc 0.5226044058799744\n",
      "Loss 0.5227078795433044 | F1 0.33789366483688354 | AUC 0.5049726660545074 | Specificity 0.22758978605270386 | Recall 0.8225840330123901 | Bal Acc 0.5250868797302246\n",
      "Loss 0.5164555311203003 | F1 0.3279539942741394 | AUC 0.5134868811854655 | Specificity 0.2839632034301758 | Recall 0.7761827707290649 | Bal Acc 0.5300729870796204\n",
      "Loss 0.5003716349601746 | F1 0.3276658058166504 | AUC 0.5078194864286031 | Specificity 0.4291400611400604 | Recall 0.5795118808746338 | Bal Acc 0.5043259859085083\n",
      "Loss 0.5153465270996094 | F1 0.35093796253204346 | AUC 0.5415374387019231 | Specificity 0.33479446172714233 | Recall 0.738349974155426 | Bal Acc 0.5365722179412842\n",
      "Loss 0.534054160118103 | F1 0.31331896781921387 | AUC 0.49730686173023486 | Specificity 0.2653140425682068 | Recall 0.738935649394989 | Bal Acc 0.5021248459815979\n",
      "Loss 0.49955612421035767 | F1 0.33887946605682373 | AUC 0.5404624361833268 | Specificity 0.32047760486602783 | Recall 0.7400407791137695 | Bal Acc 0.5302591919898987\n",
      "Loss 0.5106217265129089 | F1 0.3365953862667084 | AUC 0.5180511611453315 | Specificity 0.2935275733470917 | Recall 0.740106999874115 | Bal Acc 0.5168172717094421\n",
      "Loss 0.509360671043396 | F1 0.3508206605911255 | AUC 0.5225669004866074 | Specificity 0.29419371485710144 | Recall 0.7349251508712769 | Bal Acc 0.5145594477653503\n",
      "Loss 0.5528685450553894 | F1 0.35296231508255005 | AUC 0.4929829476109648 | Specificity 0.18190258741378784 | Recall 0.8452953100204468 | Bal Acc 0.5135989189147949\n",
      "Loss 0.5149194002151489 | F1 0.3447740077972412 | AUC 0.5341391005074351 | Specificity 0.29493042826652527 | Recall 0.7168885469436646 | Bal Acc 0.5059095025062561\n",
      "Loss 0.5249502062797546 | F1 0.30633166432380676 | AUC 0.454010060504224 | Specificity 0.31229284405708313 | Recall 0.6621562838554382 | Bal Acc 0.4872245788574219\n",
      "Loss 0.5045344829559326 | F1 0.30325376987457275 | AUC 0.5394068343778909 | Specificity 0.3481419086456299 | Recall 0.6605269908905029 | Bal Acc 0.5043344497680664\n",
      "Loss 0.5017822980880737 | F1 0.3360479474067688 | AUC 0.5451225638223732 | Specificity 0.3563441038131714 | Recall 0.7385607361793518 | Bal Acc 0.547452449798584\n",
      "Loss 0.5116150379180908 | F1 0.3505362272262573 | AUC 0.503856590554851 | Specificity 0.32946816086769104 | Recall 0.7595738172531128 | Bal Acc 0.5445209741592407\n",
      "Loss 0.5384339094161987 | F1 0.3008890151977539 | AUC 0.47682670084964063 | Specificity 0.20331552624702454 | Recall 0.7578463554382324 | Bal Acc 0.4805809259414673\n",
      "Loss 0.4977794885635376 | F1 0.3117385804653168 | AUC 0.5191139611331329 | Specificity 0.4225151240825653 | Recall 0.6294934749603271 | Bal Acc 0.5260043144226074\n",
      "Loss 0.5419552326202393 | F1 0.33435502648353577 | AUC 0.4998158372536982 | Specificity 0.2264200747013092 | Recall 0.7584525346755981 | Bal Acc 0.4924362897872925\n",
      "Loss 0.5065381526947021 | F1 0.3334595561027527 | AUC 0.5323521312698398 | Specificity 0.3364288806915283 | Recall 0.6889592409133911 | Bal Acc 0.5126940608024597\n",
      "Loss 0.5221291780471802 | F1 0.34926939010620117 | AUC 0.5200537316591103 | Specificity 0.2716984748840332 | Recall 0.7796621322631836 | Bal Acc 0.5256803035736084\n",
      "Loss 0.5146085023880005 | F1 0.35538148880004883 | AUC 0.5556107069765612 | Specificity 0.33771589398384094 | Recall 0.7253820896148682 | Bal Acc 0.5315489768981934\n",
      "(0.5176611107129317, 0.3301025199202391, 0.5152128020957644, 0.3007722393824504, 0.7256100991597543)\n",
      "test\n",
      "Loss 0.5332232713699341 | F1 0.40918493270874023 | AUC 0.4842045248605665 | Specificity 0.27704012393951416 | Recall 0.8057308197021484 | Bal Acc 0.5413854718208313\n",
      "Loss 0.5459243059158325 | F1 0.38130491971969604 | AUC 0.47486199826753495 | Specificity 0.18991965055465698 | Recall 0.7744251489639282 | Bal Acc 0.4821723997592926\n",
      "Loss 0.5203691124916077 | F1 0.36976200342178345 | AUC 0.5038878120193747 | Specificity 0.2422696352005005 | Recall 0.7660075426101685 | Bal Acc 0.5041385889053345\n",
      "Loss 0.5274635553359985 | F1 0.35716208815574646 | AUC 0.4757835339992592 | Specificity 0.2668183445930481 | Recall 0.7203766107559204 | Bal Acc 0.49359747767448425\n",
      "Loss 0.5367117524147034 | F1 0.3632076382637024 | AUC 0.4838741195799042 | Specificity 0.2662488520145416 | Recall 0.6979509592056274 | Bal Acc 0.48209989070892334\n",
      "Loss 0.5169841647148132 | F1 0.39492201805114746 | AUC 0.49421829233601816 | Specificity 0.3081110417842865 | Recall 0.7331584095954895 | Bal Acc 0.5206347107887268\n",
      "Loss 0.5240482091903687 | F1 0.3713703155517578 | AUC 0.4853453783087382 | Specificity 0.29628846049308777 | Recall 0.6906704902648926 | Bal Acc 0.49347949028015137\n",
      "Loss 0.5009201765060425 | F1 0.3860155940055847 | AUC 0.5537986741013767 | Specificity 0.3265228271484375 | Recall 0.7402792572975159 | Bal Acc 0.5334010124206543\n",
      "Loss 0.5286966562271118 | F1 0.3751266598701477 | AUC 0.5557195821443128 | Specificity 0.2974032163619995 | Recall 0.7790413498878479 | Bal Acc 0.5382223129272461\n",
      "Loss 0.5444391965866089 | F1 0.37502503395080566 | AUC 0.558698610391907 | Specificity 0.15094882249832153 | Recall 0.8598774671554565 | Bal Acc 0.5054131746292114\n",
      "Loss 0.5570163726806641 | F1 0.35787931084632874 | AUC 0.47874047441687523 | Specificity 0.18436399102210999 | Recall 0.7470874786376953 | Bal Acc 0.46572571992874146\n",
      "Loss 0.5252397656440735 | F1 0.35937726497650146 | AUC 0.4785499461728064 | Specificity 0.26499199867248535 | Recall 0.6714919805526733 | Bal Acc 0.46824198961257935\n",
      "Loss 0.5587559938430786 | F1 0.37069523334503174 | AUC 0.4967594098528104 | Specificity 0.20935410261154175 | Recall 0.7767527103424072 | Bal Acc 0.4930534064769745\n",
      "Loss 0.5431550741195679 | F1 0.36135345697402954 | AUC 0.4752782892268052 | Specificity 0.2489849478006363 | Recall 0.7475323677062988 | Bal Acc 0.49825865030288696\n",
      "Loss 0.49730491638183594 | F1 0.3995380401611328 | AUC 0.5627332239658065 | Specificity 0.3175997734069824 | Recall 0.7561224699020386 | Bal Acc 0.5368611216545105\n",
      "Loss 0.5374085307121277 | F1 0.3656772971153259 | AUC 0.4674507863304355 | Specificity 0.22156354784965515 | Recall 0.7510510683059692 | Bal Acc 0.4863073229789734\n",
      "Loss 0.5272454023361206 | F1 0.37585845589637756 | AUC 0.5060787760163318 | Specificity 0.2674933671951294 | Recall 0.7445887923240662 | Bal Acc 0.5060410499572754\n",
      "Loss 0.5337862968444824 | F1 0.35090142488479614 | AUC 0.47521854387576185 | Specificity 0.23054611682891846 | Recall 0.7432901263237 | Bal Acc 0.4869181215763092\n",
      "Loss 0.5411354899406433 | F1 0.36574432253837585 | AUC 0.4772717850293199 | Specificity 0.19921506941318512 | Recall 0.8076587319374084 | Bal Acc 0.5034369230270386\n",
      "Loss 0.5294400453567505 | F1 0.37725889682769775 | AUC 0.4946898748139716 | Specificity 0.2663615942001343 | Recall 0.7628079652786255 | Bal Acc 0.5145847797393799\n",
      "Loss 0.5236145257949829 | F1 0.3773460388183594 | AUC 0.5178496347411679 | Specificity 0.269697368144989 | Recall 0.7567434310913086 | Bal Acc 0.5132204294204712\n",
      "Loss 0.5394390225410461 | F1 0.36212021112442017 | AUC 0.5131779340270772 | Specificity 0.24716044962406158 | Recall 0.720482349395752 | Bal Acc 0.48382139205932617\n",
      "Loss 0.5622440576553345 | F1 0.3979300856590271 | AUC 0.5256300009657341 | Specificity 0.14975270628929138 | Recall 0.8582672476768494 | Bal Acc 0.5040099620819092\n",
      "Loss 0.519991934299469 | F1 0.3735673427581787 | AUC 0.5356360874472043 | Specificity 0.2830618619918823 | Recall 0.7639622092247009 | Bal Acc 0.5235120058059692\n",
      "Loss 0.5297188758850098 | F1 0.34070447087287903 | AUC 0.48267674593605164 | Specificity 0.247224360704422 | Recall 0.6876122951507568 | Bal Acc 0.4674183130264282\n",
      "Loss 0.5153452754020691 | F1 0.38298559188842773 | AUC 0.5232313060277388 | Specificity 0.30012622475624084 | Recall 0.7328233122825623 | Bal Acc 0.5164747834205627\n",
      "Loss 0.5279889106750488 | F1 0.36554819345474243 | AUC 0.5015186739444023 | Specificity 0.24745628237724304 | Recall 0.7883751392364502 | Bal Acc 0.5179157257080078\n",
      "Loss 0.5511398315429688 | F1 0.39471811056137085 | AUC 0.5085779517634673 | Specificity 0.19826599955558777 | Recall 0.8549258708953857 | Bal Acc 0.526595950126648\n",
      "Loss 0.5231164693832397 | F1 0.38986527919769287 | AUC 0.5300246907919883 | Specificity 0.30083364248275757 | Recall 0.7798996567726135 | Bal Acc 0.5403666496276855\n",
      "Loss 0.51157546043396 | F1 0.3809029161930084 | AUC 0.5317815790697819 | Specificity 0.302495539188385 | Recall 0.7236356735229492 | Bal Acc 0.5130655765533447\n",
      "Loss 0.5098448991775513 | F1 0.36296477913856506 | AUC 0.5144180865976417 | Specificity 0.3231094777584076 | Recall 0.6952918767929077 | Bal Acc 0.5092006921768188\n",
      "Loss 0.5290764570236206 | F1 0.3696931004524231 | AUC 0.5025192991100952 | Specificity 0.25774961709976196 | Recall 0.7734655141830444 | Bal Acc 0.5156075954437256\n",
      "Loss 0.5387729406356812 | F1 0.3701382577419281 | AUC 0.47897872595241014 | Specificity 0.20588748157024384 | Recall 0.8047162294387817 | Bal Acc 0.505301833152771\n",
      "Loss 0.5525063276290894 | F1 0.3765367865562439 | AUC 0.47580841517632877 | Specificity 0.2151947021484375 | Recall 0.7833065986633301 | Bal Acc 0.4992506504058838\n",
      "Loss 0.5141277313232422 | F1 0.3886255621910095 | AUC 0.5126448173320461 | Specificity 0.3082779347896576 | Recall 0.762693464756012 | Bal Acc 0.5354856848716736\n",
      "Loss 0.5262551307678223 | F1 0.35426998138427734 | AUC 0.5104360919996421 | Specificity 0.2879880666732788 | Recall 0.697595477104187 | Bal Acc 0.4927917718887329\n",
      "Loss 0.5407015085220337 | F1 0.3891693353652954 | AUC 0.5226521416585105 | Specificity 0.18254125118255615 | Recall 0.8454098701477051 | Bal Acc 0.5139755606651306\n",
      "Loss 0.5582960844039917 | F1 0.34163230657577515 | AUC 0.4418461826846713 | Specificity 0.1934863030910492 | Recall 0.7263944745063782 | Bal Acc 0.4599403738975525\n",
      "Loss 0.5219971537590027 | F1 0.41562509536743164 | AUC 0.5194816823791442 | Specificity 0.2799699902534485 | Recall 0.7851120233535767 | Bal Acc 0.532541036605835\n",
      "Loss 0.5355277061462402 | F1 0.3509823679924011 | AUC 0.4946192852717183 | Specificity 0.24127313494682312 | Recall 0.7157639265060425 | Bal Acc 0.478518545627594\n",
      "Loss 0.5382592678070068 | F1 0.3584268093109131 | AUC 0.4948904529085739 | Specificity 0.2331380397081375 | Recall 0.7531724572181702 | Bal Acc 0.49315524101257324\n",
      "Loss 0.5194523334503174 | F1 0.4137876629829407 | AUC 0.5372085373481945 | Specificity 0.29030194878578186 | Recall 0.8154217004776001 | Bal Acc 0.5528618097305298\n",
      "Loss 0.5492452383041382 | F1 0.3799975514411926 | AUC 0.4805737332968483 | Specificity 0.21499520540237427 | Recall 0.781013011932373 | Bal Acc 0.49800410866737366\n",
      "Loss 0.5285797715187073 | F1 0.35385996103286743 | AUC 0.5257154844193765 | Specificity 0.2913634181022644 | Recall 0.7117103338241577 | Bal Acc 0.5015368461608887\n",
      "Loss 0.534847617149353 | F1 0.36068660020828247 | AUC 0.501751350875966 | Specificity 0.21292385458946228 | Recall 0.7628874778747559 | Bal Acc 0.48790568113327026\n",
      "Loss 0.531889796257019 | F1 0.3527871370315552 | AUC 0.46416736607071757 | Specificity 0.23618769645690918 | Recall 0.7207746505737305 | Bal Acc 0.4784811735153198\n",
      "Loss 0.5204068422317505 | F1 0.3778337836265564 | AUC 0.5093192885796345 | Specificity 0.29035037755966187 | Recall 0.7054799795150757 | Bal Acc 0.4979151785373688\n",
      "Loss 0.5171473026275635 | F1 0.3904266953468323 | AUC 0.5454012004624176 | Specificity 0.26433494687080383 | Recall 0.7710134983062744 | Bal Acc 0.5176742076873779\n",
      "Loss 0.5370568633079529 | F1 0.38801273703575134 | AUC 0.49284921430170586 | Specificity 0.25645750761032104 | Recall 0.7336344718933105 | Bal Acc 0.4950459897518158\n",
      "Loss 0.5427047610282898 | F1 0.4028899371623993 | AUC 0.5207861775562722 | Specificity 0.2152070850133896 | Recall 0.7753838896751404 | Bal Acc 0.4952954947948456\n",
      "Loss 0.5283427238464355 | F1 0.3991771340370178 | AUC 0.5046041204410064 | Specificity 0.28771522641181946 | Recall 0.7540662288665771 | Bal Acc 0.5208907127380371\n",
      "Loss 0.527319610118866 | F1 0.37461090087890625 | AUC 0.48806122438050475 | Specificity 0.3023509383201599 | Recall 0.7077865600585938 | Bal Acc 0.5050687789916992\n",
      "Loss 0.5311983823776245 | F1 0.38963019847869873 | AUC 0.517472411364016 | Specificity 0.23596324026584625 | Recall 0.8028844594955444 | Bal Acc 0.5194238424301147\n",
      "Loss 0.5507655739784241 | F1 0.3603784739971161 | AUC 0.46942757651186645 | Specificity 0.184719055891037 | Recall 0.7371339797973633 | Bal Acc 0.46092653274536133\n",
      "Loss 0.5246320962905884 | F1 0.3791201114654541 | AUC 0.5329620225343589 | Specificity 0.23955777287483215 | Recall 0.7826438546180725 | Bal Acc 0.5111008286476135\n",
      "Loss 0.5126090049743652 | F1 0.39422714710235596 | AUC 0.5116653098689246 | Specificity 0.3517147898674011 | Recall 0.7104792594909668 | Bal Acc 0.5310970544815063\n",
      "Loss 0.5277959108352661 | F1 0.36293405294418335 | AUC 0.5080937337928862 | Specificity 0.24096429347991943 | Recall 0.7781941294670105 | Bal Acc 0.5095791816711426\n",
      "Loss 0.5074299573898315 | F1 0.37007057666778564 | AUC 0.5311601857138075 | Specificity 0.3056500256061554 | Recall 0.6957105398178101 | Bal Acc 0.5006802678108215\n",
      "Loss 0.5455017685890198 | F1 0.36142903566360474 | AUC 0.440514898047386 | Specificity 0.24320624768733978 | Recall 0.6758241653442383 | Bal Acc 0.45951521396636963\n",
      "Loss 0.5213165283203125 | F1 0.34412166476249695 | AUC 0.48981095130497765 | Specificity 0.2657586634159088 | Recall 0.6694324612617493 | Bal Acc 0.46759557723999023\n",
      "Loss 0.5395299196243286 | F1 0.3701288104057312 | AUC 0.5332778945704905 | Specificity 0.20054477453231812 | Recall 0.8241648077964783 | Bal Acc 0.5123547911643982\n",
      "Loss 0.5316783785820007 | F1 0.36859095096588135 | AUC 0.47001096719740987 | Specificity 0.27765536308288574 | Recall 0.6879912614822388 | Bal Acc 0.48282331228256226\n",
      "Loss 0.5236037969589233 | F1 0.3936785161495209 | AUC 0.5182863237615833 | Specificity 0.21381065249443054 | Recall 0.7834811806678772 | Bal Acc 0.4986459016799927\n",
      "(0.5309819370981247, 0.374595193162797, 0.5034076729189787, 0.25283284130550565, 0.7535343293159728)\n"
     ]
    }
   ],
   "source": [
    "seeds = [42]\n",
    "# seeds = [42, 142, 321]\n",
    "dataloaders = {\n",
    "    'query': btrainer.create_query_eval_dataloader(),\n",
    "    'val': btrainer.val_loader,\n",
    "    'test': btrainer.test_loader\n",
    "}\n",
    "for seed in seeds:\n",
    "    print(f\"Running seed: {seed}\")\n",
    "    for k, d in dataloaders.items():\n",
    "        set_seed(seed)\n",
    "        print(k)\n",
    "        print(btrainer.run_eval(btrainer.model, d, True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
