{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.device import get_device\n",
    "from utils.data import DatasetConfig\n",
    "from utils.labels import VINDR_CXR_LABELS, VINDR_SPLIT\n",
    "from models.backbone.datasets import MEAN_STDS\n",
    "\n",
    "IMG_PATH = 'datasets/vindr-cxr-png'\n",
    "\n",
    "NUM_SHOTS = 5\n",
    "NUM_WAYS = 7\n",
    "TRAIN_NUM_WAYS= 7\n",
    "dataset_config = DatasetConfig(IMG_PATH, 'data/vindr_cxr_split_labels.pkl', 'data/vindr_train_query_set.pkl', VINDR_CXR_LABELS, VINDR_SPLIT, MEAN_STDS['chestmnist'])\n",
    "device =  get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with attention\n",
    "### Run experiments on proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.model import ClsModel\n",
    "\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/attention-model-8h4l.pth')\n",
    "model = ClsModel(encoder, attention, 512, class_prototype_inf, fc_hidden_size=16)\n",
    "mtrainer = ControlledMetaTrainer(model, NUM_SHOTS, NUM_WAYS, dataset_config, train_n_ways=TRAIN_NUM_WAYS, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.361516034985424, 0.5202569099543621, 0.7382618546485901)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.6902595162391663 | Acc 53.46938775510204\n",
      "Batch 2: loss 0.6968538761138916 | Acc 42.44897959183673\n",
      "Batch 3: loss 0.7003634770711263 | Acc 37.95918367346939\n",
      "Batch 4: loss 0.6974166184663773 | Acc 53.46938775510204\n",
      "Batch 5: loss 0.6979597449302674 | Acc 44.08163265306123\n",
      "Batch 6: loss 0.6973948379357656 | Acc 48.97959183673469\n",
      "Batch 7: loss 0.6978198204721723 | Acc 44.08163265306123\n",
      "Batch 8: loss 0.6980315819382668 | Acc 45.714285714285715\n",
      "Batch 9: loss 0.6969953179359436 | Acc 53.87755102040816\n",
      "Batch 10: loss 0.6979582905769348 | Acc 39.183673469387756\n",
      "Batch 11: loss 0.6966771320863203 | Acc 57.55102040816327\n",
      "Batch 12: loss 0.6973831256230673 | Acc 40.0\n",
      "Batch 13: loss 0.6974497345777658 | Acc 46.53061224489796\n",
      "Batch 14: loss 0.6974168930734906 | Acc 46.93877551020408\n",
      "Batch 15: loss 0.697468622525533 | Acc 44.89795918367347\n",
      "Batch 16: loss 0.6972164176404476 | Acc 49.38775510204081\n",
      "Batch 17: loss 0.6974642136517692 | Acc 43.26530612244898\n",
      "Batch 18: loss 0.6976404885450999 | Acc 44.48979591836735\n",
      "Batch 19: loss 0.697437584400177 | Acc 50.61224489795918\n",
      "Batch 20: loss 0.6982869148254395 | Acc 32.6530612244898\n",
      "Batch 21: loss 0.6977014598392305 | Acc 53.87755102040816\n",
      "Batch 22: loss 0.6983142820271578 | Acc 36.3265306122449\n",
      "Batch 23: loss 0.6985053549642148 | Acc 42.04081632653061\n",
      "Batch 24: loss 0.6985820308327675 | Acc 44.08163265306123\n",
      "Batch 25: loss 0.6991787457466125 | Acc 32.6530612244898\n",
      "Batch 26: loss 0.6985859756286328 | Acc 57.95918367346938\n",
      "Batch 27: loss 0.698534177409278 | Acc 46.12244897959184\n",
      "Batch 28: loss 0.6989063514130456 | Acc 37.95918367346939\n",
      "Batch 29: loss 0.6984526843860231 | Acc 54.69387755102041\n",
      "Batch 30: loss 0.6989006300767263 | Acc 34.285714285714285\n",
      "Batch 31: loss 0.6992459412544004 | Acc 37.142857142857146\n",
      "Batch 32: loss 0.6990807168185711 | Acc 48.97959183673469\n",
      "Batch 33: loss 0.6990183772462787 | Acc 48.57142857142857\n",
      "Batch 34: loss 0.6992399955497068 | Acc 39.183673469387756\n",
      "Batch 35: loss 0.6993974498340062 | Acc 41.224489795918366\n",
      "Batch 36: loss 0.6993901464674208 | Acc 46.12244897959184\n",
      "Batch 37: loss 0.6994660706133455 | Acc 42.04081632653061\n",
      "Batch 38: loss 0.699384890104595 | Acc 46.93877551020408\n",
      "Batch 39: loss 0.6990496516227722 | Acc 55.10204081632652\n",
      "Batch 40: loss 0.6992146909236908 | Acc 38.775510204081634\n",
      "Batch 41: loss 0.6991479992866516 | Acc 46.93877551020408\n",
      "Batch 42: loss 0.6992222425483522 | Acc 42.44897959183673\n",
      "Batch 43: loss 0.6992232841114665 | Acc 44.89795918367347\n",
      "Batch 44: loss 0.6990917176008224 | Acc 48.97959183673469\n",
      "Batch 45: loss 0.6990066965421041 | Acc 49.38775510204081\n",
      "Batch 46: loss 0.6991237687027972 | Acc 40.0\n",
      "Batch 47: loss 0.6992306709289551 | Acc 40.0\n",
      "Batch 48: loss 0.6991085310777029 | Acc 51.02040816326531\n",
      "Batch 49: loss 0.6991061689902325 | Acc 44.08163265306123\n",
      "Batch 50: loss 0.6991305923461915 | Acc 43.26530612244898\n",
      "Batch 51: loss 0.6990558201191472 | Acc 47.3469387755102\n",
      "Batch 52: loss 0.6992611965307822 | Acc 36.734693877551024\n",
      "Batch 53: loss 0.6992889642715454 | Acc 42.857142857142854\n",
      "Batch 54: loss 0.6991484540480154 | Acc 49.38775510204081\n",
      "Batch 55: loss 0.6991740075024692 | Acc 44.08163265306123\n",
      "Batch 56: loss 0.6989562213420868 | Acc 54.285714285714285\n",
      "Batch 57: loss 0.6990251248342949 | Acc 40.40816326530612\n",
      "Batch 58: loss 0.6988698706544679 | Acc 53.06122448979592\n",
      "Batch 59: loss 0.6988935207916518 | Acc 44.48979591836735\n",
      "Batch 60: loss 0.6988354702790578 | Acc 46.93877551020408\n",
      "Batch 61: loss 0.6987212700921981 | Acc 51.42857142857142\n",
      "Batch 62: loss 0.6989561280896587 | Acc 34.285714285714285\n",
      "Batch 63: loss 0.6989159129914784 | Acc 46.93877551020408\n",
      "Batch 64: loss 0.6989387217909098 | Acc 44.08163265306123\n",
      "Batch 65: loss 0.698858891083644 | Acc 50.204081632653065\n",
      "Batch 66: loss 0.6989195048809052 | Acc 40.816326530612244\n",
      "Batch 67: loss 0.6988088737672834 | Acc 53.06122448979592\n",
      "Batch 68: loss 0.6989070755593917 | Acc 38.775510204081634\n",
      "Batch 69: loss 0.6987871475841688 | Acc 51.83673469387755\n",
      "Batch 70: loss 0.6988296244825636 | Acc 41.63265306122449\n",
      "Batch 71: loss 0.6988656957384566 | Acc 42.04081632653061\n",
      "Batch 72: loss 0.6988107437888781 | Acc 48.57142857142857\n",
      "Batch 73: loss 0.6986776745482667 | Acc 51.42857142857142\n",
      "Batch 74: loss 0.698747763762603 | Acc 41.63265306122449\n",
      "Batch 75: loss 0.6988968404134115 | Acc 34.285714285714285\n",
      "Batch 76: loss 0.6988241350964496 | Acc 49.38775510204081\n",
      "Batch 77: loss 0.6987839542426072 | Acc 47.755102040816325\n",
      "Batch 78: loss 0.6988224593492655 | Acc 42.857142857142854\n",
      "Batch 79: loss 0.6986470396005655 | Acc 55.10204081632652\n",
      "Batch 80: loss 0.6988065771758556 | Acc 35.10204081632653\n",
      "Batch 81: loss 0.6988347974824317 | Acc 43.26530612244898\n",
      "Batch 82: loss 0.6987368362705882 | Acc 51.02040816326531\n",
      "Batch 83: loss 0.6987857509808368 | Acc 42.44897959183673\n",
      "Batch 84: loss 0.6988106157098498 | Acc 41.63265306122449\n",
      "Batch 85: loss 0.6988123213543611 | Acc 44.48979591836735\n",
      "Batch 86: loss 0.6988363716491434 | Acc 43.673469387755105\n",
      "Batch 87: loss 0.698715095547424 | Acc 53.87755102040816\n",
      "Batch 88: loss 0.6988034905357794 | Acc 36.3265306122449\n",
      "Batch 89: loss 0.6987988185346796 | Acc 44.48979591836735\n",
      "Batch 90: loss 0.6988417757882013 | Acc 42.04081632653061\n",
      "Batch 91: loss 0.6988565908683525 | Acc 42.857142857142854\n",
      "Batch 92: loss 0.698939332495565 | Acc 40.0\n",
      "Batch 93: loss 0.6989762449777255 | Acc 41.63265306122449\n",
      "Batch 94: loss 0.6988571292542397 | Acc 53.46938775510204\n",
      "Batch 95: loss 0.6988501630331341 | Acc 46.53061224489796\n",
      "Batch 96: loss 0.698791311432918 | Acc 49.795918367346935\n",
      "Batch 97: loss 0.6987897385026991 | Acc 42.857142857142854\n",
      "Batch 98: loss 0.6987442733073721 | Acc 50.61224489795918\n",
      "Epoch 1: Training loss 0.6987442733073721 | Acc: 45.168679716784695\n",
      "Epoch 1: Validation loss 0.736474529334477 | Accuracy 20.769679300291543 | AUC 0.4569750506480995\n",
      "Batch 1: loss 0.7044628858566284 | Acc 38.775510204081634\n",
      "Batch 2: loss 0.6940997242927551 | Acc 57.55102040816327\n",
      "Batch 3: loss 0.6945532957712809 | Acc 47.755102040816325\n",
      "Batch 4: loss 0.6950720399618149 | Acc 47.3469387755102\n",
      "Batch 5: loss 0.6966105818748474 | Acc 41.63265306122449\n",
      "Batch 6: loss 0.6953600943088531 | Acc 54.285714285714285\n",
      "Batch 7: loss 0.6928992526871818 | Acc 62.04081632653061\n",
      "Batch 8: loss 0.6949512287974358 | Acc 35.91836734693877\n",
      "Batch 9: loss 0.6966120335790846 | Acc 33.87755102040816\n",
      "Batch 10: loss 0.6944658756256104 | Acc 64.08163265306122\n",
      "Batch 11: loss 0.6938001892783425 | Acc 54.69387755102041\n",
      "Batch 12: loss 0.6951030741135279 | Acc 35.91836734693877\n",
      "Batch 13: loss 0.6956120821145865 | Acc 42.44897959183673\n",
      "Batch 14: loss 0.6956028640270233 | Acc 45.30612244897959\n",
      "Batch 15: loss 0.6964484135309855 | Acc 37.142857142857146\n",
      "Batch 16: loss 0.695210438221693 | Acc 64.48979591836735\n",
      "Batch 17: loss 0.6954904514200547 | Acc 44.08163265306123\n",
      "Batch 18: loss 0.6954486270745596 | Acc 46.93877551020408\n",
      "Batch 19: loss 0.6954178433669241 | Acc 47.755102040816325\n",
      "Batch 20: loss 0.6958093285560608 | Acc 40.40816326530612\n",
      "Batch 21: loss 0.6960378885269165 | Acc 42.44897959183673\n",
      "Batch 22: loss 0.6958069665865465 | Acc 50.204081632653065\n",
      "Batch 23: loss 0.6962297662444736 | Acc 37.142857142857146\n",
      "Batch 24: loss 0.6961251969138781 | Acc 50.61224489795918\n",
      "Batch 25: loss 0.6962594795227051 | Acc 46.93877551020408\n",
      "Batch 26: loss 0.6963288050431472 | Acc 42.857142857142854\n",
      "Batch 27: loss 0.6968896300704391 | Acc 34.285714285714285\n",
      "Batch 28: loss 0.6967681348323822 | Acc 48.57142857142857\n",
      "Batch 29: loss 0.6969031465464625 | Acc 41.63265306122449\n",
      "Batch 30: loss 0.6967681209246318 | Acc 48.57142857142857\n",
      "Batch 31: loss 0.6967145127634848 | Acc 45.714285714285715\n",
      "Batch 32: loss 0.6968089230358601 | Acc 44.89795918367347\n",
      "Batch 33: loss 0.6969500346617266 | Acc 42.857142857142854\n",
      "Batch 34: loss 0.6969892698175767 | Acc 45.714285714285715\n",
      "Batch 35: loss 0.6971894025802612 | Acc 38.775510204081634\n",
      "Batch 36: loss 0.6971558911932839 | Acc 46.53061224489796\n",
      "Batch 37: loss 0.6971979640625618 | Acc 44.08163265306123\n",
      "Batch 38: loss 0.6974332834544935 | Acc 36.734693877551024\n",
      "Batch 39: loss 0.6972491909296085 | Acc 53.46938775510204\n",
      "Batch 40: loss 0.6974675476551055 | Acc 33.87755102040816\n",
      "Batch 41: loss 0.6973858519298274 | Acc 48.57142857142857\n",
      "Batch 42: loss 0.6974053269340879 | Acc 44.08163265306123\n",
      "Batch 43: loss 0.6974436737770258 | Acc 44.48979591836735\n",
      "Batch 44: loss 0.6974154331467368 | Acc 47.3469387755102\n",
      "Batch 45: loss 0.6977510518497891 | Acc 33.06122448979592\n",
      "Batch 46: loss 0.6973712677540986 | Acc 60.816326530612244\n",
      "Batch 47: loss 0.6972544041085751 | Acc 51.83673469387755\n",
      "Batch 48: loss 0.6973107680678368 | Acc 42.04081632653061\n",
      "Batch 49: loss 0.6972122897907179 | Acc 49.795918367346935\n",
      "Batch 50: loss 0.69745645403862 | Acc 33.87755102040816\n",
      "Batch 51: loss 0.6972631531603196 | Acc 54.285714285714285\n",
      "Batch 52: loss 0.6975054717980899 | Acc 34.69387755102041\n",
      "Batch 53: loss 0.6973518436809756 | Acc 53.06122448979592\n",
      "Batch 54: loss 0.6975735988881853 | Acc 32.244897959183675\n",
      "Batch 55: loss 0.6974888324737549 | Acc 49.795918367346935\n",
      "Batch 56: loss 0.6974074042269162 | Acc 45.30612244897959\n",
      "Batch 57: loss 0.6974303994262427 | Acc 43.26530612244898\n",
      "Batch 58: loss 0.6974328057519321 | Acc 46.93877551020408\n",
      "Batch 59: loss 0.6975121780977411 | Acc 42.04081632653061\n",
      "Batch 60: loss 0.6973253617684047 | Acc 53.46938775510204\n",
      "Batch 61: loss 0.6974368710986903 | Acc 42.44897959183673\n",
      "Batch 62: loss 0.6973750139436414 | Acc 48.97959183673469\n",
      "Batch 63: loss 0.6972667347817194 | Acc 49.795918367346935\n",
      "Batch 64: loss 0.6974086724221706 | Acc 37.142857142857146\n",
      "Batch 65: loss 0.697331337745373 | Acc 51.42857142857142\n",
      "Batch 66: loss 0.6974015777761285 | Acc 41.224489795918366\n",
      "Batch 67: loss 0.6975743654948562 | Acc 33.46938775510204\n",
      "Batch 68: loss 0.6973868108847562 | Acc 57.95918367346938\n",
      "Batch 69: loss 0.6974135360855988 | Acc 43.673469387755105\n",
      "Batch 70: loss 0.6973637342453003 | Acc 50.61224489795918\n",
      "Batch 71: loss 0.697402684621408 | Acc 41.224489795918366\n",
      "Batch 72: loss 0.6972872498962615 | Acc 53.87755102040816\n",
      "Batch 73: loss 0.6973685940651044 | Acc 38.36734693877551\n",
      "Batch 74: loss 0.6973473260531554 | Acc 49.795918367346935\n",
      "Batch 75: loss 0.6974197753270467 | Acc 40.0\n",
      "Batch 76: loss 0.6973787836338344 | Acc 48.16326530612245\n",
      "Batch 77: loss 0.6974248746772865 | Acc 40.816326530612244\n",
      "Batch 78: loss 0.6974543401828179 | Acc 46.12244897959184\n",
      "Batch 79: loss 0.6975245875648305 | Acc 38.36734693877551\n",
      "Batch 80: loss 0.6974681831896306 | Acc 51.83673469387755\n",
      "Batch 81: loss 0.6975148916244507 | Acc 42.857142857142854\n",
      "Batch 82: loss 0.6974858852421365 | Acc 45.30612244897959\n",
      "Batch 83: loss 0.6974202775093447 | Acc 50.61224489795918\n",
      "Batch 84: loss 0.6974761173838661 | Acc 39.59183673469388\n",
      "Batch 85: loss 0.6975127689978655 | Acc 45.30612244897959\n",
      "Batch 86: loss 0.6974710662697636 | Acc 45.714285714285715\n",
      "Batch 87: loss 0.6975338137012789 | Acc 39.59183673469388\n",
      "Batch 88: loss 0.697557811032642 | Acc 42.04081632653061\n",
      "Batch 89: loss 0.6975906558251113 | Acc 40.40816326530612\n",
      "Batch 90: loss 0.6974085032939911 | Acc 57.95918367346938\n",
      "Batch 91: loss 0.6974860901360983 | Acc 40.816326530612244\n",
      "Batch 92: loss 0.6975787029318188 | Acc 36.3265306122449\n",
      "Batch 93: loss 0.6976746839861716 | Acc 35.10204081632653\n",
      "Batch 94: loss 0.6976825975357218 | Acc 44.48979591836735\n",
      "Batch 95: loss 0.6976946284896449 | Acc 45.714285714285715\n",
      "Batch 96: loss 0.6976971955349048 | Acc 44.89795918367347\n",
      "Batch 97: loss 0.6977878845844072 | Acc 36.3265306122449\n",
      "Batch 98: loss 0.69767649198065 | Acc 55.10204081632652\n",
      "Epoch 2: Training loss 0.69767649198065 | Acc: 45.13119533527698\n",
      "Epoch 2: Validation loss 0.735885557106563 | Accuracy 20.851311953352774 | AUC 0.45497777255634475\n",
      "Best epoch:  2\n"
     ]
    }
   ],
   "source": [
    "# 5 times?\n",
    "mtrainer.run_train(2, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.93031358885018, 0.507083518313992, 0.7321400235338908)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.attn_model.set_trainable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.6971045732498169 | Acc 42.44897959183673\n",
      "Batch 2: loss 0.6954399049282074 | Acc 48.16326530612245\n",
      "Batch 3: loss 0.6974401871363322 | Acc 39.183673469387756\n",
      "Batch 4: loss 0.696072444319725 | Acc 50.61224489795918\n",
      "Batch 5: loss 0.693632709980011 | Acc 60.0\n",
      "Batch 6: loss 0.6950256526470184 | Acc 37.55102040816327\n",
      "Batch 7: loss 0.6943262900624957 | Acc 51.83673469387755\n",
      "Batch 8: loss 0.6948138996958733 | Acc 42.44897959183673\n",
      "Batch 9: loss 0.6948209206263224 | Acc 46.93877551020408\n",
      "Batch 10: loss 0.6951384782791138 | Acc 43.26530612244898\n",
      "Batch 11: loss 0.6944867806001143 | Acc 52.6530612244898\n",
      "Batch 12: loss 0.6939454972743988 | Acc 51.42857142857142\n",
      "Batch 13: loss 0.6941679395162142 | Acc 44.89795918367347\n",
      "Batch 14: loss 0.6944387938295092 | Acc 46.12244897959184\n",
      "Batch 15: loss 0.6944648385047912 | Acc 48.16326530612245\n",
      "Batch 16: loss 0.6943309046328068 | Acc 47.3469387755102\n",
      "Batch 17: loss 0.6938948526101953 | Acc 55.51020408163265\n",
      "Batch 18: loss 0.6942294736703237 | Acc 41.224489795918366\n",
      "Batch 19: loss 0.6947939239050213 | Acc 36.734693877551024\n",
      "Batch 20: loss 0.6946301907300949 | Acc 51.83673469387755\n",
      "Batch 21: loss 0.695044926234654 | Acc 40.0\n",
      "Batch 22: loss 0.6949186406352303 | Acc 51.42857142857142\n",
      "Batch 23: loss 0.6950044165486875 | Acc 46.93877551020408\n",
      "Batch 24: loss 0.6955882335702578 | Acc 38.36734693877551\n",
      "Batch 25: loss 0.6958429741859437 | Acc 44.48979591836735\n",
      "Batch 26: loss 0.696150506918247 | Acc 41.63265306122449\n",
      "Batch 27: loss 0.6961055221381011 | Acc 49.795918367346935\n",
      "Batch 28: loss 0.696749883038657 | Acc 32.6530612244898\n",
      "Batch 29: loss 0.6974111302145596 | Acc 31.428571428571427\n",
      "Batch 30: loss 0.6972325662771861 | Acc 52.244897959183675\n",
      "Batch 31: loss 0.697345627892402 | Acc 44.48979591836735\n",
      "Batch 32: loss 0.6974859405308962 | Acc 43.673469387755105\n",
      "Batch 33: loss 0.6976434552308285 | Acc 42.04081632653061\n",
      "Batch 34: loss 0.6976613682859084 | Acc 46.93877551020408\n",
      "Batch 35: loss 0.69798298733575 | Acc 35.51020408163265\n",
      "Batch 36: loss 0.6979411774211459 | Acc 47.755102040816325\n",
      "Batch 37: loss 0.6980928198711293 | Acc 41.224489795918366\n",
      "Batch 38: loss 0.6980905579893213 | Acc 46.93877551020408\n",
      "Batch 39: loss 0.6981622989361103 | Acc 44.48979591836735\n",
      "Batch 40: loss 0.698043592274189 | Acc 49.38775510204081\n",
      "Batch 41: loss 0.6980306564307794 | Acc 46.93877551020408\n",
      "Batch 42: loss 0.6981203556060791 | Acc 41.224489795918366\n",
      "Batch 43: loss 0.6982590472975443 | Acc 38.36734693877551\n",
      "Batch 44: loss 0.6979313465681943 | Acc 60.816326530612244\n",
      "Batch 45: loss 0.6977917247348362 | Acc 52.6530612244898\n",
      "Batch 46: loss 0.6977966790613921 | Acc 44.48979591836735\n",
      "Batch 47: loss 0.6978722252744309 | Acc 41.63265306122449\n",
      "Batch 48: loss 0.6978417771557966 | Acc 46.93877551020408\n",
      "Batch 49: loss 0.6978924031160316 | Acc 44.48979591836735\n",
      "Batch 50: loss 0.6979076039791107 | Acc 42.04081632653061\n",
      "Batch 51: loss 0.6979703657767352 | Acc 42.44897959183673\n",
      "Batch 52: loss 0.6977408769039007 | Acc 56.734693877551024\n",
      "Batch 53: loss 0.6975521411535874 | Acc 55.91836734693878\n",
      "Batch 54: loss 0.6976068947050307 | Acc 42.04081632653061\n",
      "Batch 55: loss 0.6975973205132918 | Acc 46.12244897959184\n",
      "Batch 56: loss 0.6975642048886844 | Acc 50.61224489795918\n",
      "Batch 57: loss 0.6975233983575252 | Acc 47.755102040816325\n",
      "Batch 58: loss 0.6975325130183121 | Acc 44.08163265306123\n",
      "Batch 59: loss 0.6975550166631149 | Acc 44.48979591836735\n",
      "Batch 60: loss 0.6974895348151525 | Acc 50.61224489795918\n",
      "Batch 61: loss 0.6974558361241074 | Acc 46.12244897959184\n",
      "Batch 62: loss 0.6974802074893829 | Acc 44.89795918367347\n",
      "Batch 63: loss 0.6972833077112833 | Acc 60.40816326530612\n",
      "Batch 64: loss 0.697296797297895 | Acc 44.48979591836735\n",
      "Batch 65: loss 0.6971664208632249 | Acc 54.285714285714285\n",
      "Batch 66: loss 0.6971752020445737 | Acc 45.30612244897959\n",
      "Batch 67: loss 0.6970892762070271 | Acc 52.6530612244898\n",
      "Batch 68: loss 0.6970981771455091 | Acc 44.89795918367347\n",
      "Batch 69: loss 0.6970813447150631 | Acc 46.93877551020408\n",
      "Batch 70: loss 0.6969942390918732 | Acc 53.46938775510204\n",
      "Batch 71: loss 0.6969931696502256 | Acc 44.89795918367347\n",
      "Batch 72: loss 0.696926425728533 | Acc 51.02040816326531\n",
      "Batch 73: loss 0.6968418498561807 | Acc 52.6530612244898\n",
      "Batch 74: loss 0.6968813401621741 | Acc 42.04081632653061\n",
      "Batch 75: loss 0.6969148286183675 | Acc 42.04081632653061\n",
      "Batch 76: loss 0.6968359170775664 | Acc 53.46938775510204\n",
      "Batch 77: loss 0.6967693907873971 | Acc 52.244897959183675\n",
      "Batch 78: loss 0.6967939245395172 | Acc 42.44897959183673\n",
      "Batch 79: loss 0.6968077609810648 | Acc 42.857142857142854\n",
      "Batch 80: loss 0.6967840440571308 | Acc 48.97959183673469\n",
      "Batch 81: loss 0.6967891035256563 | Acc 44.08163265306123\n",
      "Batch 82: loss 0.6967087010057961 | Acc 56.326530612244895\n",
      "Batch 83: loss 0.6966860832938229 | Acc 45.714285714285715\n",
      "Batch 84: loss 0.6966177267687661 | Acc 55.10204081632652\n",
      "Batch 85: loss 0.6966347112375147 | Acc 43.26530612244898\n",
      "Batch 86: loss 0.6966115111528441 | Acc 48.16326530612245\n",
      "Batch 87: loss 0.6965576389740253 | Acc 54.285714285714285\n",
      "Batch 88: loss 0.6965776377103545 | Acc 43.26530612244898\n",
      "Batch 89: loss 0.696546837185206 | Acc 48.16326530612245\n",
      "Batch 90: loss 0.6965786808066898 | Acc 39.59183673469388\n",
      "Batch 91: loss 0.6965633126405569 | Acc 47.755102040816325\n",
      "Batch 92: loss 0.6965153703223104 | Acc 53.46938775510204\n",
      "Batch 93: loss 0.6964508660377995 | Acc 55.91836734693878\n",
      "Batch 94: loss 0.6964192193873385 | Acc 47.755102040816325\n",
      "Batch 95: loss 0.6963630406480087 | Acc 54.69387755102041\n",
      "Batch 96: loss 0.6963626214613517 | Acc 44.08163265306123\n",
      "Batch 97: loss 0.6963505904699109 | Acc 44.08163265306123\n",
      "Batch 98: loss 0.6962621309319321 | Acc 58.77551020408164\n",
      "Epoch 1: Training loss 0.6962621309319321 | Acc: 46.947105372761335\n",
      "Epoch 1: Validation loss 0.7044891612870353 | Accuracy 28.408163265306115 | AUC 0.528573254872334\n",
      "Batch 1: loss 0.6911651492118835 | Acc 48.16326530612245\n",
      "Batch 2: loss 0.6906952559947968 | Acc 55.10204081632652\n",
      "Batch 3: loss 0.6897823413213094 | Acc 59.183673469387756\n",
      "Batch 4: loss 0.6918270438909531 | Acc 41.63265306122449\n",
      "Batch 5: loss 0.6905031204223633 | Acc 57.14285714285714\n",
      "Batch 6: loss 0.6900751193364462 | Acc 57.95918367346938\n",
      "Batch 7: loss 0.6898397973605565 | Acc 59.591836734693885\n",
      "Batch 8: loss 0.6902012228965759 | Acc 47.755102040816325\n",
      "Batch 9: loss 0.6901301278008355 | Acc 58.77551020408164\n",
      "Batch 10: loss 0.6902716994285584 | Acc 54.285714285714285\n",
      "Batch 11: loss 0.6901290850205855 | Acc 57.55102040816327\n",
      "Batch 12: loss 0.6904562413692474 | Acc 49.795918367346935\n",
      "Batch 13: loss 0.6909165382385254 | Acc 45.30612244897959\n",
      "Batch 14: loss 0.6908481461661202 | Acc 55.91836734693878\n",
      "Batch 15: loss 0.6908385912577312 | Acc 50.61224489795918\n",
      "Batch 16: loss 0.690532635897398 | Acc 57.14285714285714\n",
      "Batch 17: loss 0.6903846894993502 | Acc 59.183673469387756\n",
      "Batch 18: loss 0.6904270516501533 | Acc 49.795918367346935\n",
      "Batch 19: loss 0.6902600464067961 | Acc 59.183673469387756\n",
      "Batch 20: loss 0.690324142575264 | Acc 49.795918367346935\n",
      "Batch 21: loss 0.6903990705808004 | Acc 50.61224489795918\n",
      "Batch 22: loss 0.69023090059107 | Acc 58.36734693877551\n",
      "Batch 23: loss 0.6900481840838557 | Acc 58.77551020408164\n",
      "Batch 24: loss 0.6901360750198364 | Acc 53.87755102040816\n",
      "Batch 25: loss 0.6901242423057556 | Acc 54.285714285714285\n",
      "Batch 26: loss 0.6899504157213064 | Acc 59.183673469387756\n",
      "Batch 27: loss 0.6901089306230899 | Acc 45.30612244897959\n",
      "Batch 28: loss 0.6900407139744077 | Acc 58.36734693877551\n",
      "Batch 29: loss 0.689971689520211 | Acc 59.591836734693885\n",
      "Batch 30: loss 0.6900323410828908 | Acc 51.83673469387755\n",
      "Batch 31: loss 0.6901010544069351 | Acc 48.97959183673469\n",
      "Batch 32: loss 0.6902307998389006 | Acc 46.93877551020408\n",
      "Batch 33: loss 0.6902287186998309 | Acc 58.77551020408164\n",
      "Batch 34: loss 0.6902517974376678 | Acc 49.795918367346935\n",
      "Batch 35: loss 0.6902053713798523 | Acc 54.69387755102041\n",
      "Batch 36: loss 0.6902566171354718 | Acc 50.204081632653065\n",
      "Batch 37: loss 0.6902312346406885 | Acc 60.0\n",
      "Batch 38: loss 0.6901928406012686 | Acc 54.69387755102041\n",
      "Batch 39: loss 0.6902099771377368 | Acc 56.734693877551024\n",
      "Batch 40: loss 0.6900493070483208 | Acc 63.26530612244898\n",
      "Batch 41: loss 0.6900831344651013 | Acc 51.83673469387755\n",
      "Batch 42: loss 0.6899638161772773 | Acc 58.36734693877551\n",
      "Batch 43: loss 0.6900802712107814 | Acc 49.38775510204081\n",
      "Batch 44: loss 0.6900331676006317 | Acc 55.10204081632652\n",
      "Batch 45: loss 0.6900770876142713 | Acc 52.244897959183675\n",
      "Batch 46: loss 0.6899524538413339 | Acc 59.591836734693885\n",
      "Batch 47: loss 0.6899544495217343 | Acc 53.46938775510204\n",
      "Batch 48: loss 0.6900014926989874 | Acc 55.10204081632652\n",
      "Batch 49: loss 0.6899723617398009 | Acc 56.734693877551024\n",
      "Batch 50: loss 0.6899354040622712 | Acc 56.734693877551024\n",
      "Batch 51: loss 0.6899321909044304 | Acc 57.14285714285714\n",
      "Batch 52: loss 0.689936890051915 | Acc 55.51020408163265\n",
      "Batch 53: loss 0.6897990085043997 | Acc 62.857142857142854\n",
      "Batch 54: loss 0.6898343938368338 | Acc 52.6530612244898\n",
      "Batch 55: loss 0.689866088737141 | Acc 52.6530612244898\n",
      "Batch 56: loss 0.6897176206111908 | Acc 60.816326530612244\n",
      "Batch 57: loss 0.68953867230499 | Acc 63.6734693877551\n",
      "Batch 58: loss 0.6895624738315056 | Acc 48.16326530612245\n",
      "Batch 59: loss 0.6897034180366387 | Acc 48.16326530612245\n",
      "Batch 60: loss 0.6896352092425029 | Acc 60.40816326530612\n",
      "Batch 61: loss 0.689720516322089 | Acc 49.38775510204081\n",
      "Batch 62: loss 0.6895980748438066 | Acc 60.40816326530612\n",
      "Batch 63: loss 0.6895522475242615 | Acc 58.77551020408164\n",
      "Batch 64: loss 0.6894514886662364 | Acc 60.40816326530612\n",
      "Batch 65: loss 0.689367598753709 | Acc 63.26530612244898\n",
      "Batch 66: loss 0.6893356099273219 | Acc 58.77551020408164\n",
      "Batch 67: loss 0.6893061052507429 | Acc 57.14285714285714\n",
      "Batch 68: loss 0.6893071216695449 | Acc 55.10204081632652\n",
      "Batch 69: loss 0.6893884738286337 | Acc 48.16326530612245\n",
      "Batch 70: loss 0.6892953353268759 | Acc 64.08163265306122\n",
      "Batch 71: loss 0.6893041486471472 | Acc 50.61224489795918\n",
      "Batch 72: loss 0.6892430037260056 | Acc 58.36734693877551\n",
      "Batch 73: loss 0.6891183444898422 | Acc 61.224489795918366\n",
      "Batch 74: loss 0.689193340572151 | Acc 48.57142857142857\n",
      "Batch 75: loss 0.6891711250940958 | Acc 54.69387755102041\n",
      "Batch 76: loss 0.6891072808127654 | Acc 55.91836734693878\n",
      "Batch 77: loss 0.689254076449902 | Acc 45.714285714285715\n",
      "Batch 78: loss 0.6892141623374743 | Acc 55.10204081632652\n",
      "Batch 79: loss 0.6892058109935326 | Acc 54.285714285714285\n",
      "Batch 80: loss 0.6891518041491509 | Acc 56.734693877551024\n",
      "Batch 81: loss 0.6891525991169023 | Acc 52.244897959183675\n",
      "Batch 82: loss 0.6891218169433314 | Acc 57.14285714285714\n",
      "Batch 83: loss 0.6890834771006941 | Acc 59.183673469387756\n",
      "Batch 84: loss 0.689120474315825 | Acc 48.97959183673469\n",
      "Batch 85: loss 0.6892870103611666 | Acc 43.26530612244898\n",
      "Batch 86: loss 0.6891740033792895 | Acc 57.95918367346938\n",
      "Batch 87: loss 0.6891887784004211 | Acc 52.244897959183675\n",
      "Batch 88: loss 0.6891765086488291 | Acc 56.326530612244895\n",
      "Batch 89: loss 0.6891645474380321 | Acc 56.326530612244895\n",
      "Batch 90: loss 0.6892447743150923 | Acc 48.57142857142857\n",
      "Batch 91: loss 0.6891601124962607 | Acc 61.63265306122449\n",
      "Batch 92: loss 0.6892139425744181 | Acc 51.42857142857142\n",
      "Batch 93: loss 0.6891883727042906 | Acc 55.91836734693878\n",
      "Batch 94: loss 0.6891712362461901 | Acc 54.69387755102041\n",
      "Batch 95: loss 0.6891186977687634 | Acc 56.734693877551024\n",
      "Batch 96: loss 0.6891021523624659 | Acc 56.734693877551024\n",
      "Batch 97: loss 0.6890400119663513 | Acc 54.69387755102041\n",
      "Batch 98: loss 0.6891347887564678 | Acc 46.93877551020408\n",
      "Epoch 2: Training loss 0.6891347887564678 | Acc: 54.76051645147856\n",
      "Epoch 2: Validation loss 0.6612316472189766 | Accuracy 78.89212827988337 | AUC 0.5223173467927928\n",
      "Batch 1: loss 0.6987109780311584 | Acc 47.755102040816325\n",
      "Batch 2: loss 0.692996084690094 | Acc 53.87755102040816\n",
      "Batch 3: loss 0.6951832373936971 | Acc 46.53061224489796\n",
      "Batch 4: loss 0.6929234564304352 | Acc 55.10204081632652\n",
      "Batch 5: loss 0.6944148421287537 | Acc 44.08163265306123\n",
      "Batch 6: loss 0.691870371500651 | Acc 59.591836734693885\n",
      "Batch 7: loss 0.6903429968016488 | Acc 59.183673469387756\n",
      "Batch 8: loss 0.6900140941143036 | Acc 54.285714285714285\n",
      "Batch 9: loss 0.6911471221182082 | Acc 46.12244897959184\n",
      "Batch 10: loss 0.6897434651851654 | Acc 62.857142857142854\n",
      "Batch 11: loss 0.6881651986729015 | Acc 65.3061224489796\n",
      "Batch 12: loss 0.6891338179508845 | Acc 45.30612244897959\n",
      "Batch 13: loss 0.6897529180233295 | Acc 48.97959183673469\n",
      "Batch 14: loss 0.6889055626732963 | Acc 62.04081632653061\n",
      "Batch 15: loss 0.689293917020162 | Acc 48.57142857142857\n",
      "Batch 16: loss 0.6882546246051788 | Acc 64.89795918367346\n",
      "Batch 17: loss 0.6882795761613285 | Acc 53.06122448979592\n",
      "Batch 18: loss 0.6879952914184995 | Acc 59.183673469387756\n",
      "Batch 19: loss 0.687561505719235 | Acc 63.26530612244898\n",
      "Batch 20: loss 0.6874663293361664 | Acc 57.14285714285714\n",
      "Batch 21: loss 0.6875091337022328 | Acc 51.42857142857142\n",
      "Batch 22: loss 0.6871053928678686 | Acc 56.734693877551024\n",
      "Batch 23: loss 0.6871541971745698 | Acc 51.83673469387755\n",
      "Batch 24: loss 0.686801644663016 | Acc 61.63265306122449\n",
      "Batch 25: loss 0.6868631982803345 | Acc 52.6530612244898\n",
      "Batch 26: loss 0.6865255053226764 | Acc 57.55102040816327\n",
      "Batch 27: loss 0.6865771920592697 | Acc 55.91836734693878\n",
      "Batch 28: loss 0.6862731788839612 | Acc 59.591836734693885\n",
      "Batch 29: loss 0.6865313998584089 | Acc 54.285714285714285\n",
      "Batch 30: loss 0.6862991392612457 | Acc 62.857142857142854\n",
      "Batch 31: loss 0.6863538526719616 | Acc 55.91836734693878\n",
      "Batch 32: loss 0.6863611098378897 | Acc 55.10204081632652\n",
      "Batch 33: loss 0.6863502318208868 | Acc 56.326530612244895\n",
      "Batch 34: loss 0.6864835988072788 | Acc 51.42857142857142\n",
      "Batch 35: loss 0.6865571771349226 | Acc 53.46938775510204\n",
      "Batch 36: loss 0.6863431334495544 | Acc 60.40816326530612\n",
      "Batch 37: loss 0.6862329566800917 | Acc 61.63265306122449\n",
      "Batch 38: loss 0.6863283248324143 | Acc 55.51020408163265\n",
      "Batch 39: loss 0.6863564069454486 | Acc 55.91836734693878\n",
      "Batch 40: loss 0.6863020494580269 | Acc 60.816326530612244\n",
      "Batch 41: loss 0.6862977452394439 | Acc 60.0\n",
      "Batch 42: loss 0.6864842275778452 | Acc 52.6530612244898\n",
      "Batch 43: loss 0.6866391841755357 | Acc 51.83673469387755\n",
      "Batch 44: loss 0.6865577508102764 | Acc 59.591836734693885\n",
      "Batch 45: loss 0.6866442044576009 | Acc 53.46938775510204\n",
      "Batch 46: loss 0.6868095553439596 | Acc 51.42857142857142\n",
      "Batch 47: loss 0.6868234289453384 | Acc 58.77551020408164\n",
      "Batch 48: loss 0.6869058087468147 | Acc 53.06122448979592\n",
      "Batch 49: loss 0.6869323071168394 | Acc 57.95918367346938\n",
      "Batch 50: loss 0.6870786702632904 | Acc 50.61224489795918\n",
      "Batch 51: loss 0.6870971438931484 | Acc 57.55102040816327\n",
      "Batch 52: loss 0.6870836753111619 | Acc 56.734693877551024\n",
      "Batch 53: loss 0.6871565108029347 | Acc 52.6530612244898\n",
      "Batch 54: loss 0.6871772165651675 | Acc 57.14285714285714\n",
      "Batch 55: loss 0.6872316479682923 | Acc 52.244897959183675\n",
      "Batch 56: loss 0.6872024631925991 | Acc 56.734693877551024\n",
      "Batch 57: loss 0.6872110670072991 | Acc 57.95918367346938\n",
      "Batch 58: loss 0.687167042288287 | Acc 57.14285714285714\n",
      "Batch 59: loss 0.6872797931654978 | Acc 50.61224489795918\n",
      "Batch 60: loss 0.687236883242925 | Acc 58.36734693877551\n",
      "Batch 61: loss 0.6872497259593401 | Acc 56.326530612244895\n",
      "Batch 62: loss 0.6872102156762154 | Acc 59.591836734693885\n",
      "Batch 63: loss 0.6871213723742773 | Acc 61.63265306122449\n",
      "Batch 64: loss 0.6871735099703074 | Acc 52.6530612244898\n",
      "Batch 65: loss 0.6872317616756146 | Acc 55.51020408163265\n",
      "Batch 66: loss 0.6872420997330637 | Acc 53.87755102040816\n",
      "Batch 67: loss 0.6873016330733228 | Acc 53.46938775510204\n",
      "Batch 68: loss 0.6872673972564585 | Acc 55.51020408163265\n",
      "Batch 69: loss 0.6874226409456005 | Acc 51.42857142857142\n",
      "Batch 70: loss 0.6874598860740662 | Acc 55.10204081632652\n",
      "Batch 71: loss 0.6873669867784205 | Acc 60.0\n",
      "Batch 72: loss 0.6874775207704968 | Acc 51.02040816326531\n",
      "Batch 73: loss 0.6873758614879765 | Acc 61.63265306122449\n",
      "Batch 74: loss 0.6874596114094192 | Acc 52.6530612244898\n",
      "Batch 75: loss 0.6873890256881714 | Acc 57.55102040816327\n",
      "Batch 76: loss 0.687363959456745 | Acc 58.36734693877551\n",
      "Batch 77: loss 0.6872944738957789 | Acc 58.77551020408164\n",
      "Batch 78: loss 0.6872872473337711 | Acc 56.326530612244895\n",
      "Batch 79: loss 0.6872640410556069 | Acc 57.95918367346938\n",
      "Batch 80: loss 0.6873113811016083 | Acc 55.10204081632652\n",
      "Batch 81: loss 0.6872323766166781 | Acc 62.44897959183674\n",
      "Batch 82: loss 0.6872115796659051 | Acc 57.55102040816327\n",
      "Batch 83: loss 0.6871903761323676 | Acc 58.36734693877551\n",
      "Batch 84: loss 0.6871051639318466 | Acc 61.63265306122449\n",
      "Batch 85: loss 0.6871227678130655 | Acc 51.83673469387755\n",
      "Batch 86: loss 0.686965158512426 | Acc 63.6734693877551\n",
      "Batch 87: loss 0.6870731170150055 | Acc 50.204081632653065\n",
      "Batch 88: loss 0.6869264922358773 | Acc 64.89795918367346\n",
      "Batch 89: loss 0.6870193622085485 | Acc 48.97959183673469\n",
      "Batch 90: loss 0.6869343101978302 | Acc 58.36734693877551\n",
      "Batch 91: loss 0.6867940157324404 | Acc 63.6734693877551\n",
      "Batch 92: loss 0.6868831787420355 | Acc 51.02040816326531\n",
      "Batch 93: loss 0.6867775365870487 | Acc 60.816326530612244\n",
      "Batch 94: loss 0.6869117421038607 | Acc 47.755102040816325\n",
      "Batch 95: loss 0.6867367976590206 | Acc 65.71428571428571\n",
      "Batch 96: loss 0.6868949619432291 | Acc 48.16326530612245\n",
      "Batch 97: loss 0.6866457812564889 | Acc 68.57142857142857\n",
      "Batch 98: loss 0.686875407793084 | Acc 40.0\n",
      "Epoch 3: Training loss 0.686875407793084 | Acc: 55.94752186588921\n",
      "Epoch 3: Validation loss 0.6498899681227548 | Accuracy 77.865889212828 | AUC 0.5201141500427718\n",
      "Best epoch:  2\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.01891488302637, 0.4961423906653175, 0.6495074789698531)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model trained 3 epochs with lr=5e-6, 3 epochs with lr=1e-6, 3 epochs with lr=1e-5\n",
    "mtrainer.run_eval(mtrainer.model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.21353907416626, 0.5099220733360005, 0.6617257754977156)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.cls.state_dict(), 'models/metaclassifier/model/comb3/cls_weights-16.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mtrainer.best_model.attn_model, 'models/metaclassifier/model/comb3/attention-model-8h4l.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.model import ProtoNetAttention\n",
    "\n",
    "device =  get_device()\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "attention = torch.load('models/attention/model/attention-model-8h4l.pth')\n",
    "# imgtxt_encoder, attn_model, class_prototype_aggregator, distance_func\n",
    "model = ProtoNetAttention(encoder, attention, class_prototype_inf, euclidean_distance)\n",
    "mtrainer = ControlledMetaTrainer(model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.encoder.set_trainable(True, True, include_logit_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.model.attn_model.set_trainable(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naomileow/Documents/school/CS6240/project/utils/prototype.py:55: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  classes_count = torch.nonzero(label_inds)[:,1].bincount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.6663146018981934 | Accuracy 81.63265306122449 | AUC 0.5520890348476556\n",
      "Loss 0.6675408482551575 | Accuracy 77.9591836734694 | AUC 0.592805177243311\n",
      "Loss 0.6662786602973938 | Accuracy 80.81632653061224 | AUC 0.5031611300576818\n",
      "Loss 0.6649683117866516 | Accuracy 80.0 | AUC 0.5192899818312419\n",
      "Loss 0.6666518449783325 | Accuracy 80.0 | AUC 0.5661068620956023\n",
      "Loss 0.665653645992279 | Accuracy 80.81632653061224 | AUC 0.5215153647665963\n",
      "Loss 0.6630535125732422 | Accuracy 81.63265306122449 | AUC 0.48086569424007847\n",
      "Loss 0.6627781987190247 | Accuracy 81.63265306122449 | AUC 0.5596055745021262\n",
      "Loss 0.6620592474937439 | Accuracy 82.44897959183673 | AUC 0.45533174308684515\n",
      "Loss 0.6656913161277771 | Accuracy 79.59183673469387 | AUC 0.5300442635824945\n",
      "Loss 0.666347324848175 | Accuracy 81.22448979591836 | AUC 0.5316662740132128\n",
      "Loss 0.6675103306770325 | Accuracy 79.18367346938776 | AUC 0.5914888911229517\n",
      "Loss 0.6687719821929932 | Accuracy 77.9591836734694 | AUC 0.5190180989547633\n",
      "Loss 0.6678135395050049 | Accuracy 81.63265306122449 | AUC 0.5030692436814886\n",
      "Loss 0.6668816804885864 | Accuracy 80.40816326530611 | AUC 0.5499452257997985\n",
      "Loss 0.6622057557106018 | Accuracy 80.40816326530611 | AUC 0.5284938606367178\n",
      "Loss 0.666708767414093 | Accuracy 77.9591836734694 | AUC 0.5530734637166727\n",
      "Loss 0.6685255169868469 | Accuracy 80.40816326530611 | AUC 0.5230501011237175\n",
      "Loss 0.6651032567024231 | Accuracy 79.59183673469387 | AUC 0.5732378830021335\n",
      "Loss 0.6652759909629822 | Accuracy 81.63265306122449 | AUC 0.4988360888466448\n",
      "Loss 0.6661949157714844 | Accuracy 80.0 | AUC 0.4626874657909141\n",
      "Loss 0.6704035401344299 | Accuracy 78.36734693877551 | AUC 0.5474009827845155\n",
      "Loss 0.6634404063224792 | Accuracy 80.0 | AUC 0.5676296117675428\n",
      "Loss 0.6621778607368469 | Accuracy 82.0408163265306 | AUC 0.5448544386698779\n",
      "Loss 0.6679819822311401 | Accuracy 78.77551020408163 | AUC 0.5663474756535981\n",
      "Loss 0.6682234406471252 | Accuracy 79.18367346938776 | AUC 0.5030020295974461\n",
      "Loss 0.6644898056983948 | Accuracy 80.81632653061224 | AUC 0.6171108401843036\n",
      "Loss 0.6677553057670593 | Accuracy 82.44897959183673 | AUC 0.5112857142857143\n",
      "Loss 0.6693733930587769 | Accuracy 79.18367346938776 | AUC 0.5032710700043564\n",
      "Loss 0.6647546887397766 | Accuracy 80.0 | AUC 0.5484820213799806\n",
      "Loss 0.6664096117019653 | Accuracy 78.77551020408163 | AUC 0.5071954022988506\n",
      "Loss 0.670527458190918 | Accuracy 78.36734693877551 | AUC 0.5394795542738168\n",
      "Loss 0.6648236513137817 | Accuracy 79.59183673469387 | AUC 0.5473208095810062\n",
      "Loss 0.6674649119377136 | Accuracy 80.40816326530611 | AUC 0.5394973851939247\n",
      "Loss 0.6685299277305603 | Accuracy 80.40816326530611 | AUC 0.5376157293328301\n",
      "Loss 0.665405809879303 | Accuracy 78.36734693877551 | AUC 0.5307389162561577\n",
      "Loss 0.667019784450531 | Accuracy 80.40816326530611 | AUC 0.4825544476635258\n",
      "Loss 0.6682369112968445 | Accuracy 81.22448979591836 | AUC 0.5543210429417327\n",
      "Loss 0.666824221611023 | Accuracy 80.40816326530611 | AUC 0.5389670676361005\n",
      "Loss 0.6657087802886963 | Accuracy 80.81632653061224 | AUC 0.5367444055749903\n",
      "Loss 0.6671684384346008 | Accuracy 80.0 | AUC 0.5064126537314434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80.15928322548531, 0.5328198297988869, 0.6663182726720485)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(model, mtrainer.test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.37026239067053, 0.5161583489962621, 0.6703500832830157)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainer.run_eval(model, mtrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naomileow/Documents/school/CS6240/project/utils/prototype.py:55: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  classes_count = torch.nonzero(label_inds)[:,1].bincount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.6557514071464539 | Acc 0.6938775510204082\n",
      "Batch 2: loss 0.6739354431629181 | Acc 0.4775510204081633\n",
      "Batch 3: loss 0.6683227817217509 | Acc 0.6204081632653061\n",
      "Batch 4: loss 0.6763685345649719 | Acc 0.4204081632653061\n",
      "Batch 5: loss 0.680125379562378 | Acc 0.4775510204081633\n",
      "Batch 6: loss 0.6733721892038981 | Acc 0.6204081632653061\n",
      "Batch 7: loss 0.6762673003332955 | Acc 0.4897959183673469\n",
      "Batch 8: loss 0.6740930899977684 | Acc 0.5673469387755102\n",
      "Batch 9: loss 0.6698068777720133 | Acc 0.6122448979591837\n",
      "Batch 10: loss 0.6712128102779389 | Acc 0.5224489795918368\n",
      "Batch 11: loss 0.6722890626300465 | Acc 0.5183673469387755\n",
      "Batch 12: loss 0.6703207542498907 | Acc 0.5959183673469388\n",
      "Batch 13: loss 0.6714858687840976 | Acc 0.4897959183673469\n",
      "Batch 14: loss 0.6678845116070339 | Acc 0.6163265306122448\n",
      "Batch 15: loss 0.6657224218050639 | Acc 0.5714285714285714\n",
      "Batch 16: loss 0.6668382249772549 | Acc 0.4897959183673469\n",
      "Batch 17: loss 0.6636558841256535 | Acc 0.6244897959183674\n",
      "Batch 18: loss 0.6653974850972494 | Acc 0.44081632653061226\n",
      "Batch 19: loss 0.6661656655763325 | Acc 0.4816326530612245\n",
      "Batch 20: loss 0.6648231118917465 | Acc 0.6163265306122448\n",
      "Batch 21: loss 0.6627939825966245 | Acc 0.5755102040816327\n",
      "Batch 22: loss 0.6632556888190183 | Acc 0.6\n",
      "Batch 23: loss 0.6636065685230753 | Acc 0.5142857142857142\n",
      "Batch 24: loss 0.6627985537052155 | Acc 0.5714285714285714\n",
      "Batch 25: loss 0.6648533487319946 | Acc 0.49795918367346936\n",
      "Batch 26: loss 0.6630945480786837 | Acc 0.6081632653061224\n",
      "Batch 27: loss 0.6630104449060228 | Acc 0.5469387755102041\n",
      "Batch 28: loss 0.6624583921262196 | Acc 0.563265306122449\n",
      "Batch 29: loss 0.6633479841824236 | Acc 0.5428571428571428\n",
      "Batch 30: loss 0.6618026653925578 | Acc 0.6\n",
      "Batch 31: loss 0.6602345051303986 | Acc 0.5959183673469388\n",
      "Batch 32: loss 0.6612627878785133 | Acc 0.5061224489795918\n",
      "Batch 33: loss 0.6604176308169509 | Acc 0.6122448979591837\n",
      "Batch 34: loss 0.6614934924770804 | Acc 0.4816326530612245\n",
      "Batch 35: loss 0.6625709823199681 | Acc 0.5306122448979592\n",
      "Batch 36: loss 0.6614108615451388 | Acc 0.5836734693877551\n",
      "Batch 37: loss 0.6634007821211944 | Acc 0.4489795918367347\n",
      "Batch 38: loss 0.6622316523602134 | Acc 0.6040816326530613\n",
      "Batch 39: loss 0.6613375147183737 | Acc 0.6040816326530613\n",
      "Batch 40: loss 0.6605346620082855 | Acc 0.6204081632653061\n",
      "Batch 41: loss 0.6620277326281477 | Acc 0.45714285714285713\n",
      "Batch 42: loss 0.6608725317886898 | Acc 0.6285714285714286\n",
      "Batch 43: loss 0.661092548869377 | Acc 0.5877551020408164\n",
      "Batch 44: loss 0.6601704657077789 | Acc 0.5714285714285714\n",
      "Batch 45: loss 0.660970664024353 | Acc 0.4489795918367347\n",
      "Batch 46: loss 0.661817421083865 | Acc 0.5224489795918368\n",
      "Batch 47: loss 0.6635452394789838 | Acc 0.39591836734693875\n",
      "Batch 48: loss 0.6617948388059934 | Acc 0.6979591836734694\n",
      "Batch 49: loss 0.6616927361001774 | Acc 0.5469387755102041\n",
      "Batch 50: loss 0.6623876595497131 | Acc 0.5428571428571428\n",
      "Batch 51: loss 0.6617848136845756 | Acc 0.6\n",
      "Batch 52: loss 0.6620938113102546 | Acc 0.5265306122448979\n",
      "Batch 53: loss 0.6630608147045352 | Acc 0.4857142857142857\n",
      "Batch 54: loss 0.6623294254144033 | Acc 0.6081632653061224\n",
      "Batch 55: loss 0.6618777578527277 | Acc 0.6\n",
      "Batch 56: loss 0.6625278059925351 | Acc 0.4816326530612245\n",
      "Batch 57: loss 0.6623487566646776 | Acc 0.6163265306122448\n",
      "Batch 58: loss 0.6619323923670012 | Acc 0.5346938775510204\n",
      "Batch 59: loss 0.662766853631553 | Acc 0.5224489795918368\n",
      "Batch 60: loss 0.6625618348519008 | Acc 0.5551020408163265\n",
      "Batch 61: loss 0.6606981558877913 | Acc 0.710204081632653\n",
      "Batch 62: loss 0.6614590267981252 | Acc 0.5020408163265306\n",
      "Batch 63: loss 0.6624775472141448 | Acc 0.5142857142857142\n",
      "Batch 64: loss 0.6620799051597714 | Acc 0.5714285714285714\n",
      "Batch 65: loss 0.6617665740159842 | Acc 0.5306122448979592\n",
      "Batch 66: loss 0.6626629386887406 | Acc 0.5469387755102041\n",
      "Batch 67: loss 0.6633131192691291 | Acc 0.5265306122448979\n",
      "Batch 68: loss 0.6630470139138839 | Acc 0.5591836734693878\n",
      "Batch 69: loss 0.663277128468389 | Acc 0.5265306122448979\n",
      "Batch 70: loss 0.6636466239179883 | Acc 0.563265306122449\n",
      "Batch 71: loss 0.664687605810837 | Acc 0.4775510204081633\n",
      "Batch 72: loss 0.6641688115066953 | Acc 0.5551020408163265\n",
      "Batch 73: loss 0.6647116100951417 | Acc 0.5061224489795918\n",
      "Batch 74: loss 0.664156926644815 | Acc 0.6040816326530613\n",
      "Batch 75: loss 0.6634069728851318 | Acc 0.6122448979591837\n",
      "Batch 76: loss 0.6643253211912356 | Acc 0.46530612244897956\n",
      "Batch 77: loss 0.6647061945556046 | Acc 0.5306122448979592\n",
      "Batch 78: loss 0.6645743610003055 | Acc 0.5387755102040817\n",
      "Batch 79: loss 0.6647336935695214 | Acc 0.5142857142857142\n",
      "Batch 80: loss 0.6652034156024456 | Acc 0.5469387755102041\n",
      "Batch 81: loss 0.6649496562686967 | Acc 0.5755102040816327\n",
      "Batch 82: loss 0.665681548961779 | Acc 0.49795918367346936\n",
      "Batch 83: loss 0.666383473988039 | Acc 0.4775510204081633\n",
      "Batch 84: loss 0.665506274217651 | Acc 0.6489795918367347\n",
      "Batch 85: loss 0.665786995607264 | Acc 0.5591836734693878\n",
      "Batch 86: loss 0.6659079928730809 | Acc 0.5142857142857142\n",
      "Batch 87: loss 0.6646722575713848 | Acc 0.6979591836734694\n",
      "Batch 88: loss 0.6652668179436163 | Acc 0.46938775510204084\n",
      "Batch 89: loss 0.6648144661710503 | Acc 0.6204081632653061\n",
      "Batch 90: loss 0.6657019933064778 | Acc 0.4448979591836735\n",
      "Batch 91: loss 0.6663750030182221 | Acc 0.5020408163265306\n",
      "Batch 92: loss 0.6659799619861271 | Acc 0.5714285714285714\n",
      "Batch 93: loss 0.6655044126254256 | Acc 0.5959183673469388\n",
      "Batch 94: loss 0.666087196862444 | Acc 0.5142857142857142\n",
      "Batch 95: loss 0.6655722818876567 | Acc 0.5959183673469388\n",
      "Batch 96: loss 0.6658240656057993 | Acc 0.5551020408163265\n",
      "Batch 97: loss 0.6660782651802928 | Acc 0.49795918367346936\n",
      "Batch 98: loss 0.666350012531086 | Acc 0.563265306122449\n",
      "Epoch 1: Training loss 0.666350012531086 | Acc: 0.5498958767180342\n",
      "Epoch 1: Validation loss 0.5608366642679486 | Accuracy 0.791603498542274 | AUC 0.5566798566896144\n",
      "Batch 1: loss 0.6035547256469727 | Acc 0.6040816326530613\n",
      "Batch 2: loss 0.6290133595466614 | Acc 0.6204081632653061\n",
      "Batch 3: loss 0.6643449664115906 | Acc 0.47346938775510206\n",
      "Batch 4: loss 0.6537256687879562 | Acc 0.5877551020408164\n",
      "Batch 5: loss 0.6463199973106384 | Acc 0.6163265306122448\n",
      "Batch 6: loss 0.6579307417074839 | Acc 0.5061224489795918\n",
      "Batch 7: loss 0.6683066231863839 | Acc 0.4897959183673469\n",
      "Batch 8: loss 0.6639256030321121 | Acc 0.5918367346938775\n",
      "Batch 9: loss 0.6607481439908346 | Acc 0.6448979591836734\n",
      "Batch 10: loss 0.6600608348846435 | Acc 0.5102040816326531\n",
      "Batch 11: loss 0.6673211455345154 | Acc 0.46122448979591835\n",
      "Batch 12: loss 0.660578633348147 | Acc 0.6244897959183674\n",
      "Batch 13: loss 0.6653398137826186 | Acc 0.5224489795918368\n",
      "Batch 14: loss 0.6626013261931283 | Acc 0.5469387755102041\n",
      "Batch 15: loss 0.6594908277193705 | Acc 0.5673469387755102\n",
      "Batch 16: loss 0.6618236303329468 | Acc 0.5346938775510204\n",
      "Batch 17: loss 0.6611696516766268 | Acc 0.5183673469387755\n",
      "Batch 18: loss 0.6655832197931077 | Acc 0.4448979591836735\n",
      "Batch 19: loss 0.6662327113904452 | Acc 0.5224489795918368\n",
      "Batch 20: loss 0.6701372683048248 | Acc 0.4816326530612245\n",
      "Batch 21: loss 0.6723585724830627 | Acc 0.5020408163265306\n",
      "Batch 22: loss 0.6697179620916193 | Acc 0.6244897959183674\n",
      "Batch 23: loss 0.6707942719044893 | Acc 0.5469387755102041\n",
      "Batch 24: loss 0.6692744294802347 | Acc 0.5673469387755102\n",
      "Batch 25: loss 0.6699223613739014 | Acc 0.5591836734693878\n",
      "Batch 26: loss 0.6673725384932297 | Acc 0.5714285714285714\n",
      "Batch 27: loss 0.6656787726614211 | Acc 0.5755102040816327\n",
      "Batch 28: loss 0.6674019758190427 | Acc 0.5265306122448979\n",
      "Batch 29: loss 0.664180079410816 | Acc 0.6448979591836734\n",
      "Batch 30: loss 0.6653270661830902 | Acc 0.5020408163265306\n",
      "Batch 31: loss 0.6664963095418869 | Acc 0.5061224489795918\n",
      "Batch 32: loss 0.6654725186526775 | Acc 0.5836734693877551\n",
      "Batch 33: loss 0.6680488116813429 | Acc 0.42857142857142855\n",
      "Batch 34: loss 0.6661078894839567 | Acc 0.636734693877551\n",
      "Batch 35: loss 0.6665396622249058 | Acc 0.5510204081632653\n",
      "Batch 36: loss 0.6661296288172404 | Acc 0.5469387755102041\n",
      "Batch 37: loss 0.6689334705069259 | Acc 0.4\n",
      "Batch 38: loss 0.6671424335555026 | Acc 0.6040816326530613\n",
      "Batch 39: loss 0.6658101723744319 | Acc 0.563265306122449\n",
      "Batch 40: loss 0.665933395922184 | Acc 0.5836734693877551\n",
      "Batch 41: loss 0.6662559189447542 | Acc 0.5428571428571428\n",
      "Batch 42: loss 0.665770004192988 | Acc 0.5673469387755102\n",
      "Batch 43: loss 0.6671507511028024 | Acc 0.4897959183673469\n",
      "Batch 44: loss 0.6664097200740468 | Acc 0.5836734693877551\n",
      "Batch 45: loss 0.669250468413035 | Acc 0.3877551020408163\n",
      "Batch 46: loss 0.6683569991070292 | Acc 0.5510204081632653\n",
      "Batch 47: loss 0.6696122428204151 | Acc 0.46530612244897956\n",
      "Batch 48: loss 0.6681394030650457 | Acc 0.6285714285714286\n",
      "Batch 49: loss 0.6676229031718507 | Acc 0.6326530612244898\n",
      "Batch 50: loss 0.6666626250743866 | Acc 0.5551020408163265\n",
      "Batch 51: loss 0.6664637537563548 | Acc 0.5836734693877551\n",
      "Batch 52: loss 0.6654247744725301 | Acc 0.5795918367346938\n",
      "Batch 53: loss 0.6674973424875511 | Acc 0.3551020408163265\n",
      "Batch 54: loss 0.6658541825082567 | Acc 0.6816326530612244\n",
      "Batch 55: loss 0.6671157349239696 | Acc 0.45714285714285713\n",
      "Batch 56: loss 0.6652162021824292 | Acc 0.6408163265306123\n",
      "Batch 57: loss 0.665951413020753 | Acc 0.5102040816326531\n",
      "Batch 58: loss 0.6645699246176358 | Acc 0.6285714285714286\n",
      "Batch 59: loss 0.6657667331776377 | Acc 0.44081632653061226\n",
      "Batch 60: loss 0.6648689081271489 | Acc 0.6326530612244898\n",
      "Batch 61: loss 0.6634870611253332 | Acc 0.6040816326530613\n",
      "Batch 62: loss 0.6639817731995736 | Acc 0.5102040816326531\n",
      "Batch 63: loss 0.6631625890731812 | Acc 0.5877551020408164\n",
      "Batch 64: loss 0.6638980070129037 | Acc 0.5306122448979592\n",
      "Batch 65: loss 0.6629553804030786 | Acc 0.5551020408163265\n",
      "Batch 66: loss 0.6629544433319208 | Acc 0.5673469387755102\n",
      "Batch 67: loss 0.6612340843499597 | Acc 0.6857142857142857\n",
      "Batch 68: loss 0.6625394119935877 | Acc 0.42448979591836733\n",
      "Batch 69: loss 0.6633560994397039 | Acc 0.4857142857142857\n",
      "Batch 70: loss 0.6619527050427028 | Acc 0.6571428571428571\n",
      "Batch 71: loss 0.6625976436574694 | Acc 0.5183673469387755\n",
      "Batch 72: loss 0.66156907296843 | Acc 0.6204081632653061\n",
      "Batch 73: loss 0.6610167753206541 | Acc 0.5551020408163265\n",
      "Batch 74: loss 0.6617215348256601 | Acc 0.5183673469387755\n",
      "Batch 75: loss 0.6620132811864217 | Acc 0.5469387755102041\n",
      "Batch 76: loss 0.661444720469023 | Acc 0.5428571428571428\n",
      "Batch 77: loss 0.6627282956977943 | Acc 0.40816326530612246\n",
      "Batch 78: loss 0.6618675482578766 | Acc 0.6081632653061224\n",
      "Batch 79: loss 0.6611781339102154 | Acc 0.5959183673469388\n",
      "Batch 80: loss 0.661841569840908 | Acc 0.47346938775510206\n",
      "Batch 81: loss 0.6615081812128608 | Acc 0.5061224489795918\n",
      "Batch 82: loss 0.6617554716947602 | Acc 0.5551020408163265\n",
      "Batch 83: loss 0.661096998726029 | Acc 0.6326530612244898\n",
      "Batch 84: loss 0.6617628158557982 | Acc 0.46938775510204084\n",
      "Batch 85: loss 0.6613656387609594 | Acc 0.5306122448979592\n",
      "Batch 86: loss 0.6610293215097383 | Acc 0.6244897959183674\n",
      "Batch 87: loss 0.6600374476662998 | Acc 0.6040816326530613\n",
      "Batch 88: loss 0.6602209041064436 | Acc 0.563265306122449\n",
      "Batch 89: loss 0.6603514076618666 | Acc 0.5795918367346938\n",
      "Batch 90: loss 0.6597302224900987 | Acc 0.5551020408163265\n",
      "Batch 91: loss 0.6589316660231286 | Acc 0.6448979591836734\n",
      "Batch 92: loss 0.6597090208012125 | Acc 0.4448979591836735\n",
      "Batch 93: loss 0.6589948041464693 | Acc 0.6244897959183674\n",
      "Batch 94: loss 0.6597694234645113 | Acc 0.4530612244897959\n",
      "Batch 95: loss 0.6591194341057225 | Acc 0.6040816326530613\n",
      "Batch 96: loss 0.6595905379702648 | Acc 0.5020408163265306\n",
      "Batch 97: loss 0.659196830901903 | Acc 0.5551020408163265\n",
      "Batch 98: loss 0.6599312588876608 | Acc 0.42857142857142855\n",
      "Epoch 2: Training loss 0.6599312588876608 | Acc: 0.5477717617659308\n",
      "Epoch 2: Validation loss 0.5618419902665275 | Accuracy 0.7919533527696793 | AUC 0.5708627555692818\n",
      "Batch 1: loss 0.6810908317565918 | Acc 0.5551020408163265\n",
      "Batch 2: loss 0.6300989985466003 | Acc 0.636734693877551\n",
      "Batch 3: loss 0.6624711751937866 | Acc 0.47346938775510206\n",
      "Batch 4: loss 0.6466571241617203 | Acc 0.6\n",
      "Batch 5: loss 0.6426498413085937 | Acc 0.5469387755102041\n",
      "Batch 6: loss 0.6471070150534312 | Acc 0.5755102040816327\n",
      "Batch 7: loss 0.6468228101730347 | Acc 0.5795918367346938\n",
      "Batch 8: loss 0.6479665488004684 | Acc 0.5551020408163265\n",
      "Batch 9: loss 0.6512651046117147 | Acc 0.5591836734693878\n",
      "Batch 10: loss 0.646141129732132 | Acc 0.5673469387755102\n",
      "Batch 11: loss 0.6439377286217429 | Acc 0.5428571428571428\n",
      "Batch 12: loss 0.6477072636286417 | Acc 0.5142857142857142\n",
      "Batch 13: loss 0.6498734675920926 | Acc 0.5346938775510204\n",
      "Batch 14: loss 0.6460939262594495 | Acc 0.6122448979591837\n",
      "Batch 15: loss 0.6507611155509949 | Acc 0.49387755102040815\n",
      "Batch 16: loss 0.6458162628114223 | Acc 0.6204081632653061\n",
      "Batch 17: loss 0.6408365824643303 | Acc 0.6448979591836734\n",
      "Batch 18: loss 0.6463697387112511 | Acc 0.45714285714285713\n",
      "Batch 19: loss 0.6451636866519326 | Acc 0.5714285714285714\n",
      "Batch 20: loss 0.6480991423130036 | Acc 0.5183673469387755\n",
      "Batch 21: loss 0.6455980681237721 | Acc 0.5673469387755102\n",
      "Batch 22: loss 0.646802238442681 | Acc 0.5836734693877551\n",
      "Batch 23: loss 0.6440034275469573 | Acc 0.6\n",
      "Batch 24: loss 0.6459568018714587 | Acc 0.5265306122448979\n",
      "Batch 25: loss 0.6430551052093506 | Acc 0.6448979591836734\n",
      "Batch 26: loss 0.645838703100498 | Acc 0.4775510204081633\n",
      "Batch 27: loss 0.6481765089211641 | Acc 0.5102040816326531\n",
      "Batch 28: loss 0.6472585712160382 | Acc 0.5469387755102041\n",
      "Batch 29: loss 0.6452875507288965 | Acc 0.5795918367346938\n",
      "Batch 30: loss 0.6471594532330831 | Acc 0.49795918367346936\n",
      "Batch 31: loss 0.649985263424535 | Acc 0.4816326530612245\n",
      "Batch 32: loss 0.6488004717975855 | Acc 0.5918367346938775\n",
      "Batch 33: loss 0.6508025039326061 | Acc 0.47346938775510206\n",
      "Batch 34: loss 0.6493935865514419 | Acc 0.6\n",
      "Batch 35: loss 0.6512067437171936 | Acc 0.45714285714285713\n",
      "Batch 36: loss 0.6504741377300687 | Acc 0.5755102040816327\n",
      "Batch 37: loss 0.6508907160243472 | Acc 0.5673469387755102\n",
      "Batch 38: loss 0.6503075941612846 | Acc 0.5551020408163265\n",
      "Batch 39: loss 0.648099266565763 | Acc 0.6448979591836734\n",
      "Batch 40: loss 0.6495173320174217 | Acc 0.5020408163265306\n",
      "Batch 41: loss 0.6473232871148644 | Acc 0.6489795918367347\n",
      "Batch 42: loss 0.6490134795506796 | Acc 0.46530612244897956\n",
      "Batch 43: loss 0.6487417955731236 | Acc 0.6204081632653061\n",
      "Batch 44: loss 0.6482117203148928 | Acc 0.5061224489795918\n",
      "Batch 45: loss 0.6501271433300442 | Acc 0.44081632653061226\n",
      "Batch 46: loss 0.6489555913469066 | Acc 0.6\n",
      "Batch 47: loss 0.6501894187419972 | Acc 0.4816326530612245\n",
      "Batch 48: loss 0.6488196092347304 | Acc 0.6122448979591837\n",
      "Batch 49: loss 0.6496533325740269 | Acc 0.5469387755102041\n",
      "Batch 50: loss 0.6484133541584015 | Acc 0.6040816326530613\n",
      "Batch 51: loss 0.6466298757814893 | Acc 0.6285714285714286\n",
      "Batch 52: loss 0.6474670320749283 | Acc 0.5265306122448979\n",
      "Batch 53: loss 0.6492073682119262 | Acc 0.4448979591836735\n",
      "Batch 54: loss 0.6478074921502007 | Acc 0.6489795918367347\n",
      "Batch 55: loss 0.6486643260175532 | Acc 0.5183673469387755\n",
      "Batch 56: loss 0.6480673306754657 | Acc 0.5551020408163265\n",
      "Batch 57: loss 0.6496826389379668 | Acc 0.43673469387755104\n",
      "Batch 58: loss 0.6481727073932516 | Acc 0.6693877551020408\n",
      "Batch 59: loss 0.6494364081803015 | Acc 0.4857142857142857\n",
      "Batch 60: loss 0.6480647504329682 | Acc 0.6081632653061224\n",
      "Batch 61: loss 0.6469477463941105 | Acc 0.5918367346938775\n",
      "Batch 62: loss 0.6473967086884284 | Acc 0.5387755102040817\n",
      "Batch 63: loss 0.6468664880782838 | Acc 0.5836734693877551\n",
      "Batch 64: loss 0.6475765304639935 | Acc 0.5183673469387755\n",
      "Batch 65: loss 0.6476249621464656 | Acc 0.49795918367346936\n",
      "Batch 66: loss 0.648023351575389 | Acc 0.5551020408163265\n",
      "Batch 67: loss 0.6490063311448738 | Acc 0.5265306122448979\n",
      "Batch 68: loss 0.648094513837029 | Acc 0.5714285714285714\n",
      "Batch 69: loss 0.6462712892587634 | Acc 0.6979591836734694\n",
      "Batch 70: loss 0.6472676830632346 | Acc 0.4489795918367347\n",
      "Batch 71: loss 0.6460720401414684 | Acc 0.6\n",
      "Batch 72: loss 0.6467182288567225 | Acc 0.5142857142857142\n",
      "Batch 73: loss 0.6457280884050343 | Acc 0.5918367346938775\n",
      "Batch 74: loss 0.6461761803240389 | Acc 0.5469387755102041\n",
      "Batch 75: loss 0.6454101022084554 | Acc 0.6122448979591837\n",
      "Batch 76: loss 0.6464766593355882 | Acc 0.44081632653061226\n",
      "Batch 77: loss 0.6457331459243576 | Acc 0.5836734693877551\n",
      "Batch 78: loss 0.6461457442014645 | Acc 0.5387755102040817\n",
      "Batch 79: loss 0.6452129234241534 | Acc 0.6326530612244898\n",
      "Batch 80: loss 0.6460121855139732 | Acc 0.4857142857142857\n",
      "Batch 81: loss 0.6465496207460945 | Acc 0.5346938775510204\n",
      "Batch 82: loss 0.6463673841662523 | Acc 0.5183673469387755\n",
      "Batch 83: loss 0.6472234050911593 | Acc 0.49795918367346936\n",
      "Batch 84: loss 0.6465134003332683 | Acc 0.6\n",
      "Batch 85: loss 0.6452966886408189 | Acc 0.6612244897959184\n",
      "Batch 86: loss 0.6462043357449908 | Acc 0.4775510204081633\n",
      "Batch 87: loss 0.6452691102850026 | Acc 0.6285714285714286\n",
      "Batch 88: loss 0.6461099691011689 | Acc 0.47346938775510206\n",
      "Batch 89: loss 0.6466253989198235 | Acc 0.5306122448979592\n",
      "Batch 90: loss 0.6457425316174825 | Acc 0.6040816326530613\n",
      "Batch 91: loss 0.6455970675080687 | Acc 0.5346938775510204\n",
      "Batch 92: loss 0.6457627778467925 | Acc 0.5265306122448979\n",
      "Batch 93: loss 0.6459347355750299 | Acc 0.5673469387755102\n",
      "Batch 94: loss 0.6454721689224243 | Acc 0.5673469387755102\n",
      "Batch 95: loss 0.6448931386596278 | Acc 0.5224489795918368\n",
      "Batch 96: loss 0.645555512358745 | Acc 0.5346938775510204\n",
      "Batch 97: loss 0.6454912897237798 | Acc 0.5102040816326531\n",
      "Batch 98: loss 0.6460431856768472 | Acc 0.5102040816326531\n",
      "Epoch 3: Training loss 0.6460431856768472 | Acc: 0.5517284464806328\n",
      "Epoch 3: Validation loss 0.5621310608727591 | Accuracy 0.7914868804664722 | AUC 0.5900183985875422\n",
      "Best epoch:  2\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(1.0008, device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(mtrainer.best_model.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.model, mtrainer.create_query_eval_dataloader('train'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.val_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainer.run_eval(mtrainer.best_model, mtrainer.test_loader, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result of training backbone for 3 iterations\n",
    "Training Query set: 0.5583506872136611\n",
    "Test set:\n",
    "Validation set:\n",
    "\n",
    "\n",
    "#### Result of attention for 3 iterations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments on baseline models without attention\n",
    "### RelationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import RelationNet\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = RelationNet(encoder, 512, class_prototype_inf, fc_hidden_size=16)\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.01457725947522, 0.5016376709062274, 0.6972464016505651)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.079641612742655, 0.5146355623202179, 0.6978601042817278)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss 0.679679274559021 | Acc 68.16326530612244\n",
      "Batch 2: loss 0.6872178614139557 | Acc 48.16326530612245\n",
      "Batch 3: loss 0.6854563554128011 | Acc 63.6734693877551\n",
      "Batch 4: loss 0.6872857213020325 | Acc 53.46938775510204\n",
      "Batch 5: loss 0.6890603423118591 | Acc 52.6530612244898\n",
      "Batch 6: loss 0.687427838643392 | Acc 66.12244897959184\n",
      "Batch 7: loss 0.6865879552704948 | Acc 62.04081632653061\n",
      "Batch 8: loss 0.6865909770131111 | Acc 61.224489795918366\n",
      "Batch 9: loss 0.6880093084441291 | Acc 43.673469387755105\n",
      "Batch 10: loss 0.6870020091533661 | Acc 68.57142857142857\n",
      "Batch 11: loss 0.6873770952224731 | Acc 53.87755102040816\n",
      "Batch 12: loss 0.6869907428820928 | Acc 61.63265306122449\n",
      "Batch 13: loss 0.6864107847213745 | Acc 69.38775510204081\n",
      "Batch 14: loss 0.6862963523183551 | Acc 58.77551020408164\n",
      "Batch 15: loss 0.6861640095710755 | Acc 60.0\n",
      "Batch 16: loss 0.6858026422560215 | Acc 64.08163265306122\n",
      "Batch 17: loss 0.68585064831902 | Acc 57.14285714285714\n",
      "Batch 18: loss 0.6858793861336179 | Acc 58.77551020408164\n",
      "Batch 19: loss 0.6854901721602992 | Acc 66.12244897959184\n",
      "Batch 20: loss 0.6862986445426941 | Acc 44.89795918367347\n",
      "Batch 21: loss 0.6859852983838036 | Acc 61.224489795918366\n",
      "Batch 22: loss 0.6863649026914076 | Acc 49.795918367346935\n",
      "Batch 23: loss 0.6859448733537094 | Acc 66.12244897959184\n",
      "Batch 24: loss 0.6861392507950465 | Acc 51.42857142857142\n",
      "Batch 25: loss 0.686033296585083 | Acc 62.04081632653061\n",
      "Batch 26: loss 0.6860054868918198 | Acc 58.36734693877551\n",
      "Batch 27: loss 0.6862060317286739 | Acc 51.02040816326531\n",
      "Batch 28: loss 0.6860193014144897 | Acc 65.3061224489796\n",
      "Batch 29: loss 0.685966446481902 | Acc 60.816326530612244\n",
      "Batch 30: loss 0.6861148258050283 | Acc 53.46938775510204\n",
      "Batch 31: loss 0.6861777171011894 | Acc 57.95918367346938\n",
      "Batch 32: loss 0.6859908066689968 | Acc 63.6734693877551\n",
      "Batch 33: loss 0.6863168929562424 | Acc 50.61224489795918\n",
      "Batch 34: loss 0.686203122138977 | Acc 61.63265306122449\n",
      "Batch 35: loss 0.6862580265317645 | Acc 57.95918367346938\n",
      "Batch 36: loss 0.6861586521069208 | Acc 62.04081632653061\n",
      "Batch 37: loss 0.6860735803037077 | Acc 62.44897959183674\n",
      "Batch 38: loss 0.6862599112485585 | Acc 52.6530612244898\n",
      "Batch 39: loss 0.6862701559678103 | Acc 56.326530612244895\n",
      "Batch 40: loss 0.6861455470323563 | Acc 61.63265306122449\n",
      "Batch 41: loss 0.6859097175481843 | Acc 67.75510204081633\n",
      "Batch 42: loss 0.6861493488152822 | Acc 53.06122448979592\n",
      "Batch 43: loss 0.6861644262491271 | Acc 60.40816326530612\n",
      "Batch 44: loss 0.6861361319368536 | Acc 59.183673469387756\n",
      "Batch 45: loss 0.6859990000724793 | Acc 61.63265306122449\n",
      "Batch 46: loss 0.6862297472746476 | Acc 49.795918367346935\n",
      "Batch 47: loss 0.6861953646578687 | Acc 59.183673469387756\n",
      "Batch 48: loss 0.686012198527654 | Acc 64.48979591836735\n",
      "Batch 49: loss 0.6861263756849327 | Acc 54.69387755102041\n",
      "Batch 50: loss 0.6861001336574555 | Acc 62.04081632653061\n",
      "Batch 51: loss 0.6860652636079227 | Acc 61.224489795918366\n",
      "Batch 52: loss 0.6862311775867755 | Acc 49.38775510204081\n",
      "Batch 53: loss 0.6861241606046569 | Acc 63.26530612244898\n",
      "Batch 54: loss 0.686188409725825 | Acc 54.69387755102041\n",
      "Batch 55: loss 0.6860619924285195 | Acc 67.3469387755102\n",
      "Batch 56: loss 0.6862971314362117 | Acc 46.12244897959184\n",
      "Batch 57: loss 0.6864463132724428 | Acc 52.244897959183675\n",
      "Batch 58: loss 0.6862736775957304 | Acc 71.0204081632653\n",
      "Batch 59: loss 0.6864105180158453 | Acc 48.97959183673469\n",
      "Batch 60: loss 0.6862976471583049 | Acc 64.08163265306122\n",
      "Batch 61: loss 0.6862442933145116 | Acc 65.3061224489796\n",
      "Batch 62: loss 0.6862541619808443 | Acc 59.591836734693885\n",
      "Batch 63: loss 0.686182281327626 | Acc 61.63265306122449\n",
      "Batch 64: loss 0.6862784456461668 | Acc 53.06122448979592\n",
      "Batch 65: loss 0.6863786605688241 | Acc 51.02040816326531\n",
      "Batch 66: loss 0.6862714380928965 | Acc 67.3469387755102\n",
      "Batch 67: loss 0.6862880925634014 | Acc 62.44897959183674\n",
      "Batch 68: loss 0.6862285522853627 | Acc 60.816326530612244\n",
      "Batch 69: loss 0.6861109215280284 | Acc 66.53061224489795\n",
      "Batch 70: loss 0.6861976223332541 | Acc 53.87755102040816\n",
      "Batch 71: loss 0.6861527453006153 | Acc 62.04081632653061\n",
      "Batch 72: loss 0.6862441193726327 | Acc 56.734693877551024\n",
      "Batch 73: loss 0.68622157181779 | Acc 63.26530612244898\n",
      "Batch 74: loss 0.6862205726069373 | Acc 60.0\n",
      "Batch 75: loss 0.686271653175354 | Acc 55.10204081632652\n",
      "Batch 76: loss 0.6862196977201261 | Acc 64.89795918367346\n",
      "Batch 77: loss 0.6862564938408988 | Acc 56.326530612244895\n",
      "Batch 78: loss 0.6862516372631757 | Acc 55.51020408163265\n",
      "Batch 79: loss 0.6861759967441801 | Acc 62.857142857142854\n",
      "Batch 80: loss 0.6861750558018684 | Acc 57.95918367346938\n",
      "Batch 81: loss 0.6861522094703015 | Acc 59.183673469387756\n",
      "Batch 82: loss 0.6861482168116221 | Acc 60.0\n",
      "Batch 83: loss 0.6861032944127737 | Acc 62.44897959183674\n",
      "Batch 84: loss 0.6860755085945129 | Acc 62.857142857142854\n",
      "Batch 85: loss 0.6860248292193694 | Acc 62.04081632653061\n",
      "Batch 86: loss 0.6861230093379354 | Acc 52.6530612244898\n",
      "Batch 87: loss 0.6861885011881247 | Acc 56.734693877551024\n",
      "Batch 88: loss 0.6861094988205216 | Acc 61.224489795918366\n",
      "Batch 89: loss 0.68607506390368 | Acc 62.04081632653061\n",
      "Batch 90: loss 0.6861249347527821 | Acc 53.87755102040816\n",
      "Batch 91: loss 0.6861159172686901 | Acc 60.816326530612244\n",
      "Batch 92: loss 0.6860519757737285 | Acc 65.3061224489796\n",
      "Batch 93: loss 0.6859866220463988 | Acc 65.3061224489796\n",
      "Batch 94: loss 0.6861258650079687 | Acc 43.673469387755105\n",
      "Batch 95: loss 0.6860519440550553 | Acc 65.71428571428571\n",
      "Batch 96: loss 0.6861012056469917 | Acc 55.10204081632652\n",
      "Batch 97: loss 0.6860048598849896 | Acc 67.75510204081633\n",
      "Batch 98: loss 0.6860991783288061 | Acc 49.38775510204081\n",
      "Epoch 1: Training loss 0.6860991783288061 | Acc: 59.00041649312786\n",
      "Epoch 1: Validation loss 0.6726657918521336 | Accuracy 72.32653061224488 | AUC 0.5241775528725205\n",
      "Batch 1: loss 0.6899733543395996 | Acc 54.285714285714285\n",
      "Batch 2: loss 0.6848945617675781 | Acc 67.3469387755102\n",
      "Batch 3: loss 0.6872022151947021 | Acc 53.87755102040816\n",
      "Batch 4: loss 0.6855256259441376 | Acc 63.26530612244898\n",
      "Batch 5: loss 0.6869061946868896 | Acc 52.6530612244898\n",
      "Batch 6: loss 0.6860408782958984 | Acc 64.08163265306122\n",
      "Batch 7: loss 0.6859152657645089 | Acc 60.40816326530612\n",
      "Batch 8: loss 0.6862817108631134 | Acc 57.55102040816327\n",
      "Batch 9: loss 0.6853578156895108 | Acc 64.89795918367346\n",
      "Batch 10: loss 0.6863217055797577 | Acc 49.795918367346935\n",
      "Batch 11: loss 0.6860607970844615 | Acc 57.95918367346938\n",
      "Batch 12: loss 0.6865395605564117 | Acc 52.244897959183675\n",
      "Batch 13: loss 0.686865169268388 | Acc 52.244897959183675\n",
      "Batch 14: loss 0.6866682640143803 | Acc 61.63265306122449\n",
      "Batch 15: loss 0.6859461307525635 | Acc 68.57142857142857\n",
      "Batch 16: loss 0.6864418983459473 | Acc 51.02040816326531\n",
      "Batch 17: loss 0.6866597638410681 | Acc 55.51020408163265\n",
      "Batch 18: loss 0.6862850354777442 | Acc 61.63265306122449\n",
      "Batch 19: loss 0.6866826603287145 | Acc 50.61224489795918\n",
      "Batch 20: loss 0.6863340169191361 | Acc 66.53061224489795\n",
      "Batch 21: loss 0.6861436452184405 | Acc 62.04081632653061\n",
      "Batch 22: loss 0.6859120672399347 | Acc 62.44897959183674\n",
      "Batch 23: loss 0.6858772013498389 | Acc 60.816326530612244\n",
      "Batch 24: loss 0.685884435971578 | Acc 57.95918367346938\n",
      "Batch 25: loss 0.6857252860069275 | Acc 62.04081632653061\n",
      "Batch 26: loss 0.6856267704413488 | Acc 59.591836734693885\n",
      "Batch 27: loss 0.6855097457214638 | Acc 61.224489795918366\n",
      "Batch 28: loss 0.6857226107801709 | Acc 49.38775510204081\n",
      "Batch 29: loss 0.6858627940046376 | Acc 56.734693877551024\n",
      "Batch 30: loss 0.6856659690539042 | Acc 67.3469387755102\n",
      "Batch 31: loss 0.6859661802168815 | Acc 51.83673469387755\n",
      "Batch 32: loss 0.6856746152043343 | Acc 63.26530612244898\n",
      "Batch 33: loss 0.6855620723782163 | Acc 63.6734693877551\n",
      "Batch 34: loss 0.6858321936691508 | Acc 49.795918367346935\n",
      "Batch 35: loss 0.6857544541358948 | Acc 64.08163265306122\n",
      "Batch 36: loss 0.6858676986561881 | Acc 56.326530612244895\n",
      "Batch 37: loss 0.6857975028656624 | Acc 61.224489795918366\n",
      "Batch 38: loss 0.6859246241418939 | Acc 53.46938775510204\n",
      "Batch 39: loss 0.6860489952258575 | Acc 53.87755102040816\n",
      "Batch 40: loss 0.685893501341343 | Acc 66.53061224489795\n",
      "Batch 41: loss 0.6861743389106378 | Acc 50.61224489795918\n",
      "Batch 42: loss 0.6860205474353972 | Acc 65.3061224489796\n",
      "Batch 43: loss 0.6860861584197643 | Acc 55.91836734693878\n",
      "Batch 44: loss 0.6860133897174489 | Acc 62.857142857142854\n",
      "Batch 45: loss 0.6858252022001479 | Acc 64.89795918367346\n",
      "Batch 46: loss 0.6859711343827455 | Acc 50.61224489795918\n",
      "Batch 47: loss 0.6859812153146622 | Acc 56.734693877551024\n",
      "Batch 48: loss 0.6858579479157925 | Acc 62.04081632653061\n",
      "Batch 49: loss 0.6859530271316061 | Acc 55.91836734693878\n",
      "Batch 50: loss 0.6858721387386322 | Acc 63.6734693877551\n",
      "Batch 51: loss 0.6858368457532397 | Acc 64.48979591836735\n",
      "Batch 52: loss 0.6859973932688053 | Acc 53.06122448979592\n",
      "Batch 53: loss 0.6858971591265697 | Acc 62.04081632653061\n",
      "Batch 54: loss 0.6858683062924279 | Acc 61.224489795918366\n",
      "Batch 55: loss 0.6857433427463878 | Acc 67.3469387755102\n",
      "Batch 56: loss 0.6858252968106952 | Acc 56.734693877551024\n",
      "Batch 57: loss 0.6859765429245798 | Acc 51.42857142857142\n",
      "Batch 58: loss 0.68581030183825 | Acc 67.3469387755102\n",
      "Batch 59: loss 0.6857508693711233 | Acc 64.08163265306122\n",
      "Batch 60: loss 0.6859213650226593 | Acc 48.97959183673469\n",
      "Batch 61: loss 0.6857789432416197 | Acc 67.75510204081633\n",
      "Batch 62: loss 0.6859360981372095 | Acc 53.46938775510204\n",
      "Batch 63: loss 0.6862099804575481 | Acc 42.857142857142854\n",
      "Batch 64: loss 0.6861227620393038 | Acc 62.44897959183674\n",
      "Batch 65: loss 0.6860559206742507 | Acc 63.26530612244898\n",
      "Batch 66: loss 0.6861024074482195 | Acc 55.91836734693878\n",
      "Batch 67: loss 0.6861351826297704 | Acc 57.14285714285714\n",
      "Batch 68: loss 0.6860616540207582 | Acc 68.16326530612244\n",
      "Batch 69: loss 0.6860747415086498 | Acc 58.36734693877551\n",
      "Batch 70: loss 0.6860257744789123 | Acc 60.816326530612244\n",
      "Batch 71: loss 0.6860919880195403 | Acc 54.69387755102041\n",
      "Batch 72: loss 0.6860605171985097 | Acc 61.224489795918366\n",
      "Batch 73: loss 0.6862136101069516 | Acc 48.57142857142857\n",
      "Batch 74: loss 0.6861263231651203 | Acc 65.3061224489796\n",
      "Batch 75: loss 0.6863530548413594 | Acc 42.857142857142854\n",
      "Batch 76: loss 0.6862286290055827 | Acc 68.57142857142857\n",
      "Batch 77: loss 0.6861827381245502 | Acc 61.224489795918366\n",
      "Batch 78: loss 0.686274915933609 | Acc 52.244897959183675\n",
      "Batch 79: loss 0.6864111906365503 | Acc 46.93877551020408\n",
      "Batch 80: loss 0.686340344697237 | Acc 63.26530612244898\n",
      "Batch 81: loss 0.6862710979249742 | Acc 63.26530612244898\n",
      "Batch 82: loss 0.6863599157914883 | Acc 50.61224489795918\n",
      "Batch 83: loss 0.686479854296489 | Acc 50.61224489795918\n",
      "Batch 84: loss 0.6863823980093002 | Acc 66.53061224489795\n",
      "Batch 85: loss 0.6864506812656627 | Acc 53.06122448979592\n",
      "Batch 86: loss 0.6864142806030983 | Acc 61.224489795918366\n",
      "Batch 87: loss 0.6863265106047707 | Acc 60.816326530612244\n",
      "Batch 88: loss 0.6863647658716548 | Acc 54.285714285714285\n",
      "Batch 89: loss 0.6863426720158438 | Acc 57.55102040816327\n",
      "Batch 90: loss 0.6863557325469123 | Acc 55.51020408163265\n",
      "Batch 91: loss 0.6863161685702565 | Acc 60.816326530612244\n",
      "Batch 92: loss 0.6863045634134955 | Acc 60.0\n",
      "Batch 93: loss 0.6863105207361201 | Acc 55.51020408163265\n",
      "Batch 94: loss 0.6862852719235928 | Acc 63.6734693877551\n",
      "Batch 95: loss 0.6862719134280556 | Acc 61.63265306122449\n",
      "Batch 96: loss 0.6862260227402052 | Acc 62.857142857142854\n",
      "Batch 97: loss 0.686230236722022 | Acc 57.55102040816327\n",
      "Batch 98: loss 0.6862373169587583 | Acc 59.183673469387756\n",
      "Epoch 2: Training loss 0.6862373169587583 | Acc: 58.621407746772135\n",
      "Epoch 2: Validation loss 0.6721009288515364 | Accuracy 72.36151603498544 | AUC 0.5239913606961554\n",
      "Best epoch:  2\n"
     ]
    }
   ],
   "source": [
    "btrainer.run_train(2, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.12827988338194, 0.5262049313442498, 0.6789789761815752)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70.60228969636637, 0.5078939691060346, 0.6737378544923736)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.best_model, btrainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(btrainer.best_model.cls.state_dict(), 'relnet_weights-16.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import ProtoNet\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = ProtoNet(encoder, class_prototype_inf, euclidean_distance, trainable_base=False)\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.val_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5569669604301453 | Accuracy 79.59183673469387 | AUC 0.6209134773272705\n",
      "Loss 0.5399513244628906 | Accuracy 79.59183673469387 | AUC 0.6711944518066967\n",
      "Loss 0.5567415356636047 | Accuracy 80.40816326530611 | AUC 0.5641938202283031\n",
      "Loss 0.5585796236991882 | Accuracy 78.36734693877551 | AUC 0.6835645847945377\n",
      "Loss 0.5578333735466003 | Accuracy 80.81632653061224 | AUC 0.6120503887997691\n",
      "Loss 0.5560277104377747 | Accuracy 79.59183673469387 | AUC 0.5566583374979178\n",
      "Loss 0.5344257950782776 | Accuracy 80.81632653061224 | AUC 0.6238864838864838\n",
      "Loss 0.5641512870788574 | Accuracy 79.18367346938776 | AUC 0.5742744103968594\n",
      "Loss 0.5355821251869202 | Accuracy 79.59183673469387 | AUC 0.6636724640595155\n",
      "Loss 0.5311662554740906 | Accuracy 80.81632653061224 | AUC 0.6199343504515918\n",
      "Loss 0.553301215171814 | Accuracy 79.59183673469387 | AUC 0.605984796864459\n",
      "Loss 0.5594642162322998 | Accuracy 82.0408163265306 | AUC 0.6736303714032197\n",
      "Loss 0.5388792753219604 | Accuracy 80.40816326530611 | AUC 0.5890472839382059\n",
      "Loss 0.5470589995384216 | Accuracy 79.59183673469387 | AUC 0.673080995945176\n",
      "Loss 0.5667111277580261 | Accuracy 78.36734693877551 | AUC 0.60029633202047\n",
      "Loss 0.5544089674949646 | Accuracy 79.18367346938776 | AUC 0.6478960155490768\n",
      "Loss 0.5280553698539734 | Accuracy 81.22448979591836 | AUC 0.6024616124616126\n",
      "Loss 0.5454680323600769 | Accuracy 80.0 | AUC 0.5712762731041348\n",
      "Loss 0.5616838335990906 | Accuracy 78.77551020408163 | AUC 0.5790068027210884\n",
      "Loss 0.5658369660377502 | Accuracy 80.40816326530611 | AUC 0.628787702013655\n",
      "Loss 0.5615301728248596 | Accuracy 78.36734693877551 | AUC 0.5520775415061129\n",
      "Loss 0.5375939011573792 | Accuracy 78.77551020408163 | AUC 0.6370870625293416\n",
      "Loss 0.5495061874389648 | Accuracy 79.59183673469387 | AUC 0.6445158524328124\n",
      "Loss 0.5476319193840027 | Accuracy 78.77551020408163 | AUC 0.673220292950428\n",
      "Loss 0.5323706865310669 | Accuracy 82.44897959183673 | AUC 0.6151746529332736\n",
      "Loss 0.5520763993263245 | Accuracy 80.0 | AUC 0.5912921818973895\n",
      "Loss 0.5558860898017883 | Accuracy 77.9591836734694 | AUC 0.6224105137612119\n",
      "Loss 0.5429625511169434 | Accuracy 80.81632653061224 | AUC 0.6356835501663088\n",
      "Loss 0.5392792820930481 | Accuracy 80.81632653061224 | AUC 0.6014689461241185\n",
      "Loss 0.5720858573913574 | Accuracy 78.36734693877551 | AUC 0.5706607034828451\n",
      "Loss 0.559914231300354 | Accuracy 79.18367346938776 | AUC 0.6630744917761104\n",
      "Loss 0.5597913861274719 | Accuracy 78.36734693877551 | AUC 0.6263123275192239\n",
      "Loss 0.5656315684318542 | Accuracy 78.77551020408163 | AUC 0.604475995503441\n",
      "Loss 0.5459438562393188 | Accuracy 81.22448979591836 | AUC 0.5889934650279478\n",
      "Loss 0.5272388458251953 | Accuracy 81.22448979591836 | AUC 0.6056940505216367\n",
      "Loss 0.5570147633552551 | Accuracy 80.0 | AUC 0.6454975282038282\n",
      "Loss 0.5399886965751648 | Accuracy 82.44897959183673 | AUC 0.6018392815254181\n",
      "Loss 0.5604156851768494 | Accuracy 79.18367346938776 | AUC 0.6387734995476023\n",
      "Loss 0.5419832468032837 | Accuracy 80.81632653061224 | AUC 0.5976882641168355\n",
      "Loss 0.5419884324073792 | Accuracy 81.22448979591836 | AUC 0.6122557372107597\n",
      "Loss 0.5318223834037781 | Accuracy 81.22448979591836 | AUC 0.627953527953528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79.95022399203586, 0.6175112298039078, 0.5496329301741065)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.attention.model import LabelImageAttention, LabelImagePrototypeModel\n",
    "from models.embedding.model import ImageTextEmbedding, TextEncoder, ImageEncoder\n",
    "\n",
    "from utils.prototype import class_prototype_inf, class_prototype_mean\n",
    "from models.metaclassifier.base import euclidean_distance\n",
    "from models.metaclassifier.trainer import ControlledMetaTrainer\n",
    "from models.metaclassifier.baselines import ProtoNet\n",
    "\n",
    "encoder = torch.load('models/embedding/model/imgtext_model_trained.pth')\n",
    "encoder.text_model.device = device\n",
    "base_model = ProtoNet(encoder, class_prototype_mean, euclidean_distance, trainable_base=False)\n",
    "btrainer = ControlledMetaTrainer(base_model, NUM_SHOTS, NUM_WAYS, dataset_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no finding', 'tuberculosis', 'other lesion', 'infiltration', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6143988966941833 | Accuracy 57.14285714285714 | AUC 0.8143151004762809\n",
      "['consolidation', 'interstitial lung disease', 'pleural effusion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.6604911684989929 | Accuracy 55.10204081632652 | AUC 0.7138259071509845\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.6800097823143005 | Accuracy 54.285714285714285 | AUC 0.6943492781728074\n",
      "['no finding', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.607733964920044 | Accuracy 54.69387755102041 | AUC 0.7853427164454344\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7186079621315002 | Accuracy 47.755102040816325 | AUC 0.683973391442363\n",
      "['no finding', 'consolidation', 'pleural effusion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.5546445250511169 | Accuracy 58.36734693877551 | AUC 0.7889162337789342\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.6872994303703308 | Accuracy 54.285714285714285 | AUC 0.6779584794290677\n",
      "['no finding', 'tuberculosis', 'infiltration', 'pleural effusion', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6029692888259888 | Accuracy 53.06122448979592 | AUC 0.8596773857153871\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.6720254421234131 | Accuracy 56.326530612244895 | AUC 0.6427844444753154\n",
      "['no finding', 'tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6258397102355957 | Accuracy 51.83673469387755 | AUC 0.7720182772736953\n",
      "['tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.7022716999053955 | Accuracy 51.02040816326531 | AUC 0.68938134445235\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5510713458061218 | Accuracy 64.08163265306122 | AUC 0.7898833775905648\n",
      "['no finding', 'consolidation', 'infiltration', 'lung opacity', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.5649588108062744 | Accuracy 59.591836734693885 | AUC 0.8375432217509048\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'pleural effusion', 'pneumonia', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.6715869903564453 | Accuracy 53.06122448979592 | AUC 0.6874884552082984\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7157101035118103 | Accuracy 46.93877551020408 | AUC 0.7117631052420968\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5733081698417664 | Accuracy 61.224489795918366 | AUC 0.7908349837647873\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'lung opacity', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6018257737159729 | Accuracy 57.14285714285714 | AUC 0.7630797590663609\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.7390947341918945 | Accuracy 48.97959183673469 | AUC 0.7003149212901535\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.723018229007721 | Accuracy 53.46938775510204 | AUC 0.6438238197534654\n",
      "['no finding', 'consolidation', 'infiltration', 'pleural effusion', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6134007573127747 | Accuracy 55.51020408163265 | AUC 0.7910870122274682\n",
      "['no finding', 'consolidation', 'tuberculosis', 'infiltration', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5314430594444275 | Accuracy 59.591836734693885 | AUC 0.8833252765989339\n",
      "['interstitial lung disease', 'other lesion', 'pleural effusion', 'lung opacity', 'pneumonia', 'pleural thickening', 'other diseases']\n",
      "Loss 0.7597353458404541 | Accuracy 46.53061224489796 | AUC 0.588005891351756\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'other lesion', 'infiltration', 'lung opacity', 'other diseases']\n",
      "Loss 0.5717542767524719 | Accuracy 63.6734693877551 | AUC 0.7179479911960731\n",
      "['tuberculosis', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6840047836303711 | Accuracy 49.795918367346935 | AUC 0.7125039730177785\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.6807363033294678 | Accuracy 55.91836734693878 | AUC 0.71893513618342\n",
      "['no finding', 'consolidation', 'other lesion', 'pleural effusion', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5767626166343689 | Accuracy 58.36734693877551 | AUC 0.8097967425398398\n",
      "['consolidation', 'interstitial lung disease', 'infiltration', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.731013298034668 | Accuracy 44.48979591836735 | AUC 0.6930039380908947\n",
      "['no finding', 'tuberculosis', 'other lesion', 'pleural effusion', 'lung opacity', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5808091759681702 | Accuracy 61.63265306122449 | AUC 0.7684432578378051\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'pleural effusion', 'lung opacity', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.7301161289215088 | Accuracy 44.48979591836735 | AUC 0.6394070970309362\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6265401840209961 | Accuracy 57.95918367346938 | AUC 0.7817070257188411\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'pleural effusion', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6716942191123962 | Accuracy 55.10204081632652 | AUC 0.7048421429305801\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.6094871759414673 | Accuracy 57.55102040816327 | AUC 0.759879922765663\n",
      "['consolidation', 'tuberculosis', 'other lesion', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.7449150681495667 | Accuracy 52.244897959183675 | AUC 0.635952608786786\n",
      "['no finding', 'interstitial lung disease', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.5712753534317017 | Accuracy 58.36734693877551 | AUC 0.8331700434641611\n",
      "['tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.7297084331512451 | Accuracy 46.93877551020408 | AUC 0.6264902739755839\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5632311701774597 | Accuracy 63.6734693877551 | AUC 0.768281294391718\n",
      "['no finding', 'tuberculosis', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.566461443901062 | Accuracy 60.0 | AUC 0.8327399882090958\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6980266571044922 | Accuracy 52.244897959183675 | AUC 0.6770545101157346\n",
      "['no finding', 'tuberculosis', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5466252565383911 | Accuracy 58.36734693877551 | AUC 0.853824282770577\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'infiltration', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.6662538647651672 | Accuracy 57.95918367346938 | AUC 0.6679903642819243\n",
      "['no finding', 'other lesion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.6071560978889465 | Accuracy 55.51020408163265 | AUC 0.7814226810341361\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6571255326271057 | Accuracy 62.04081632653061 | AUC 0.6396960295939887\n",
      "['other lesion', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7502840757369995 | Accuracy 42.04081632653061 | AUC 0.6239923510424045\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'tuberculosis', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5519418120384216 | Accuracy 63.6734693877551 | AUC 0.7773220948298348\n",
      "['tuberculosis', 'other lesion', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.7404930591583252 | Accuracy 48.97959183673469 | AUC 0.6494220772650349\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'lung opacity', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5601769089698792 | Accuracy 60.816326530612244 | AUC 0.7663521523932848\n",
      "['consolidation', 'interstitial lung disease', 'infiltration', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7252132296562195 | Accuracy 46.93877551020408 | AUC 0.7076571727592136\n",
      "['no finding', 'tuberculosis', 'other lesion', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.5374006628990173 | Accuracy 65.71428571428571 | AUC 0.7582335330340048\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pleural effusion', 'cardiomegaly']\n",
      "Loss 0.5303004384040833 | Accuracy 64.08163265306122 | AUC 0.8339648825125858\n",
      "['consolidation', 'lung opacity', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7840862274169922 | Accuracy 41.224489795918366 | AUC 0.6614425447276008\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.5781093835830688 | Accuracy 57.14285714285714 | AUC 0.82853825099344\n",
      "['consolidation', 'other lesion', 'infiltration', 'pleural effusion', 'lung opacity', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.6802566051483154 | Accuracy 56.326530612244895 | AUC 0.6330300631741208\n",
      "['consolidation', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6755358576774597 | Accuracy 53.46938775510204 | AUC 0.7496718201986697\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'pneumonia', 'pleural thickening']\n",
      "Loss 0.5725189447402954 | Accuracy 62.857142857142854 | AUC 0.7361189476830882\n",
      "['interstitial lung disease', 'other lesion', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7026877999305725 | Accuracy 47.755102040816325 | AUC 0.7005116197503415\n",
      "['no finding', 'consolidation', 'tuberculosis', 'infiltration', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5779486298561096 | Accuracy 56.326530612244895 | AUC 0.8588838699789291\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.6930515766143799 | Accuracy 54.285714285714285 | AUC 0.6261980163238745\n",
      "['no finding', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.587277889251709 | Accuracy 56.326530612244895 | AUC 0.8275422730459027\n",
      "['interstitial lung disease', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7475595474243164 | Accuracy 46.93877551020408 | AUC 0.6831380294726159\n",
      "['no finding', 'consolidation', 'tuberculosis', 'other lesion', 'infiltration', 'lung opacity', 'cardiomegaly']\n",
      "Loss 0.5244974493980408 | Accuracy 65.3061224489796 | AUC 0.8180667620568849\n",
      "['tuberculosis', 'pleural effusion', 'lung opacity', 'pneumonia', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7425586581230164 | Accuracy 44.08163265306123 | AUC 0.685573238065766\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'other lesion', 'infiltration', 'cardiomegaly', 'pulmonary fibrosis']\n",
      "Loss 0.5282263159751892 | Accuracy 67.3469387755102 | AUC 0.7959214048589799\n",
      "['no finding', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.5705691576004028 | Accuracy 55.51020408163265 | AUC 0.8431824903874593\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6730220317840576 | Accuracy 56.326530612244895 | AUC 0.6881412727773583\n",
      "['no finding', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5810356140136719 | Accuracy 58.36734693877551 | AUC 0.8165865619430729\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'pleural effusion', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6976190805435181 | Accuracy 55.51020408163265 | AUC 0.6408003749350305\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'lung opacity', 'pneumonia', 'pleural thickening']\n",
      "Loss 0.6642196774482727 | Accuracy 55.91836734693878 | AUC 0.6951659118525866\n",
      "['no finding', 'consolidation', 'pleural effusion', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5784987211227417 | Accuracy 54.69387755102041 | AUC 0.8376893285896887\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'pneumonia', 'cardiomegaly']\n",
      "Loss 0.5305435657501221 | Accuracy 67.3469387755102 | AUC 0.8064371380253733\n",
      "['tuberculosis', 'infiltration', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7680330872535706 | Accuracy 38.775510204081634 | AUC 0.7125146731067614\n",
      "['no finding', 'interstitial lung disease', 'infiltration', 'pleural effusion', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5954834818840027 | Accuracy 58.36734693877551 | AUC 0.8355289994785792\n",
      "['consolidation', 'tuberculosis', 'other lesion', 'lung opacity', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.7199788093566895 | Accuracy 52.6530612244898 | AUC 0.6637663859300688\n",
      "['interstitial lung disease', 'other lesion', 'lung opacity', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.7264775037765503 | Accuracy 51.83673469387755 | AUC 0.6708036247812111\n",
      "['no finding', 'consolidation', 'tuberculosis', 'infiltration', 'pleural effusion', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.5410443544387817 | Accuracy 64.08163265306122 | AUC 0.8270093700988969\n",
      "['other lesion', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.690475344657898 | Accuracy 52.244897959183675 | AUC 0.7545904486123602\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'tuberculosis', 'lung opacity', 'pneumonia', 'pleural thickening']\n",
      "Loss 0.5694530606269836 | Accuracy 62.44897959183674 | AUC 0.7654414456930934\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'pleural effusion', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.677298903465271 | Accuracy 57.95918367346938 | AUC 0.6350801649915505\n",
      "['no finding', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6350027918815613 | Accuracy 52.6530612244898 | AUC 0.8219428548361701\n",
      "['no finding', 'consolidation', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.6121673583984375 | Accuracy 54.285714285714285 | AUC 0.7837898444401915\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'lung opacity', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6906912326812744 | Accuracy 54.285714285714285 | AUC 0.7227199939337428\n",
      "['interstitial lung disease', 'other lesion', 'infiltration', 'pleural effusion', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.690609872341156 | Accuracy 50.204081632653065 | AUC 0.6802130733518208\n",
      "['no finding', 'consolidation', 'tuberculosis', 'lung opacity', 'pneumonia', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.5422155261039734 | Accuracy 60.0 | AUC 0.8940541046467766\n",
      "['no finding', 'consolidation', 'pleural effusion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.5849510431289673 | Accuracy 57.95918367346938 | AUC 0.8216716306094323\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7472596168518066 | Accuracy 51.42857142857142 | AUC 0.6041152381768733\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'lung opacity', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6259788870811462 | Accuracy 55.51020408163265 | AUC 0.7961484179961652\n",
      "['consolidation', 'other lesion', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.6889268159866333 | Accuracy 51.42857142857142 | AUC 0.619987588634837\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'pneumonia', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.6881577968597412 | Accuracy 58.77551020408164 | AUC 0.6152000886222854\n",
      "['no finding', 'infiltration', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6072455644607544 | Accuracy 53.46938775510204 | AUC 0.7904102573839416\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'pleural effusion', 'lung opacity', 'pneumonia', 'pleural thickening']\n",
      "Loss 0.5376883149147034 | Accuracy 62.857142857142854 | AUC 0.7988504473744747\n",
      "['tuberculosis', 'other lesion', 'infiltration', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7331523299217224 | Accuracy 44.08163265306123 | AUC 0.6774909346979502\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'other lesion', 'lung opacity', 'cardiomegaly', 'aortic enlargement']\n",
      "Loss 0.5712773203849792 | Accuracy 63.6734693877551 | AUC 0.7455698063151479\n",
      "['tuberculosis', 'infiltration', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7499282956123352 | Accuracy 42.04081632653061 | AUC 0.73154397603796\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.578631579875946 | Accuracy 58.36734693877551 | AUC 0.7898652990170019\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'pleural effusion', 'lung opacity', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.703771710395813 | Accuracy 44.89795918367347 | AUC 0.7170605347975041\n",
      "['no finding', 'other lesion', 'infiltration', 'pleural effusion', 'lung opacity', 'pneumonia', 'other diseases']\n",
      "Loss 0.5795026421546936 | Accuracy 57.95918367346938 | AUC 0.8034417136818097\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6200553178787231 | Accuracy 61.224489795918366 | AUC 0.75683898875348\n",
      "['other lesion', 'infiltration', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.78037029504776 | Accuracy 43.673469387755105 | AUC 0.653553929064133\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'tuberculosis', 'pleural effusion', 'pneumonia', 'cardiomegaly']\n",
      "Loss 0.5276474356651306 | Accuracy 66.93877551020408 | AUC 0.8475789073393332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.16034985422738, 0.7399913123640167, 0.6413699126973444)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.create_query_eval_dataloader(), True)\n",
    "# mean prototype 55.16034985422738, 0.7399913123640167 (auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'aortic enlargement', 'other diseases']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naomileow/Documents/school/CS6240/project/utils/prototype.py:55: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  classes_count = torch.nonzero(label_inds)[:,1].bincount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5694094300270081 | Accuracy 62.44897959183674 | AUC 0.7926244586226436\n",
      "['consolidation', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.6985782384872437 | Accuracy 50.204081632653065 | AUC 0.7035248454675698\n",
      "['consolidation', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.7009211182594299 | Accuracy 46.93877551020408 | AUC 0.7360091733326218\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pneumonia', 'other diseases']\n",
      "Loss 0.5711962580680847 | Accuracy 58.77551020408164 | AUC 0.811180126345821\n",
      "['no finding', 'other lesion', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.5496819615364075 | Accuracy 60.816326530612244 | AUC 0.8068685701322694\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'lung opacity', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7309876680374146 | Accuracy 49.38775510204081 | AUC 0.6250703762468469\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'pneumonia', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7056512832641602 | Accuracy 51.02040816326531 | AUC 0.6715955179064107\n",
      "['no finding', 'consolidation', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5620208978652954 | Accuracy 60.816326530612244 | AUC 0.7759797099869444\n",
      "['consolidation', 'infiltration', 'pleural effusion', 'lung opacity', 'pneumonia', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.7542497515678406 | Accuracy 42.857142857142854 | AUC 0.6519350697611567\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.541762113571167 | Accuracy 60.40816326530612 | AUC 0.8618824508824509\n",
      "['no finding', 'other lesion', 'infiltration', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pulmonary fibrosis']\n",
      "Loss 0.5539557933807373 | Accuracy 64.89795918367346 | AUC 0.7890153626902852\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'pneumonia', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7206223011016846 | Accuracy 52.244897959183675 | AUC 0.7090655953636305\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6496408581733704 | Accuracy 53.87755102040816 | AUC 0.7784643384484965\n",
      "['consolidation', 'other lesion', 'infiltration', 'pleural effusion', 'lung opacity', 'pneumonia', 'cardiomegaly']\n",
      "Loss 0.6841103434562683 | Accuracy 50.204081632653065 | AUC 0.7230228933433268\n",
      "['consolidation', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7498283386230469 | Accuracy 46.12244897959184 | AUC 0.622165256887409\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'lung opacity', 'cardiomegaly']\n",
      "Loss 0.5489403605461121 | Accuracy 66.53061224489795 | AUC 0.7632990095024608\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'lung opacity', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.729088306427002 | Accuracy 46.93877551020408 | AUC 0.7655508707420456\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis']\n",
      "Loss 0.5532944798469543 | Accuracy 63.6734693877551 | AUC 0.7234790560983143\n",
      "['no finding', 'consolidation', 'other lesion', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.585803210735321 | Accuracy 58.77551020408164 | AUC 0.836243762996513\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'lung opacity', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.7128180861473083 | Accuracy 47.755102040816325 | AUC 0.6187112122331175\n",
      "['consolidation', 'other lesion', 'lung opacity', 'pneumonia', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7652080655097961 | Accuracy 42.857142857142854 | AUC 0.6159878239592081\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pulmonary fibrosis']\n",
      "Loss 0.5427564978599548 | Accuracy 66.93877551020408 | AUC 0.7790356838387529\n",
      "['no finding', 'consolidation', 'other lesion', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5443441867828369 | Accuracy 62.44897959183674 | AUC 0.8058520029502834\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7201305627822876 | Accuracy 45.714285714285715 | AUC 0.7671641737599643\n",
      "['no finding', 'consolidation', 'other lesion', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pleural thickening']\n",
      "Loss 0.5696208477020264 | Accuracy 63.6734693877551 | AUC 0.7331229209387103\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7284618020057678 | Accuracy 44.89795918367347 | AUC 0.7196690411096173\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'aortic enlargement']\n",
      "Loss 0.5397756099700928 | Accuracy 63.6734693877551 | AUC 0.8191103701939616\n",
      "['other lesion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7545890212059021 | Accuracy 44.48979591836735 | AUC 0.6807981546292557\n",
      "['interstitial lung disease', 'infiltration', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6931021213531494 | Accuracy 51.83673469387755 | AUC 0.6859078246244954\n",
      "['no finding', 'consolidation', 'tuberculosis', 'other lesion', 'pneumonia', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5363782644271851 | Accuracy 62.857142857142854 | AUC 0.8492121640418182\n",
      "['no finding', 'consolidation', 'tuberculosis', 'other lesion', 'infiltration', 'pleural thickening', 'other diseases']\n",
      "Loss 0.6041468381881714 | Accuracy 61.224489795918366 | AUC 0.770140403657645\n",
      "['interstitial lung disease', 'pleural effusion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6763070821762085 | Accuracy 55.10204081632652 | AUC 0.6813764506334165\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5168719291687012 | Accuracy 68.57142857142857 | AUC 0.7723690043260891\n",
      "['consolidation', 'other lesion', 'infiltration', 'lung opacity', 'pneumonia', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7283000946044922 | Accuracy 50.204081632653065 | AUC 0.6287178245257478\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'cardiomegaly']\n",
      "Loss 0.5469224452972412 | Accuracy 71.42857142857143 | AUC 0.7293740272720782\n",
      "['infiltration', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7558627128601074 | Accuracy 41.224489795918366 | AUC 0.6403028988555304\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly']\n",
      "Loss 0.6442606449127197 | Accuracy 63.26530612244898 | AUC 0.6643814816881412\n",
      "['no finding', 'tuberculosis', 'pleural effusion', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6623183488845825 | Accuracy 57.55102040816327 | AUC 0.7159817401080515\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'infiltration', 'pleural effusion', 'lung opacity', 'pleural thickening']\n",
      "Loss 0.5434162616729736 | Accuracy 64.08163265306122 | AUC 0.7599661023829822\n",
      "['tuberculosis', 'other lesion', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7276895642280579 | Accuracy 47.755102040816325 | AUC 0.7381365714470178\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'lung opacity', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5423262119293213 | Accuracy 63.6734693877551 | AUC 0.7938410226245888\n",
      "['tuberculosis', 'other lesion', 'infiltration', 'pleural effusion', 'pneumonia', 'pleural thickening', 'other diseases']\n",
      "Loss 0.7148754596710205 | Accuracy 49.38775510204081 | AUC 0.6758208216875835\n",
      "['consolidation', 'other lesion', 'infiltration', 'lung opacity', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6765804290771484 | Accuracy 54.285714285714285 | AUC 0.7259832426133007\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'pleural effusion', 'pneumonia', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5710405111312866 | Accuracy 61.63265306122449 | AUC 0.7751624355267703\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'lung opacity', 'pneumonia', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7075638175010681 | Accuracy 51.83673469387755 | AUC 0.673098537297306\n",
      "['no finding', 'other lesion', 'infiltration', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5492703318595886 | Accuracy 60.40816326530612 | AUC 0.7994329244165839\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'lung opacity', 'pneumonia']\n",
      "Loss 0.6715521216392517 | Accuracy 58.36734693877551 | AUC 0.6253780899639242\n",
      "['no finding', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6586343050003052 | Accuracy 51.02040816326531 | AUC 0.7560786545194519\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'lung opacity', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5828784704208374 | Accuracy 61.63265306122449 | AUC 0.7858561570160693\n",
      "['tuberculosis', 'other lesion', 'infiltration', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.6761749386787415 | Accuracy 53.46938775510204 | AUC 0.7105766800914195\n",
      "['consolidation', 'interstitial lung disease', 'tuberculosis', 'infiltration', 'lung opacity', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.670778214931488 | Accuracy 56.734693877551024 | AUC 0.7287393655439002\n",
      "['no finding', 'other lesion', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5921433568000793 | Accuracy 57.55102040816327 | AUC 0.8122974240861808\n",
      "['consolidation', 'tuberculosis', 'other lesion', 'pleural effusion', 'pneumonia', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7014543414115906 | Accuracy 48.16326530612245 | AUC 0.6804545351129202\n",
      "['no finding', 'interstitial lung disease', 'infiltration', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5711351037025452 | Accuracy 66.12244897959184 | AUC 0.7478925904916301\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis']\n",
      "Loss 0.6876042485237122 | Accuracy 55.51020408163265 | AUC 0.6581794675912324\n",
      "['no finding', 'consolidation', 'other lesion', 'pleural effusion', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.5819361805915833 | Accuracy 60.0 | AUC 0.7724581627522804\n",
      "['tuberculosis', 'other lesion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.7076234817504883 | Accuracy 51.02040816326531 | AUC 0.6643875236705922\n",
      "['no finding', 'consolidation', 'interstitial lung disease', 'infiltration', 'pleural effusion', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5628191232681274 | Accuracy 62.857142857142854 | AUC 0.785202802339826\n",
      "['no finding', 'consolidation', 'tuberculosis', 'pleural effusion', 'cardiomegaly', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5008107423782349 | Accuracy 71.42857142857143 | AUC 0.7860833995936037\n",
      "['interstitial lung disease', 'other lesion', 'infiltration', 'lung opacity', 'pneumonia', 'pleural thickening', 'other diseases']\n",
      "Loss 0.719370424747467 | Accuracy 48.57142857142857 | AUC 0.6418863132332521\n",
      "['consolidation', 'interstitial lung disease', 'infiltration', 'pleural effusion', 'lung opacity', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7103484272956848 | Accuracy 49.38775510204081 | AUC 0.6322451981773423\n",
      "['no finding', 'tuberculosis', 'other lesion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5831156373023987 | Accuracy 65.71428571428571 | AUC 0.73578480424297\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'infiltration', 'lung opacity', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.682661771774292 | Accuracy 55.10204081632652 | AUC 0.6735463408421012\n",
      "['no finding', 'tuberculosis', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.6128542423248291 | Accuracy 55.10204081632652 | AUC 0.8488135966165914\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'infiltration', 'pleural effusion', 'lung opacity', 'aortic enlargement']\n",
      "Loss 0.5553810596466064 | Accuracy 65.3061224489796 | AUC 0.7701451199334564\n",
      "['consolidation', 'tuberculosis', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.6950355768203735 | Accuracy 50.204081632653065 | AUC 0.7351679584332371\n",
      "['no finding', 'consolidation', 'other lesion', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.5585793852806091 | Accuracy 60.816326530612244 | AUC 0.7676708817498291\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.7103819847106934 | Accuracy 47.3469387755102 | AUC 0.6540193300440305\n",
      "['no finding', 'interstitial lung disease', 'infiltration', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.5651524066925049 | Accuracy 62.857142857142854 | AUC 0.7993701747888868\n",
      "['consolidation', 'tuberculosis', 'other lesion', 'pleural effusion', 'pneumonia', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7192009091377258 | Accuracy 48.97959183673469 | AUC 0.6797642925817807\n",
      "['interstitial lung disease', 'other lesion', 'pleural effusion', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.729957640171051 | Accuracy 47.3469387755102 | AUC 0.6434975305911838\n",
      "['no finding', 'consolidation', 'tuberculosis', 'infiltration', 'lung opacity', 'cardiomegaly', 'aortic enlargement']\n",
      "Loss 0.5343399047851562 | Accuracy 62.857142857142854 | AUC 0.8596307874558649\n",
      "['no finding', 'consolidation', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.5545454025268555 | Accuracy 60.40816326530612 | AUC 0.824938649070228\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pleural effusion', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.714548647403717 | Accuracy 56.326530612244895 | AUC 0.5859442054544095\n",
      "['consolidation', 'other lesion', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'aortic enlargement']\n",
      "Loss 0.6662673354148865 | Accuracy 54.69387755102041 | AUC 0.6898971260446272\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'infiltration', 'lung opacity', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.5906086564064026 | Accuracy 57.55102040816327 | AUC 0.8210048477155321\n",
      "['no finding', 'consolidation', 'other lesion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.6057284474372864 | Accuracy 59.183673469387756 | AUC 0.771618188172968\n",
      "['interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.6797893643379211 | Accuracy 53.06122448979592 | AUC 0.724777530059643\n",
      "['no finding', 'consolidation', 'other lesion', 'infiltration', 'lung opacity', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.6055874228477478 | Accuracy 57.14285714285714 | AUC 0.7575592099678788\n",
      "['interstitial lung disease', 'tuberculosis', 'pleural effusion', 'pneumonia', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7136430144309998 | Accuracy 50.204081632653065 | AUC 0.6962242726664601\n",
      "['no finding', 'consolidation', 'infiltration', 'lung opacity', 'pneumonia', 'cardiomegaly', 'aortic enlargement']\n",
      "Loss 0.5603642463684082 | Accuracy 61.224489795918366 | AUC 0.7733718994844315\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'pleural effusion', 'pleural thickening', 'pulmonary fibrosis', 'other diseases']\n",
      "Loss 0.7519544363021851 | Accuracy 45.714285714285715 | AUC 0.6444750943154206\n",
      "['interstitial lung disease', 'other lesion', 'infiltration', 'pleural effusion', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7096892595291138 | Accuracy 51.83673469387755 | AUC 0.5708205482183104\n",
      "['no finding', 'consolidation', 'tuberculosis', 'lung opacity', 'pneumonia', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5659992694854736 | Accuracy 62.857142857142854 | AUC 0.7554204346442294\n",
      "['consolidation', 'tuberculosis', 'other lesion', 'infiltration', 'pleural effusion', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6707809567451477 | Accuracy 56.734693877551024 | AUC 0.7151045267895364\n",
      "['no finding', 'interstitial lung disease', 'lung opacity', 'pneumonia', 'cardiomegaly', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5530509948730469 | Accuracy 60.40816326530612 | AUC 0.7734598562771938\n",
      "['consolidation', 'interstitial lung disease', 'other lesion', 'infiltration', 'lung opacity', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.6955077648162842 | Accuracy 51.83673469387755 | AUC 0.5994355996670712\n",
      "['no finding', 'tuberculosis', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.6110712289810181 | Accuracy 55.51020408163265 | AUC 0.8261230700196239\n",
      "['interstitial lung disease', 'tuberculosis', 'other lesion', 'lung opacity', 'pneumonia', 'cardiomegaly', 'other diseases']\n",
      "Loss 0.7020254731178284 | Accuracy 53.06122448979592 | AUC 0.6741105863584365\n",
      "['no finding', 'consolidation', 'infiltration', 'pleural effusion', 'pleural thickening', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.57230144739151 | Accuracy 62.857142857142854 | AUC 0.7442631578947367\n",
      "['consolidation', 'other lesion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7288511395454407 | Accuracy 42.857142857142854 | AUC 0.680394369473262\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'infiltration', 'pleural effusion', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.5815834999084473 | Accuracy 62.04081632653061 | AUC 0.7624946773287735\n",
      "['no finding', 'interstitial lung disease', 'tuberculosis', 'other lesion', 'infiltration', 'pneumonia', 'pulmonary fibrosis']\n",
      "Loss 0.573260486125946 | Accuracy 61.63265306122449 | AUC 0.784128279883382\n",
      "['consolidation', 'pleural effusion', 'lung opacity', 'cardiomegaly', 'pleural thickening', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7185041904449463 | Accuracy 42.44897959183673 | AUC 0.7601378970972209\n",
      "['consolidation', 'tuberculosis', 'infiltration', 'lung opacity', 'pneumonia', 'pulmonary fibrosis', 'aortic enlargement']\n",
      "Loss 0.7100948095321655 | Accuracy 50.61224489795918 | AUC 0.6967196676881695\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'pleural effusion', 'cardiomegaly', 'pleural thickening', 'other diseases']\n",
      "Loss 0.5978050827980042 | Accuracy 58.36734693877551 | AUC 0.8055300292821618\n",
      "['consolidation', 'tuberculosis', 'lung opacity', 'pneumonia', 'cardiomegaly', 'aortic enlargement', 'other diseases']\n",
      "Loss 0.7142910361289978 | Accuracy 42.44897959183673 | AUC 0.8012652895705124\n",
      "['no finding', 'interstitial lung disease', 'other lesion', 'infiltration', 'pleural effusion', 'pleural thickening', 'pulmonary fibrosis']\n",
      "Loss 0.5838038325309753 | Accuracy 60.816326530612244 | AUC 0.7502250420297114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.826738858808845, 0.7317367810483341, 0.6398802235418436)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.create_query_eval_dataloader(), True)\n",
    "# inf prototype: 55.826738858808845 (acc), 0.7317367810483341 (auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btrainer.run_eval(btrainer.model, btrainer.test_loader, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6240-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
